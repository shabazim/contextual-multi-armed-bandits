{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, types, warnings, multiprocessing\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _FixedPredictor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X=None, y=None, sample_weight=None):\n",
    "        pass\n",
    "\n",
    "    def decision_function_w_sigmoid(self, X):\n",
    "        return self.decision_function(X)\n",
    "\n",
    "class _BetaPredictor(_FixedPredictor):\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        preds = np.random.beta(self.a, self.b, size = X.shape[0]).reshape((-1, 1))\n",
    "        return np.c_[1.0 - preds, preds]\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.random.beta(self.a, self.b, size = X.shape[0])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (np.random.beta(self.a, self.b, size = X.shape[0])).astype('uint8')\n",
    "\n",
    "    def predict_avg(self, X):\n",
    "        pred = self.decision_function(X)\n",
    "        _apply_inverse_sigmoid(pred)\n",
    "        return pred\n",
    "\n",
    "    def predict_rnd(self, X):\n",
    "        return self.predict_avg(X)\n",
    "\n",
    "    def predict_ucb(self, X):\n",
    "        return self.predict_avg(X)\n",
    "\n",
    "    def exploit(self, X):\n",
    "        return np.repeat(self.a / self.b, X.shape[0])\n",
    "\n",
    "class _ZeroPredictor(_FixedPredictor):\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.c_[np.ones((X.shape[0], 1)),  np.zeros((X.shape[0], 1))]\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.zeros(X.shape[0])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.zeros(X.shape[0])\n",
    "\n",
    "    def predict_avg(self, X):\n",
    "        return np.repeat(-1e6, X.shape[0])\n",
    "\n",
    "    def predict_rnd(self, X):\n",
    "        return self.predict_avg(X)\n",
    "\n",
    "    def predict_ucb(self, X):\n",
    "        return self.predict_avg(X)\n",
    "\n",
    "class _OnePredictor(_FixedPredictor):\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.c_[np.zeros((X.shape[0], 1)),  np.ones((X.shape[0], 1))]\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.ones(X.shape[0])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.ones(X.shape[0])\n",
    "\n",
    "    def predict_avg(self, X):\n",
    "        return np.repeat(1e6, X.shape[0])\n",
    "\n",
    "    def predict_rnd(self, X):\n",
    "        return self.predict_avg(X)\n",
    "\n",
    "    def predict_ucb(self, X):\n",
    "        return self.predict_avg(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_sigmoid(x):\n",
    "    if (len(x.shape) == 2):\n",
    "        x[:, :] = 1.0 / (1.0 + np.exp(-x))\n",
    "    else:\n",
    "        x[:] = 1.0 / (1.0 + np.exp(-x))\n",
    "    return None\n",
    "\n",
    "def _apply_smoothing(preds, smoothing, counts):\n",
    "    if (smoothing is not None) and (counts is not None):\n",
    "        preds[:, :] = (preds * counts + smoothing[0]) / (counts + smoothing[1])\n",
    "    return None\n",
    "\n",
    "def _check_beta_prior(beta_prior, nchoices, default_b):\n",
    "    if beta_prior == 'auto':\n",
    "        out = (_calculate_beta_prior(nchoices), default_b)\n",
    "    elif beta_prior is None:\n",
    "        out = ((1.0,1.0), 0)\n",
    "    else:\n",
    "        assert len(beta_prior) == 2\n",
    "        assert len(beta_prior[0]) == 2\n",
    "        assert isinstance(beta_prior[1], int)\n",
    "        assert isinstance(beta_prior[0][0], int) or isinstance(beta_prior[0][0], float)\n",
    "        assert isinstance(beta_prior[0][1], int) or isinstance(beta_prior[0][1], float)\n",
    "        assert (beta_prior[0][0] > 0) and (beta_prior[0][1] > 0)\n",
    "        out = beta_prior\n",
    "    return out\n",
    "\n",
    "def _check_smoothing(smoothing):\n",
    "    if smoothing is None:\n",
    "        return None\n",
    "    assert len(smoothing) >= 2\n",
    "    assert (smoothing[0] >= 0) & (smoothing[1] >= 0)\n",
    "    assert smoothing[1] > smoothing[0]\n",
    "    return float(smoothing[0]), float(smoothing[1])\n",
    "\n",
    "\n",
    "def _decision_function_w_sigmoid(self, X):\n",
    "    pred = self.decision_function(X).reshape(-1)\n",
    "    _apply_sigmoid(pred)\n",
    "    return pred\n",
    "\n",
    "def _decision_function_w_sigmoid_from_predict(self, X):\n",
    "    return self.predict(X).reshape(-1)\n",
    "\n",
    "def _convert_decision_function_w_sigmoid(classifier):\n",
    "    \n",
    "    if 'decision_function' in dir(classifier):\n",
    "        classifier.decision_function_w_sigmoid = types.MethodType(_decision_function_w_sigmoid, classifier)\n",
    "        #### Note: the weird name is to avoid potential collisions with user-defined methods\n",
    "    elif 'predict' in dir(classifier):\n",
    "        classifier.decision_function_w_sigmoid = types.MethodType(_decision_function_w_sigmoid_from_predict, classifier)\n",
    "    else:\n",
    "        raise ValueError(\"Classifier must have at least one of 'predict_proba', 'decision_function', 'predict'.\")\n",
    "    return classifier\n",
    "    \n",
    "def _apply_inverse_sigmoid(x):\n",
    "    x[x == 0] = 1e-8\n",
    "    x[x == 1] = 1 - 1e-8\n",
    "    if (len(x.shape) == 2):\n",
    "        x[:, :] = np.log(x / (1.0 - x))\n",
    "    else:\n",
    "        x[:] = np.log(x / (1.0 - x))\n",
    "    return None\n",
    "\n",
    "def _apply_softmax(x):\n",
    "    x[:, :] = np.exp(x - x.max(axis=1).reshape((-1, 1)))\n",
    "    x[:, :] = x / x.sum(axis=1).reshape((-1, 1))\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _OneVsRest:\n",
    "    def __init__(self, base, X, a, r, n, thr, alpha, beta,force_counters=False,force_fit=False):\n",
    "        \"\"\"\n",
    "        args: \n",
    "            n: number of arms \n",
    "            a: arms chosen by policy\n",
    "            r: rewards given for the arms chosen\n",
    "            base: base binary classification algorithm\n",
    "            thr: until all arms have been sampled thr number of times (second element of beta prior tuple)\n",
    "            alpha: first param of beta prior\n",
    "            beta: seconf param of beta prior\n",
    "        \"\"\"\n",
    "        if 'predict_proba' not in dir(base):\n",
    "            base = _convert_decision_function_w_sigmoid(base)\n",
    "        \n",
    "        if isinstance(base, list):\n",
    "            self.base = None\n",
    "            self.algos = base\n",
    "        else:\n",
    "            self.base = base\n",
    "            self.algos = [deepcopy(base) for i in range(n)]\n",
    "        self.n = n\n",
    "     \n",
    "        self.thr = thr\n",
    "        self.force_fit = force_fit\n",
    "        self.force_counters = bool(force_counters)\n",
    "        if self.force_counters or (self.thr > 0 and not self.force_fit):\n",
    "            ## in case it has beta prior, keeps track of the counters until no longer needed\n",
    "            self.alpha = alpha\n",
    "            self.beta = beta\n",
    "\n",
    "            ## beta counters are represented as follows:\n",
    "            # * first row: whether it shall use the prior(0:update,1:don't update)\n",
    "            # * second row: number of positives\n",
    "            # * third row: number of negatives\n",
    "            self.beta_counters = np.zeros((3, n))\n",
    "\n",
    "\n",
    "        for choice in range(self.n):\n",
    "            self._full_fit_single(choice, X, a, r) \n",
    "\n",
    "#     def _drop_arm(self, drop_ix):\n",
    "#         del self.algos[drop_ix]\n",
    "#         self.n -= 1\n",
    "#         if self.smooth is not None:\n",
    "#             self.counters = self.counters[:, np.arange(self.counters.shape[1]) != drop_ix]\n",
    "#         if self.force_counters or (self.thr > 0 and not self.force_fit):\n",
    "#             self.beta_counters = self.beta_counters[:, np.arange(self.beta_counters.shape[1]) != drop_ix]\n",
    "\n",
    "#     def _spawn_arm(self, fitted_classifier = None, n_w_req = 0, n_wo_rew = 0):\n",
    "#         self.n += 1\n",
    "#         if self.smooth is not None:\n",
    "#             self.counters = np.c_[self.counters, np.array([n_w_req + n_wo_rew]).reshape((1, 1)).astype(self.counters.dtype)]\n",
    "#         if self.force_counters or (self.thr > 0 and not self.force_fit):\n",
    "#             new_beta_col = np.array([0 if (n_w_req + n_wo_rew) < self.thr else 1, self.alpha + n_w_req, self.beta + n_wo_rew]).reshape((3, 1)).astype(self.beta_counters.dtype)\n",
    "#             self.beta_counters = np.c_[self.beta_counters, new_beta_col]\n",
    "#         if fitted_classifier is not None:\n",
    "#             if 'predict_proba' not in dir(fitted_classifier):\n",
    "#                 fitted_classifier = _convert_decision_function_w_sigmoid(fitted_classifier)\n",
    "#             if partialfit:\n",
    "#                 fitted_classifier = _add_method_predict_robust(fitted_classifier)\n",
    "#             self.algos.append(fitted_classifier)\n",
    "#         else:\n",
    "#             if self.force_fit or self.partialfit:\n",
    "#                 if self.base is None:\n",
    "#                     raise ValueError(\"Must provide a classifier when initializing with different classifiers per arm.\")\n",
    "#                 self.algos.append( deepcopy(self.base) )\n",
    "#             else:\n",
    "#                 if self.force_counters or (self.thr > 0 and not self.force_fit):\n",
    "#                     self.algos.append(_BetaPredictor(self.beta_counters[:, -1][1], self.beta_counters[:, -1][2]))\n",
    "#                 else:\n",
    "#                     self.algos.append(_ZeroPredictor())\n",
    "\n",
    "    def _update_beta_counters(self, yclass, choice):\n",
    "        if (self.beta_counters[0, choice] == 0) or self.force_counters:\n",
    "            n_pos = yclass.sum()\n",
    "            self.beta_counters[1, choice] += n_pos\n",
    "            self.beta_counters[2, choice] += yclass.shape[0] - n_pos\n",
    "            if (self.beta_counters[1, choice] > self.thr) and (self.beta_counters[2, choice] > self.thr):\n",
    "                self.beta_counters[0, choice] = 1\n",
    "\n",
    "    def _full_fit_single(self, choice, X, a, r):\n",
    "        # for chosen arm \"choice\" filter its y and x data (yclass and xclass)\n",
    "        yclass, this_choice = self._filter_arm_data(X, a, r, choice)\n",
    "        n_pos = yclass.sum()\n",
    "#         # smoothing\n",
    "#         if self.smooth is not None:\n",
    "#             # add number of observations for that chosen arm \"choice\"\n",
    "#             self.counters[0, choice] += yclass.shape[0]\n",
    "        # beta prior enhancement (MAB-first)\n",
    "        if (n_pos < self.thr) or ((yclass.shape[0] - n_pos) < self.thr):\n",
    "            if not self.force_fit:\n",
    "                self.algos[choice] = _BetaPredictor(self.alpha + n_pos, self.beta + yclass.shape[0] - n_pos)\n",
    "                return None\n",
    "        # if all the labels (rewards) are negative \n",
    "        if n_pos == 0:\n",
    "            if not self.force_fit:\n",
    "                self.algos[choice] = _ZeroPredictor()\n",
    "                return None\n",
    "        # if all the labels are positive\n",
    "        if n_pos == yclass.shape[0]:\n",
    "            if not self.force_fit:\n",
    "                self.algos[choice] = _OnePredictor()\n",
    "                return None\n",
    "            \n",
    "        xclass = X[this_choice, :]\n",
    "        self.algos[choice].fit(xclass, yclass)\n",
    "\n",
    "        if self.force_counters or (self.thr > 0 and not self.force_fit):\n",
    "            self._update_beta_counters(yclass, choice)\n",
    "\n",
    "\n",
    "#     def partial_fit(self, X, a, r):\n",
    "#         self._partial_fit_single(choice, X, a, r) for choice in range(self.n)\n",
    "# # the base classifier must have a 'partial_fit' method\n",
    "#     def _partial_fit_single(self, choice, X, a, r):\n",
    "#         yclass, this_choice = self._filter_arm_data(X, a, r, choice)\n",
    "#         if self.smooth is not None:\n",
    "#             self.counters[choice] += yclass.shape[0]\n",
    "\n",
    "#         xclass = X[this_choice, :]\n",
    "#         if (xclass.shape[0] > 0) or self.force_fit:\n",
    "#             self.algos[choice].partial_fit(xclass, yclass, classes = [0, 1])\n",
    "\n",
    "#         ## update the beta counters if needed\n",
    "#         if self.force_counters:\n",
    "#             self._update_beta_counters(yclass, choice)\n",
    "\n",
    "    def _filter_arm_data(self, X, a, r, choice):\n",
    "        \n",
    "        this_choice = (a == choice)\n",
    "        yclass = r[this_choice]\n",
    "\n",
    "        ## Note: don't filter X here as in many cases it won't end up used\n",
    "        return yclass, this_choice\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        preds = np.zeros((X.shape[0], self.n))\n",
    "        for choice in range(self.n):\n",
    "            self._decision_function_single(choice, X, preds, 1) \n",
    "        #_apply_smoothing(preds, self.smooth, self.counters)\n",
    "        return preds\n",
    "    \n",
    "# for all observations calculate the probability of a given arm \"choice\" giving the reward 1\n",
    "    def _decision_function_single(self, choice, X, preds, depth=2):\n",
    "        ## case when using partial_fit and need beta predictions\n",
    "#         if (self.partialfit or self.force_fit) and (self.thr > 0):\n",
    "#             if self.beta_counters[0, choice] == 0:\n",
    "#                 preds[:, choice] = np.random.beta(self.alpha + self.beta_counters[1, choice],\n",
    "#                                                   self.beta  + self.beta_counters[2, choice],\n",
    "#                                                   size=preds.shape[0])\n",
    "#                 return None\n",
    "\n",
    "        if 'predict_proba_robust' in dir(self.algos[choice]):\n",
    "            preds[:, choice] = self.algos[choice].predict_proba_robust(X)[:, 1]\n",
    "        elif 'predict_proba' in dir(self.base):\n",
    "            preds[:, choice] = self.algos[choice].predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            if depth == 0:\n",
    "                raise ValueError(\"This requires a classifier with method 'predict_proba'.\")\n",
    "            if 'decision_function_robust' in dir(self.algos[choice]):\n",
    "                preds[:, choice] = self.algos[choice].decision_function_robust(X)\n",
    "            elif 'decision_function_w_sigmoid' in dir(self.algos[choice]):\n",
    "                preds[:, choice] = self.algos[choice].decision_function_w_sigmoid(X)\n",
    "            else:\n",
    "                preds[:, choice] = self.algos[choice].predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        ### this is only used for softmax explorer\n",
    "        preds = np.zeros((X.shape[0], self.n)) # of shape (num observations * num arms)\n",
    "        for choice in range(self.n):\n",
    "            self._decision_function_single(choice, X, preds, 1) \n",
    "        _apply_inverse_sigmoid(preds)\n",
    "        _apply_softmax(preds)\n",
    "        return preds\n",
    "\n",
    "#     def predict_proba_raw(self,X):\n",
    "#         preds = np.zeros((X.shape[0], self.n))\n",
    "#         for choice in range(self.n):\n",
    "#             self._decision_function_single(choice, X, preds, 0) \n",
    "#         _apply_smoothing(preds, self.smooth, self.counters)\n",
    "#         return preds\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "\n",
    "#     def should_calculate_grad(self, choice):\n",
    "#         if self.force_fit:\n",
    "#             return True\n",
    "#         if self.algos[choice].__class__.__name__ in ['_BetaPredictor', '_OnePredictor', '_ZeroPredictor']:\n",
    "#             return False\n",
    "#         if not bool(self.thr):\n",
    "#             return True\n",
    "#         try:\n",
    "#             return bool(self.beta_counters[0, choice])\n",
    "#         except:\n",
    "#             return True\n",
    "\n",
    "    def get_n_pos(self, choice):\n",
    "        return self.beta_counters[1, choice]\n",
    "\n",
    "    def get_n_neg(self, choice):\n",
    "        return self.beta_counters[2, choice]\n",
    "\n",
    "    def exploit(self, X):\n",
    "        ### only used with bootstrapped, bayesian, and lin-ucb/ts classifiers\n",
    "        pred = np.empty((X.shape[0], self.n))\n",
    "        for choice in range(self.n):\n",
    "            self._exploit_single(choice, pred, X) \n",
    "        return pred\n",
    "\n",
    "    def _exploit_single(self, choice, pred, X):\n",
    "        pred[:, choice] = self.algos[choice].exploit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BasePolicy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _add_common_params(self, base_algorithm, beta_prior,nchoices,prior_def_ucb = False,assign_algo=True):\n",
    "        \n",
    "        if isinstance(base_algorithm, np.ndarray) or base_algorithm.__class__.__name__ == \"Series\":\n",
    "            base_algorithm = list(base_algorithm)\n",
    "\n",
    "        self._add_choices(nchoices)\n",
    "        #_check_constructor_input(base_algorithm, self.nchoices, batch_train)\n",
    "        #self.smoothing = _check_smoothing(smoothing)\n",
    "        # \n",
    "        #self.njobs = njobs\n",
    "        #self.assume_unique_reward = assume_unique_reward\n",
    "        #self.batch_train = batch_train\n",
    "        #self.batch_train, self.assume_unique_reward = _check_bools(batch_train, assume_unique_reward)\n",
    "        if prior_def_ucb and beta_prior == \"auto\":\n",
    "            beta_prior = ( (5.0 / self.nchoices, 4.0), 2 )\n",
    "        self.beta_prior = _check_beta_prior(beta_prior, self.nchoices, 2)\n",
    "\n",
    "        if assign_algo:\n",
    "            self.base_algorithm = base_algorithm\n",
    "\n",
    "    def _add_choices(self, nchoices):\n",
    "        if isinstance(nchoices, int):\n",
    "            self.nchoices = nchoices\n",
    "            self.choice_names = None\n",
    "        elif isinstance(nchoices, list) or nchoices.__class__.__name__ == \"Series\" or nchoices.__class__.__name__ == \"DataFrame\":\n",
    "            self.choice_names = np.array(nchoices).reshape(-1)\n",
    "            self.nchoices = self.choice_names.shape[0]\n",
    "            if np.unique(self.choice_names).shape[0] != self.choice_names.shape[0]:\n",
    "                raise ValueError(\"Arm/choice names contain duplicates.\")\n",
    "        elif isinstance(self.choice_names, np.ndarray):\n",
    "            self.choice_names = nchoices.reshape(-1)\n",
    "            self.nchoices = self.choice_names.shape[0]\n",
    "            if np.unique(self.choice_names).shape[0] != self.choice_names.shape[0]:\n",
    "                raise ValueError(\"Arm/choice names contain duplicates.\")\n",
    "        else:\n",
    "            raise ValueError(\"'nchoices' must be an integer or list with named arms.\")\n",
    "\n",
    "    def _name_arms(self, pred):\n",
    "        if self.choice_names is None:\n",
    "            return pred\n",
    "        else:\n",
    "            return self.choice_names[pred]\n",
    "\n",
    "#     def drop_arm(self, arm_name):\n",
    "#         \"\"\"\n",
    "#         Drop an arm/choice\n",
    "#         Drops (removes/deletes) an arm from the set of available choices to the policy.\n",
    "#         Note\n",
    "#         ----\n",
    "#         The available arms, if named, are stored in attribute 'choice_names'.\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         arm_name : int or object\n",
    "#             Arm to drop. If passing an integer, will drop at that index (starting at zero). Otherwise,\n",
    "#             will drop the arm matching this name (argument must be of the same type as the individual entries\n",
    "#             passed to 'nchoices' in the initialization).\n",
    "#         Returns\n",
    "#         -------\n",
    "#         self : object\n",
    "#             This object\n",
    "#         \"\"\"\n",
    "#         drop_ix = self._get_drop_ix(arm_name)\n",
    "#         self._oracles._drop_arm(drop_ix)\n",
    "#         self._drop_ix(drop_ix)\n",
    "#         return self\n",
    "\n",
    "#     def _get_drop_ix(self, arm_name):\n",
    "#         if isinstance(arm_name, int):\n",
    "#             if arm_name > self.nchoices:\n",
    "#                 raise ValueError(\"Object has only \", str(self.nchoices), \" arms.\")\n",
    "#             drop_ix = arm_name\n",
    "#         else:\n",
    "#             if self.choice_names is None:\n",
    "#                 raise ValueError(\"If arms are not named, must pass an integer value.\")\n",
    "#             for ch in range(self.nchoices):\n",
    "#                 if self.choice_names[ch] == arm_name:\n",
    "#                     drop_ix = ch\n",
    "#                     break\n",
    "#             else:\n",
    "#                 raise ValueError(\"No arm named '\", str(arm_name), \"' - current names are stored in attribute 'choice_names'.\")\n",
    "#         return drop_ix\n",
    "\n",
    "#     def _drop_ix(self, drop_ix):\n",
    "#         if self.choice_names is None:\n",
    "#             self.choice_names = np.arange(self.nchoices)\n",
    "#         self.nchoices -= 1\n",
    "#         self.choice_names = np.r_[self.choice_names[:drop_ix], self.choice_names[drop_ix + 1:]]\n",
    "\n",
    "#     def add_arm(self, arm_name = None, fitted_classifier = None, n_w_req = 0, n_wo_rew = 0):\n",
    "#         \"\"\"\n",
    "#         Adds a new arm to the pool of choices\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         arm_name : object\n",
    "#             Name for this arm. Only applicable when using named arms. If None, will use the name of the last\n",
    "#             arm plus 1 (will only work when the names are integers).\n",
    "#         fitted_classifier : object\n",
    "#             If a classifier has already been fit to rewards coming from this arm, you can pass it here, otherwise,\n",
    "#             will be started from the same 'base_classifier' as the initial arms. If using bootstrapped or Bayesian methods,\n",
    "#             don't pass a classifier here (unless using the classes in `utils._BootstrappedClassifierBase`, `utils._BayesianLogisticRegression`)\n",
    "#         n_w_req : int\n",
    "#             Number of trials/rounds with rewards coming from this arm (only used when using a beta prior or smoothing).\n",
    "#         n_wo_rew : int\n",
    "#             Number of trials/rounds without rewards coming from this arm (only used when using a beta prior or smoothing).\n",
    "#         Returns\n",
    "#         -------\n",
    "#         self : object\n",
    "#             This object\n",
    "#         \"\"\"\n",
    "#         assert isinstance(n_w_req,  int)\n",
    "#         assert isinstance(n_wo_rew, int)\n",
    "#         assert n_w_req >= 0\n",
    "#         assert n_wo_rew >= 0\n",
    "#         arm_name = self._check_new_arm_name(arm_name)\n",
    "#         self._oracles._spawn_arm(fitted_classifier, n_w_req, n_wo_rew)\n",
    "#         self._append_arm(arm_name)\n",
    "#         return self\n",
    "\n",
    "#     def _check_new_arm_name(self, arm_name):\n",
    "#         if self.choice_names is None and arm_name is not None:\n",
    "#             raise ValueError(\"Cannot create a named arm when no names were passed to 'nchoices'.\")\n",
    "#         if arm_name is None and self.choice_names is not None:\n",
    "#             try:\n",
    "#                 arm_name = self.choice_names[-1] + 1\n",
    "#             except:\n",
    "#                 raise ValueError(\"Must provide an arm name when using named arms.\")\n",
    "#         return arm_name\n",
    "\n",
    "#     def _append_arm(self, arm_name):\n",
    "#         if self.choice_names is not None:\n",
    "#             self.choice_names = np.r_[self.choice_names, np.array(arm_name).reshape((1,))]\n",
    "#         self.nchoices += 1\n",
    "\n",
    "    def fit(self, X, a, r):\n",
    "        \"\"\"\n",
    "        Fits the base algorithm (one per class [and per sample if bootstrapped]) to partially labeled data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array (n_samples, n_features)\n",
    "            Matrix of covariates for the available data.\n",
    "        a : array (n_samples), int type\n",
    "            Arms or actions that were chosen for each observations.\n",
    "        r : array (n_samples), {0,1}\n",
    "            Rewards that were observed for the chosen actions. Must be binary rewards 0/1.\n",
    "        Returns\n",
    "        -------\n",
    "        self : obj\n",
    "            This object\n",
    "        \"\"\"\n",
    "        #X, a, r = _check_fit_input(X, a, r, self.choice_names)\n",
    "        self._oracles = _OneVsRest(self.base_algorithm,\n",
    "                                   X, a, r,\n",
    "                                   self.nchoices,\n",
    "                                   self.beta_prior[1], self.beta_prior[0][0], self.beta_prior[0][1])\n",
    "        return self\n",
    "    \n",
    "#     def partial_fit(self, X, a, r):\n",
    "#         \"\"\"\n",
    "#         Fits the base algorithm (one per class) to partially labeled data in batches.\n",
    "        \n",
    "#         Note\n",
    "#         ----\n",
    "#         In order to use this method, the base classifier must have a 'partial_fit' method,\n",
    "#         such as 'sklearn.linear_model.SGDClassifier'.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array (n_samples, n_features)\n",
    "#             Matrix of covariates for the available data.\n",
    "#         a : array (n_samples), int type\n",
    "#             Arms or actions that were chosen for each observations.\n",
    "#         r : array (n_samples), {0,1}\n",
    "#             Rewards that were observed for the chosen actions. Must be binary rewards 0/1.\n",
    "#         Returns\n",
    "#         -------\n",
    "#         self : obj\n",
    "#             This object\n",
    "#         \"\"\"\n",
    "#         if '_oracles' in dir(self):\n",
    "#             #X, a, r =_check_fit_input(X, a, r, self.choice_names)\n",
    "#             self._oracles.partial_fit(X, a, r)\n",
    "#             return self\n",
    "#         else:\n",
    "#             return self.fit(X, a, r)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Get the scores for each arm following this policy's action-choosing criteria.\n",
    "        Note\n",
    "        ----\n",
    "        For 'ExploreFirst', the results from this method will not actually follow the policy in\n",
    "        assigning random numbers during the exploration phase.\n",
    "        Same for 'AdaptiveGreedy' - it won't make random choices according to the policy.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array (n_samples, n_features)\n",
    "            Data for which to obtain decision function scores for each arm.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        scores : array (n_samples, n_choices)\n",
    "            Scores following this policy for each arm.\n",
    "        \"\"\"\n",
    "        #X = _check_X_input(X)\n",
    "        return self._oracles.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy(_BasePolicy):\n",
    "    \"\"\"\n",
    "    Epsilon Greedy\n",
    "    \n",
    "    Takes a random action with probability p, or the action with highest\n",
    "    estimated reward with probability 1-p.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_algorithm : obj\n",
    "        Base binary classifier for which each sample for each class will be fit.\n",
    "        Will look for, in this order:\n",
    "            1) A 'predict_proba' method with outputs (n_samples, 2), values in [0,1], rows suming to 1\n",
    "            2) A 'decision_function' method with unbounded outputs (n_samples,) to which it will apply a sigmoid function.\n",
    "            3) A 'predict' method with outputs (n_samples,) with values in [0,1].\n",
    "        Can also pass a list with a different (or already-fit) classifier for each arm.\n",
    "    nchoices : int or list-like\n",
    "        Number of arms/labels to choose from. Can also pass a list, array or series with arm names, in which case\n",
    "        the outputs from predict will follow these names and arms can be dropped by name, and new ones added with a\n",
    "        custom name.\n",
    "    explore_prob : float (0,1)\n",
    "        Probability of taking a random action at each round.\n",
    "    decay : float (0,1)\n",
    "        After each prediction, the explore probability reduces to\n",
    "        p = p*decay\n",
    "    beta_prior : str 'auto', None, or tuple ((a,b), n)\n",
    "        If not None, when there are less than 'n' positive samples from a class\n",
    "        (actions from that arm that resulted in a reward), it will predict the score\n",
    "        for that class as a random number drawn from a beta distribution with the prior\n",
    "        specified by 'a' and 'b'. If set to auto, will be calculated as:\n",
    "        beta_prior = ((3/nchoices, 4), 2)\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    smoothing : None or tuple (a,b)\n",
    "        If not None, predictions will be smoothed as yhat_smooth = (yhat*n + a)/(n + b),\n",
    "        where 'n' is the number of times each arm was chosen in the training data.\n",
    "        This will not work well with non-probabilistic classifiers such as SVM, in which case you might\n",
    "        want to define a class that embeds it with some recalibration built-in.\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    batch_train : bool\n",
    "        Whether the base algorithm will be fit to the data in batches as it comes (online),\n",
    "        or to the whole dataset each time it is refit. Requires a classifier with a\n",
    "        'partial_fit' method.\n",
    "    assume_unique_reward : bool\n",
    "        Whether to assume that only one arm has a reward per observation. If set to False,\n",
    "        whenever an arm receives a reward, the classifiers for all other arms will be\n",
    "        fit to that observation too, having negative label.\n",
    "    njobs : int or None\n",
    "        Number of parallel jobs to run. If passing None will set it to 1. If passing -1 will\n",
    "        set it to the number of CPU cores. Note that if the base algorithm is itself parallelized,\n",
    "        this might result in a slowdown as both compete for available threads, so don't set\n",
    "        parallelization in both.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [1] Cortes, David. \"Adapting multi-armed bandits policies to contextual bandits scenarios.\"\n",
    "        arXiv preprint arXiv:1811.04383 (2018).\n",
    "    [2] Yue, Yisong, et al. \"The k-armed dueling bandits problem.\"\n",
    "        Journal of Computer and System Sciences 78.5 (2012): 1538-1556.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_algorithm, nchoices, explore_prob=0.2, decay=0.9999,\n",
    "                 beta_prior='auto'):\n",
    "        self._add_common_params(base_algorithm, beta_prior,  nchoices)\n",
    "        assert (explore_prob>0) and (explore_prob<1)\n",
    "        if decay is not None:\n",
    "            assert (decay>0) and (decay<1)\n",
    "            if decay <= .99:\n",
    "                warnings.warn(\"Warning: 'EpsilonGreedy' has a very high decay rate.\")\n",
    "        self.explore_prob = explore_prob\n",
    "        self.decay = decay\n",
    "    \n",
    "    def predict(self, X, exploit = False, output_score = False):\n",
    "        \"\"\"\n",
    "        Selects actions according to this policy for new data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array (n_samples, n_features)\n",
    "            New observations for which to choose an action according to this policy.\n",
    "        exploit : bool\n",
    "            Whether to make a prediction according to the policy, or to just choose the\n",
    "            arm with the highest expected reward according to current models.\n",
    "        output_score : bool\n",
    "            Whether to output the score that this method predicted, in case it is desired to use\n",
    "            it with this pakckage's offpolicy and evaluation modules.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pred : array (n_samples,) or dict(\"choice\" : array(n_samples,), \"score\" : array(n_samples,))\n",
    "            Actions chosen by the policy. If passing output_score=True, it will be a dictionary\n",
    "            with the chosen arm and the score that the arm got following this policy with the classifiers used.\n",
    "        \"\"\"\n",
    "        scores = self.decision_function(X)\n",
    "        pred = np.argmax(scores, axis = 1)\n",
    "        if not exploit:\n",
    "            ix_change_rnd = (np.random.random(size =  X.shape[0]) <= self.explore_prob)\n",
    "            pred[ix_change_rnd] = np.random.randint(self.nchoices, size = ix_change_rnd.sum())\n",
    "        pred = self._name_arms(pred)\n",
    "\n",
    "        if self.decay is not None:\n",
    "            self.explore_prob *= self.decay ** X.shape[0]\n",
    "        \n",
    "        if not output_score:\n",
    "            return pred\n",
    "        else:\n",
    "            score_max = np.max(scores, axis = 1).reshape((-1, 1))\n",
    "            score_max[ix_change_rnd] = 1 / self.nchoices\n",
    "            return {\"choice\" : pred, \"score\" : score_max}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExploreFirst(_BasePolicy):\n",
    "    \"\"\"\n",
    "    Explore First, a.k.a. Explore-Then-Exploit\n",
    "    \n",
    "    Selects random actions for the first N predictions, after which it selects the\n",
    "    best arm only according to its estimates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_algorithm : obj\n",
    "        Base binary classifier for which each sample for each class will be fit.\n",
    "        Will look for, in this order:\n",
    "            1) A 'predict_proba' method with outputs (n_samples, 2), values in [0,1], rows suming to 1\n",
    "            2) A 'decision_function' method with unbounded outputs (n_samples,) to which it will apply a sigmoid function.\n",
    "            3) A 'predict' method with outputs (n_samples,) with values in [0,1].\n",
    "        Can also pass a list with a different (or already-fit) classifier for each arm.\n",
    "    nchoices : int or list-like\n",
    "        Number of arms/labels to choose from. Can also pass a list, array or series with arm names, in which case\n",
    "        the outputs from predict will follow these names and arms can be dropped by name, and new ones added with a\n",
    "        custom name.\n",
    "    explore_rounds : int\n",
    "        Number of rounds to wait before exploitation mode.\n",
    "        Will switch after making N predictions.\n",
    "    beta_prior : str 'auto', None, or tuple ((a,b), n)\n",
    "        If not None, when there are less than 'n' positive samples from a class\n",
    "        (actions from that arm that resulted in a reward), it will predict the score\n",
    "        for that class as a random number drawn from a beta distribution with the prior\n",
    "        specified by 'a' and 'b'. If set to auto, will be calculated as:\n",
    "        beta_prior = ((3/nchoices, 4), 2)\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    smoothing : None or tuple (a,b)\n",
    "        If not None, predictions will be smoothed as yhat_smooth = (yhat*n + a)/(n + b),\n",
    "        where 'n' is the number of times each arm was chosen in the training data.\n",
    "        This will not work well with non-probabilistic classifiers such as SVM, in which case you might\n",
    "        want to define a class that embeds it with some recalibration built-in.\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    batch_train : bool\n",
    "        Whether the base algorithm will be fit to the data in batches as it comes (online),\n",
    "        or to the whole dataset each time it is refit. Requires a classifier with a\n",
    "        'partial_fit' method.\n",
    "    assume_unique_reward : bool\n",
    "        Whether to assume that only one arm has a reward per observation. If set to False,\n",
    "        whenever an arm receives a reward, the classifiers for all other arms will be\n",
    "        fit to that observation too, having negative label.\n",
    "    njobs : int or None\n",
    "        Number of parallel jobs to run. If passing None will set it to 1. If passing -1 will\n",
    "        set it to the number of CPU cores. Note that if the base algorithm is itself parallelized,\n",
    "        this might result in a slowdown as both compete for available threads, so don't set\n",
    "        parallelization in both.\n",
    "    References\n",
    "    ----------\n",
    "    [1] Cortes, David. \"Adapting multi-armed bandits policies to contextual bandits scenarios.\"\n",
    "        arXiv preprint arXiv:1811.04383 (2018).\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self, base_algorithm, nchoices, explore_rounds=2500,\n",
    "                 beta_prior=None):\n",
    "        self._add_common_params(base_algorithm, beta_prior, nchoices)\n",
    "        \n",
    "        assert explore_rounds>0\n",
    "        assert isinstance(explore_rounds, int)\n",
    "        self.explore_rounds = explore_rounds\n",
    "        self.explore_cnt = 0\n",
    "\n",
    "    def predict(self, X, exploit = False):\n",
    "        \"\"\"\n",
    "        Selects actions according to this policy for new data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array (n_samples, n_features)\n",
    "            New observations for which to choose an action according to this policy.\n",
    "        exploit : bool\n",
    "            Whether to make a prediction according to the policy, or to just choose the\n",
    "            arm with the highest expected reward according to current models.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pred : array (n_samples,)\n",
    "            Actions chosen by the policy.\n",
    "        \"\"\"\n",
    "        # TODO: add option to output scores\n",
    "        return self._name_arms(self._predict(X, exploit))\n",
    "    \n",
    "    def _predict(self, X, exploit = False):\n",
    "        # = _check_X_input(X)\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            return np.array([])\n",
    "        \n",
    "        if exploit:\n",
    "            return self._oracles.predict(X)\n",
    "        \n",
    "        if self.explore_cnt < self.explore_rounds:\n",
    "            self.explore_cnt += X.shape[0]\n",
    "            \n",
    "            # case 1: all predictions are within allowance\n",
    "            if self.explore_cnt <= self.explore_rounds:\n",
    "                return np.random.randint(self.nchoices, size = X.shape[0])\n",
    "            \n",
    "            # case 2: some predictions are within allowance, others are not\n",
    "            else:\n",
    "                n_explore = self.explore_rounds - self.explore_cnt + X.shape[0]\n",
    "                pred = np.empty(X.shape[0], type = \"float64\")\n",
    "                pred[:n_explore] = np.random.randint(self.nchoices, n_explore)\n",
    "                pred[n_explore:] = self._oracles.predict(X[n_explore:])\n",
    "                return pred\n",
    "        else:\n",
    "            return self._oracles.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxExplorer(_BasePolicy):\n",
    "    \"\"\"\n",
    "    SoftMax Explorer\n",
    "    \n",
    "    Selects an action according to probabilites determined by a softmax transformation\n",
    "    on the scores from the decision function that predicts each class.\n",
    "    Note\n",
    "    ----\n",
    "    Will apply an inverse sigmoid transformations to the probabilities that come from the base algorithm\n",
    "    before applying the softmax function.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_algorithm : obj\n",
    "        Base binary classifier for which each sample for each class will be fit.\n",
    "        Will look for, in this order:\n",
    "            1) A 'predict_proba' method with outputs (n_samples, 2), values in [0,1], rows suming to 1, to which it\n",
    "               will apply an inverse sigmoid function.\n",
    "            2) A 'decision_function' method with unbounded outputs (n_samples,).\n",
    "            3) A 'predict' method outputting (n_samples,), values in [0,1], to which it will apply an inverse sigmoid function.\n",
    "        Can also pass a list with a different (or already-fit) classifier for each arm.\n",
    "    nchoices : int or list-like\n",
    "        Number of arms/labels to choose from. Can also pass a list, array or series with arm names, in which case\n",
    "        the outputs from predict will follow these names and arms can be dropped by name, and new ones added with a\n",
    "        custom name.\n",
    "    multiplier : float or None\n",
    "        Number by which to multiply the outputs from the base algorithm before applying the softmax function\n",
    "        (i.e. will take softmax(yhat * multiplier)).\n",
    "    inflation_rate : float or None\n",
    "        Number by which to multiply the multipier rate after every prediction, i.e. after making\n",
    "        't' predictions, the multiplier will be 'multiplier_t = multiplier * inflation_rate^t'.\n",
    "    beta_prior : str 'auto', None, or tuple ((a,b), n)\n",
    "        If not None, when there are less than 'n' positive samples from a class\n",
    "        (actions from that arm that resulted in a reward), it will predict the score\n",
    "        for that class as a random number drawn from a beta distribution with the prior\n",
    "        specified by 'a' and 'b'. If set to auto, will be calculated as:\n",
    "        beta_prior = ((3/nchoices, 4), 2)\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    smoothing : None or tuple (a,b)\n",
    "        If not None, predictions will be smoothed as yhat_smooth = (yhat*n + a)/(n + b),\n",
    "        where 'n' is the number of times each arm was chosen in the training data.\n",
    "        This will not work well with non-probabilistic classifiers such as SVM, in which case you might\n",
    "        want to define a class that embeds it with some recalibration built-in.\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    batch_train : bool\n",
    "        Whether the base algorithm will be fit to the data in batches as it comes (online),\n",
    "        or to the whole dataset each time it is refit. Requires a classifier with a\n",
    "        'partial_fit' method.\n",
    "    assume_unique_reward : bool\n",
    "        Whether to assume that only one arm has a reward per observation. If set to False,\n",
    "        whenever an arm receives a reward, the classifiers for all other arms will be\n",
    "        fit to that observation too, having negative label.\n",
    "    njobs : int or None\n",
    "        Number of parallel jobs to run. If passing None will set it to 1. If passing -1 will\n",
    "        set it to the number of CPU cores. Note that if the base algorithm is itself parallelized,\n",
    "        this might result in a slowdown as both compete for available threads, so don't set\n",
    "        parallelization in both.\n",
    "    References\n",
    "    ----------\n",
    "    [1] Cortes, David. \"Adapting multi-armed bandits policies to contextual bandits scenarios.\"\n",
    "        arXiv preprint arXiv:1811.04383 (2018).\n",
    "    \"\"\"\n",
    "    def __init__(self, base_algorithm, nchoices, multiplier=1.0, inflation_rate=1.0004,\n",
    "                 beta_prior='auto'):\n",
    "       \n",
    "        self._add_common_params(base_algorithm, beta_prior, nchoices)\n",
    "\n",
    "        if multiplier is not None:\n",
    "            if isinstance(multiplier, int):\n",
    "                multiplier = float(multiplier)\n",
    "            assert multiplier > 0\n",
    "        else:\n",
    "            multiplier = None\n",
    "        if inflation_rate is not None:\n",
    "            if isinstance(inflation_rate, int):\n",
    "                inflation_rate = float(inflation_rate)\n",
    "            assert inflation_rate > 0\n",
    "        self.multiplier = multiplier\n",
    "        self.inflation_rate = inflation_rate\n",
    "    \n",
    "#     def decision_function(self, X, output_score=False, apply_sigmoid_score=True):\n",
    "#         \"\"\"\n",
    "#         Get the scores for each arm following this policy's action-choosing criteria.\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array (n_samples, n_features)\n",
    "#             Data for which to obtain decision function scores for each arm.\n",
    "        \n",
    "#         Returns\n",
    "#         -------\n",
    "#         scores : array (n_samples, n_choices)\n",
    "#             Scores following this policy for each arm.\n",
    "#         \"\"\"\n",
    "      \n",
    "#         return self._oracles.predict_proba(X)\n",
    "    \n",
    "    def predict(self, X, exploit=False, output_score=False):\n",
    "        \"\"\"\n",
    "        Selects actions according to this policy for new data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array (n_samples, n_features)\n",
    "            New observations for which to choose an action according to this policy.\n",
    "        exploit : bool\n",
    "            Whether to make a prediction according to the policy, or to just choose the\n",
    "            arm with the highest expected reward according to current models.\n",
    "        output_score : bool\n",
    "            Whether to output the score that this method predicted, in case it is desired to use\n",
    "            it with this pakckage's offpolicy and evaluation modules.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pred : array (n_samples,) or dict(\"choice\" : array(n_samples,), \"score\" : array(n_samples,))\n",
    "            Actions chosen by the policy. If passing output_score=True, it will be a dictionary\n",
    "            with the chosen arm and the score that the arm got following this policy with the classifiers used.\n",
    "        \"\"\"\n",
    "        if exploit:\n",
    "            return np.argmax(self._oracles.decision_function(X), axis=1)\n",
    "        # according to policy\n",
    "        pred = self.decision_function(X)\n",
    "        _apply_inverse_sigmoid(pred)\n",
    "        if self.multiplier is not None:\n",
    "            pred *= self.multiplier\n",
    "            if self.inflation_rate is not None:\n",
    "                self.multiplier *= self.inflation_rate ** pred.shape[0]\n",
    "        _apply_softmax(pred)\n",
    "        \n",
    "        chosen = np.empty(pred.shape[0], dtype = \"int64\")\n",
    "        for i in range(pred.shape[0]): \n",
    "            self._pick_pred(i, chosen, pred)\n",
    "        \n",
    "    \n",
    "        if output_score:\n",
    "            score_chosen = pred[np.arange(pred.shape[0]), np.array(chosen)]\n",
    "        chosen = self._name_arms(chosen)\n",
    "\n",
    "        if not output_score:\n",
    "            return chosen\n",
    "        else:\n",
    "            return {\"choice\" : chosen, \"score\" : score_chosen}\n",
    "\n",
    "    def _pick_pred(self, i, chosen, pred):\n",
    "        if pred[i].sum() != 1.0: #floating point arithmetic issues\n",
    "            pred[i] = pred[i] / np.sum(pred[i])\n",
    "        chosen[i] = np.random.choice(self.nchoices, p = pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# action_chosen = (np.random.randint(5, size=10))\n",
    "# this_choice = action_chosen == 1\n",
    "# t_list = [np.random.randint(5, size=i+1).tolist() for i in range(0,10)]\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# y = mlb.fit_transform(t_list)\n",
    "# rewards_received = y[np.arange(10), action_chosen]\n",
    "# yclass = rewards_received[this_choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mshahbazi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def parse_data(file_name):\n",
    "    features = list()\n",
    "    labels = list()\n",
    "    with open(file_name, 'rt') as f:\n",
    "        f.readline()\n",
    "        for l in f:\n",
    "            if bool(re.search(\"^[0-9]\", l)):\n",
    "                g = re.search(\"^(([0-9]{1,2},?)+)\\s(.*)$\", l)\n",
    "                labels.append([int(i) for i in g.group(1).split(\",\")])\n",
    "                features.append(eval(\"{\" + re.sub(\"\\s\", \",\", g.group(3)) + \"}\"))\n",
    "            else:\n",
    "                l = l.strip()\n",
    "                labels.append([])\n",
    "                features.append(eval(\"{\" + re.sub(\"\\s\", \",\", l) + \"}\"))\n",
    "    features = pd.DataFrame.from_dict(features).fillna(0).as_matrix()\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(labels)\n",
    "    return features, y\n",
    "\n",
    "X, y = parse_data(\"Bibtex_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7395, 1836)\n",
      "(7395, 159)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# num of arms \n",
    "nchoices = y.shape[1]\n",
    "\n",
    "base_algorithm = LogisticRegression(random_state=123, solver='lbfgs')\n",
    "beta_prior = ((3, 7), 2) # until there are at least 2 observations of each class, will use prior Beta(3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_greedy = EpsilonGreedy(deepcopy(base_algorithm), nchoices = nchoices, beta_prior=beta_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1836)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# batch size - algorithms will be refit after N rounds\n",
    "batch_size=50\n",
    "\n",
    "# initial seed - all policies start with the same small random selection of actions/rewards\n",
    "first_batch = X[:batch_size, :]\n",
    "# a choice for each batch \n",
    "action_chosen = np.random.randint(nchoices, size=batch_size)\n",
    "# reward of the chosen action\n",
    "rewards_received = y[np.arange(batch_size), action_chosen]\n",
    "\n",
    "print(first_batch.shape)\n",
    "print(action_chosen.shape)\n",
    "print(rewards_received.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EpsilonGreedy at 0x1516ad67e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models for the first time\n",
    "\n",
    "np.random.seed(123)\n",
    "epsilon_greedy.fit(X=first_batch, a=action_chosen, r=rewards_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds are simulated from the full dataset\n",
    "def simulate_rounds(model, rewards, actions_hist, X_global, y_global, batch_st, batch_end):\n",
    "    np.random.seed(batch_st)\n",
    "    \n",
    "    ## choosing actions for this batch\n",
    "    actions_this_batch = model.predict(X_global[batch_st:batch_end, :]).astype('uint8')\n",
    "    \n",
    "    # keeping track of the sum of rewards received\n",
    "    rewards.append(y_global[np.arange(batch_st, batch_end), actions_this_batch].sum())\n",
    "    \n",
    "    # adding this batch to the history of selected actions\n",
    "    new_actions_hist = np.append(actions_hist, actions_this_batch)\n",
    "    \n",
    "    # now refitting the algorithms after observing these new rewards\n",
    "    np.random.seed(batch_st)\n",
    "    model.fit(X_global[:batch_end, :], new_actions_hist, y_global[np.arange(batch_end), new_actions_hist])\n",
    "    \n",
    "    return new_actions_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "# now running all the simulation\n",
    "for i in range(int(np.floor(X.shape[0] / batch_size))):\n",
    "    batch_st = (i + 1) * batch_size\n",
    "    batch_end = (i + 2) * batch_size\n",
    "    batch_end = np.min([batch_end, X.shape[0]])\n",
    "    \n",
    " \n",
    "    action_chosen = simulate_rounds(epsilon_greedy,\n",
    "                                             rewards,\n",
    "                                             action_chosen,\n",
    "                                             X, y,\n",
    "                                             batch_st, batch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "def get_mean_reward(reward_lst, batch_size=batch_size):\n",
    "    mean_rew=list()\n",
    "    for r in range(len(reward_lst)):\n",
    "        mean_rew.append(sum(reward_lst[:r+1]) * 1.0 / ((r+1)*batch_size))\n",
    "    return mean_rew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x151037b3278>,\n",
       "  <matplotlib.axis.XTick at 0x1510378dc18>,\n",
       "  <matplotlib.axis.XTick at 0x1510378d940>,\n",
       "  <matplotlib.axis.XTick at 0x151037dd668>,\n",
       "  <matplotlib.axis.XTick at 0x151037ddb38>,\n",
       "  <matplotlib.axis.XTick at 0x151037dda90>,\n",
       "  <matplotlib.axis.XTick at 0x151037ed278>,\n",
       "  <matplotlib.axis.XTick at 0x151037ed748>],\n",
       " <a list of 8 Text xticklabel objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(get_mean_reward(rewards))\n",
    "plt.xticks([i*20 for i in range(8)], [i*1000 for i in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore-Then-Exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# num of arms \n",
    "nchoices = y.shape[1]\n",
    "\n",
    "base_algorithm = LogisticRegression(random_state=123, solver='lbfgs')\n",
    "beta_prior = ((3, 7), 2) # until there are at least 2 observations of each class, will use prior Beta(3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_first = ExploreFirst(deepcopy(base_algorithm), nchoices = nchoices,\n",
    "                             beta_prior=None, explore_rounds=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1836)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# batch size - algorithms will be refit after N rounds\n",
    "batch_size=50\n",
    "\n",
    "# initial seed - all policies start with the same small random selection of actions/rewards\n",
    "first_batch = X[:batch_size, :]\n",
    "# a choice for each batch \n",
    "action_chosen = np.random.randint(nchoices, size=batch_size)\n",
    "# reward of the chosen action\n",
    "rewards_received = y[np.arange(batch_size), action_chosen]\n",
    "\n",
    "print(first_batch.shape)\n",
    "print(action_chosen.shape)\n",
    "print(rewards_received.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ExploreFirst at 0x191397a5c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models for the first time\n",
    "np.random.seed(123)\n",
    "explore_first.fit(X=first_batch, a=action_chosen, r=rewards_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds are simulated from the full dataset\n",
    "def simulate_rounds(model, rewards, actions_hist, X_global, y_global, batch_st, batch_end):\n",
    "    np.random.seed(batch_st)\n",
    "    \n",
    "    ## choosing actions for this batch\n",
    "    actions_this_batch = model.predict(X_global[batch_st:batch_end, :]).astype('uint8')\n",
    "    \n",
    "    # keeping track of the sum of rewards received\n",
    "    rewards.append(y_global[np.arange(batch_st, batch_end), actions_this_batch].sum())\n",
    "    \n",
    "    # adding this batch to the history of selected actions\n",
    "    new_actions_hist = np.append(actions_hist, actions_this_batch)\n",
    "    \n",
    "    # now refitting the algorithms after observing these new rewards\n",
    "    np.random.seed(batch_st)\n",
    "    model.fit(X_global[:batch_end, :], new_actions_hist, y_global[np.arange(batch_end), new_actions_hist])\n",
    "    \n",
    "    return new_actions_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "# now running all the simulation\n",
    "for i in range(int(np.floor(X.shape[0] / batch_size))):\n",
    "    batch_st = (i + 1) * batch_size\n",
    "    batch_end = (i + 2) * batch_size\n",
    "    batch_end = np.min([batch_end, X.shape[0]])\n",
    "    \n",
    " \n",
    "    action_chosen = simulate_rounds(explore_first,\n",
    "                                             rewards,\n",
    "                                             action_chosen,\n",
    "                                             X, y,\n",
    "                                             batch_st, batch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "def get_mean_reward(reward_lst, batch_size=batch_size):\n",
    "    mean_rew=list()\n",
    "    for r in range(len(reward_lst)):\n",
    "        mean_rew.append(sum(reward_lst[:r+1]) * 1.0 / ((r+1)*batch_size))\n",
    "    return mean_rew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x19151ddbcc0>,\n",
       "  <matplotlib.axis.XTick at 0x19151ddb668>,\n",
       "  <matplotlib.axis.XTick at 0x19151ddb400>,\n",
       "  <matplotlib.axis.XTick at 0x19151e18cf8>,\n",
       "  <matplotlib.axis.XTick at 0x19151e2b4e0>,\n",
       "  <matplotlib.axis.XTick at 0x19151e2b9b0>,\n",
       "  <matplotlib.axis.XTick at 0x19151e2b160>,\n",
       "  <matplotlib.axis.XTick at 0x19151e36160>],\n",
       " <a list of 8 Text xticklabel objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(get_mean_reward(rewards))\n",
    "plt.xticks([i*20 for i in range(8)], [i*1000 for i in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_explorer = SoftmaxExplorer(deepcopy(base_algorithm), nchoices = nchoices, beta_prior=beta_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1836)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# batch size - algorithms will be refit after N rounds\n",
    "batch_size=50\n",
    "\n",
    "# initial seed - all policies start with the same small random selection of actions/rewards\n",
    "first_batch = X[:batch_size, :]\n",
    "# a choice for each batch \n",
    "action_chosen = np.random.randint(nchoices, size=batch_size)\n",
    "# reward of the chosen action\n",
    "rewards_received = y[np.arange(batch_size), action_chosen]\n",
    "\n",
    "print(first_batch.shape)\n",
    "print(action_chosen.shape)\n",
    "print(rewards_received.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SoftmaxExplorer at 0x235f58140b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models for the first time\n",
    "np.random.seed(123)\n",
    "softmax_explorer.fit(X=first_batch, a=action_chosen, r=rewards_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds are simulated from the full dataset\n",
    "def simulate_rounds(model, rewards, actions_hist, X_global, y_global, batch_st, batch_end):\n",
    "    np.random.seed(batch_st)\n",
    "    \n",
    "    ## choosing actions for this batch\n",
    "    actions_this_batch = model.predict(X_global[batch_st:batch_end, :]).astype('uint8')\n",
    "    \n",
    "    # keeping track of the sum of rewards received\n",
    "    rewards.append(y_global[np.arange(batch_st, batch_end), actions_this_batch].sum())\n",
    "    \n",
    "    # adding this batch to the history of selected actions\n",
    "    new_actions_hist = np.append(actions_hist, actions_this_batch)\n",
    "    \n",
    "    # now refitting the algorithms after observing these new rewards\n",
    "    np.random.seed(batch_st)\n",
    "    model.fit(X_global[:batch_end, :], new_actions_hist, y_global[np.arange(batch_end), new_actions_hist])\n",
    "    \n",
    "    return new_actions_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "# now running all the simulation\n",
    "for i in range(int(np.floor(X.shape[0] / batch_size))):\n",
    "    batch_st = (i + 1) * batch_size\n",
    "    batch_end = (i + 2) * batch_size\n",
    "    batch_end = np.min([batch_end, X.shape[0]])\n",
    "    \n",
    " \n",
    "    action_chosen = simulate_rounds(softmax_explorer,\n",
    "                                             rewards,\n",
    "                                             action_chosen,\n",
    "                                             X, y,\n",
    "                                             batch_st, batch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x2358df212e8>,\n",
       "  <matplotlib.axis.XTick at 0x2358df0bb70>,\n",
       "  <matplotlib.axis.XTick at 0x2358df0b860>,\n",
       "  <matplotlib.axis.XTick at 0x2358df476d8>,\n",
       "  <matplotlib.axis.XTick at 0x2358df47a58>,\n",
       "  <matplotlib.axis.XTick at 0x2358df47f28>,\n",
       "  <matplotlib.axis.XTick at 0x2358df5d438>,\n",
       "  <matplotlib.axis.XTick at 0x2358df5d908>],\n",
       " <a list of 8 Text xticklabel objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8lfX5//HXlUXYkJAge0aWKEJkVEUrYnFiHRW1itWW1q/aYRdW7bB22NpvW/vzq1Jx1QFKHTgoalUqDiTsDWFmMAKBMEL29fsjNzbGYA6QcM7JeT8fj/PIfT73577PdXNC3ue+78+5b3N3RERE4sJdgIiIRAYFgoiIAAoEEREJKBBERARQIIiISECBICIigAJBREQCCgQREQEUCCIiEkgIdwFHokOHDt6zZ89wlyEiElUWLFiw093T6usXVYHQs2dPsrKywl2GiEhUMbPNofTTISMREQEUCCIiElAgiIgIoEAQEZGAAkFERAAFgoiIBBQIIiICKBBERCKWu7Nwy27ueXUl5ZVVjf56UfXFNBGRpq7oYDnvrytg4eY9vLd2BxsKDpCcGMdlQ7twUpe2jfraCgQRkTDYW1LOvpIKOrRKouhgOQs27Wb2im3MWr6N0ooqmiXEMbR7e749ujcXDO5E6+TERq9JgSAicpyUVVTx8uI8Xl2Sz0frd1FR5Z+Z3zo5ga9lduPSU7twcte2JMYf36P6CgQRkQZWWeVs3HmArE2FLNyymzgzWjVL4I1lW8kvKqFXh5Z888ze9Extwc79pTRLiGdYz/ac1LktSQnhO7WrQBAROUazV2zjoffWU1JeSUWVs6WwmLKK6pPAKS2TiI8zdh8oY0i3dvz2ssGcdWIaZhbmqj9PgSAichSqqpyVW/fy2NyNvLgoj77prejdoSVxZozpn07f9Fac2r09fdJaYma4e0SGQE0KBBGRelRUVrEoZw/vr9vJyvwiCvaVsmlXMUUHy4mPM747JoPbzun7hcf8Iz0MQIEgIvIZhQfKmPKfDezYV0JGemu27y3h1SX57DpQRpxBRnprOrZN5vxObRjRO4XT+3QgvU1yuMtuEAoEEYl5lVXOsrwi3l65nSc/3MSBsgrSWjfjxYV5JCXEce6AdC46uTOn9+lA2xaNP/wzXBQIIhLT3l2zg7teWk7enoOYwZj+HfnpuH5kdGz96SGhVs1i409lbGyliEjA3Vm9bR+Lc/bwn7UFzFq+jb7prfjLVUMYfWIaKS2TPu3btnnT3RuoiwJBRJq8kvJKPlq/i7dXbeffq3awbW8JAG2SE7jtnL7cek5fmiXEh7nK8FMgiEiTVVJeyUPvrefv72+guKySFknxjM5I45wB6QzvmUKP1BZRMfrneFEgiEiTUVXlLMrZzccbCskpLOb9dTvJ23OQCwafwNcyuzGydyrJidoTOJyQAsHMxgF/BeKBR93997Xmjwb+ApwMTHD3GTXmVQLLgqdb3P2SoL0XMA1IARYC17l72bFtjojEqplL8vn1aysp2FcKQIdWSfRNb8X9V57CqD6pYa4uOtQbCGYWDzwIjAVygflmNtPdV9botgW4AfhRHas46O5D6mi/D/izu08zs4eBm4CHjrB+ERE+3rCL26cvZlCXttx14QDO7pcecyeEG0IoewjDgWx33wBgZtOA8cCngeDum4J5Id3BwaoP2p0DXBM0PQn8EgWCiNTjYFklZpCcGE9VlbM0r4jvPL2AHqkteOrG4QqCYxBKIHQBcmo8zwVGHMFrJJtZFlAB/N7dXwZSgT3uXlFjnV2OYJ0i0sRVVFbxwfpdvLF0K1v3lnCgtIK83QfZtrcEM+jctjnFZRXsLi6nfYtEpk48TWFwjEIJhLpOwXsdbYfT3d3zzaw38I6ZLQP2hrpOM5sETALo3r37EbysiESrt1Zu5+6Xl7NtbwmtkxPondaKVs3i+VLfVHqltqTKYePO/SQlxHFazxTO6pdGeuumcfmIcAolEHKBbjWedwXyQ30Bd88Pfm4ws/eAU4F/Au3MLCHYSzjsOt19CjAFIDMz80iCSESizOZdB/jTm2uZuSSf/ie05peXDOTsfukaGXSchBII84GMYFRQHjCB/x77/0Jm1h4odvdSM+sAnA78wd3dzN4FrqB6pNFE4JWj2QARiW5VVc68jYU8M28zbyzbSkJcHN8bk8EtX+4b1pvFxKJ6A8HdK8zsVmA21cNOH3P3FWZ2D5Dl7jPN7DTgJaA9cLGZ/crdBwEDgEeCk81xVJ9DOHQy+qfANDO7F1gETG3wrRORiFJSXsmyvCI6Bod3XlqUx4yFOeQUHqR1swS+Nbo3N53eq8lcPTTamHv0HIXJzMz0rKyscJchIkdh1/5Sbnh8Psvyij5tM4Mv9UnlymHd+MqgE2iepENDjcHMFrh7Zn399E1lEWl0G3ce4KYn5pO35yC//epg4uPgQGkl5w3qSNf2LcJdngQUCCLS4Fbm72V9wX4S4405awt4ISuX5knxPP3NEZzWMyXc5clhKBBE5Ji9tXI7y/OKMIM5awtYtGXPp/OS4uO4dkR3/ufLfemocwMRTYEgIsfkg+ydfOup/57b653Wkp9fNJDT+3agsspJb9OMDq2ahbFCCZUCQUSOWlFxOT98fgm901ry2m1nkBQfR3yc6ZLSUUqBICJH5UBpBT+esYSd+0t56frTaZGkPyfRTu+giByRqipnxsJc7p+9hh37SrnzggEM7to23GVJA1AgiEhI3J2P1u/iN2+sYkX+XoZ0a8dDXx/GsB7tw12aNBAFgogcVmlFJUtyipi7roCZS/LZtKuYLu2a88DVp3LxyZ10rqCJUSCISJ3eXb2DW55dSHFw/4FRvVO5+ew+jB/SRReba6IUCCLyOVt2FfPdaYvokdqSH5ybwWk9U2jfMincZUkjUyCIyGeUlFdy8zMLMGDKdcPolqJLS8QKBYKIfOqj9bu46+VlrC84wNSJmQqDGKNAEBGqqpzfzVrF39/fSLeU5jzxjdM4u196uMuS40yBIBLjSsor+cH0xcxavo3rRvbgzgsH6KRxjFIgiMSwwgNlfOupLBZs3s1dFw7gpjN6aShpDFMgiMQgd2dF/l5ue24ReXsO8uA1Q7nw5E7hLkvCTIEgEkPKKqp4eM56ps/PIW/PQdq1SOQZ3aNAAgoEkRixMn8vtz+/mNXb9nHWiWncek5fxg7sqEtTy6cUCCIxYN32fVz1yEckJ8Xz6PWZnDuwY7hLkgikQBBpgioqq3hz5XbaNU+kd1orbnxyPs0S43n5ltPp0q55uMuTCBVSIJjZOOCvQDzwqLv/vtb80cBfgJOBCe4+I2gfAjwEtAEqgd+4+/Rg3hPAWUBRsJob3H3xsW6QSKz7eMMufjlzBau37QPArPo2ltO/PUphIF+o3kAws3jgQWAskAvMN7OZ7r6yRrctwA3Aj2otXgxc7+7rzKwzsMDMZrv7oRuu/vhQeIjIsdladJDfvrGaV5fk06Vdcx68ZiiJ8cZ/1hUwpn9HhnRrF+4SJcKFsocwHMh29w0AZjYNGA98GgjuvimYV1VzQXdfW2M638x2AGnAHkSkwby1cjvfm7aIyirne2My+M5ZfWieVP3lsvMGnRDm6iRaxIXQpwuQU+N5btB2RMxsOJAErK/R/BszW2pmfzYzDXUQOULuzhMfbGTSP7LISG/F27efxQ/GnvhpGIgciVD2EOr62qIfyYuYWSfgH8BEdz+0F3EHsI3qkJgC/BS4p45lJwGTALp3734kLyvSZO0tKefxuZt4cVEum3cVM3ZgR/46YYjuayzHJJTfnlygW43nXYH8UF/AzNoArwN3ufvHh9rdfWswWWpmj/P58w+H+k2hOjDIzMw8oiASaYpWbd3LzU8vYHNhMaN6p/LdczK49NQuxMfpkhNybEIJhPlAhpn1AvKACcA1oazczJKAl4Cn3P2FWvM6uftWq75wyqXA8iOqXCQGfZi9kxufnE+b5ESe//YofcNYGlS95xDcvQK4FZgNrAKed/cVZnaPmV0CYGanmVkucCXwiJmtCBb/GjAauMHMFgePIcG8Z8xsGbAM6ADc26BbJtLEFJdV8JN/LqVzu+a8/t0zFQbS4EI64OjubwBv1Gr7eY3p+VQfSqq93NPA04dZ5zlHVKlIjPvr2+vI3X2Q6ZNGktZaYzCk4YUyykhEwmzRlt08OncjV2V2Y0Tv1HCXI02UhiSIRLDKKufR9zfwpzfXktaqGXdc0D/cJUkTpkAQiUALNhfy3Cc5zFlbQMG+Ur4yqCO/+epg2rVICndp0oQpEEQiSFlFFX95ey0PzVlPm+REzszowEUnd+YrgzrqTmbS6BQIIhGitKKSGx6bz0cbdjHhtG7cfdFAWjbTf1E5fvTbJhIBqqqcH7+wlI827OKPV5zMlZnd6l9IpIFplJFImLk79/1rNTOX5POTcf0UBhI22kMQCaOKyirufmU5z32Sw9dHdufms/qEuySJYQoEkTDZVlTC5BeX8t6aAm75ch9+dF4/nTiWsFIgiBxn7s4z87bw+1mrKa+s4t5LT+LrI3uEuywRBYLI8VRV5dz7+ioe+2AjZ2Z04N5LT6JHastwlyUCKBBEjpvyyip+9uIyXliQyzdO78ndFw4kTpeslgiiQBA5DnbtL+V/nlnIvI2FfG9MBt8/N0PnCyTiKBBEGpG7M2v5Nu59bSW7DpTxl6uGcOmpR3wHWpHjQoEg0ghKyiuZtXwrj83dxLK8IjLSW/HwdcM4uWu7cJcmclgKBJEG9u9V27n9+SUUHSynR2oL/njFyVw2tKtucSkRT4Eg0oDeXb2Dm59eSL8TWnPH+f0Z2TtVJ44laigQRBrI60u38oPnF3PiCa14+psjaNs8MdwliRwRBYLIMSopr+TXr63kmXlbGNKtHU984zSFgUQlBYLIMXh75XZ+9doKcgoP8u2zevOj8/qRGK9rRkp0UiCIHIWKyiomv7iMGQty6Zveime/NYIv9ekQ7rJEjklIH2XMbJyZrTGzbDObXMf80Wa20MwqzOyKWvMmmtm64DGxRvswM1sWrPMB07d0JEqUlFfynacXMmNBLred05dZ3ztTYSBNQr2BYGbxwIPA+cBA4GozG1ir2xbgBuDZWsumAL8ARgDDgV+YWftg9kPAJCAjeIw76q0QOU7cne8+t4i3V23nnvGD+KEOEUkTEspv8nAg2903uHsZMA0YX7ODu29y96VAVa1lvwK85e6F7r4beAsYZ2adgDbu/pG7O/AUcOmxboxIY3shK5c3V27nZxf05/pRPcNdjkiDCiUQugA5NZ7nBm2hONyyXYLpo1mnSFjkFBbzq1dXMKp3Kt88o3e4yxFpcKEEQl3H9j3E9R9u2ZDXaWaTzCzLzLIKCgpCfFmRhlVRWcUPpi8mzoz7v3aKvmwmTVIogZAL1LzJa1cgP8T1H27Z3GC63nW6+xR3z3T3zLS0tBBfVqRh3f/mWrI27+ber55El3bNw12OSKMIJRDmAxlm1svMkoAJwMwQ1z8bOM/M2gcnk88DZrv7VmCfmY0MRhddD7xyFPWLNLp3Vm/n4TnruWZEd8YP0ZFNabrqDQR3rwBupfqP+yrgeXdfYWb3mNklAGZ2mpnlAlcCj5jZimDZQuDXVIfKfOCeoA3gZuBRIBtYD8xq0C0TaQDvrN7Orc8uYmCnNvz8otqD60SaFqse5BMdMjMzPSsrK9xlSIx4+uPN/PyV5Qzs3IbHJp5GepvkcJckclTMbIG7Z9bXT99UFqnD3HU7uevl5Yzpn87frjmVFkn6ryJNn37LRWopPFDG7c8vpm96K/7fNUNpnhQf7pJEjgt9xVKkhsoq5yczlrKnuJy/ThiiMJCYokAQCZRWVHLbcwt5e9V2Jp/fn0Gd24a7JJHjSoeMRICi4nJueXYhc7N3cteFA7jxjF7hLknkuFMgSMxbkV/EzU8vZGvRQe6/8hSuGNa1/oVEmiAFgsS0lfl7uez/PqR9iySmTRrFsB7t619IpIlSIEjMcnd+/spyWjZL4NXbziCtdbNwlyQSVjqpLDHr5cV5ZG3ezU/H9VMYiKBAkBi1t6Sc376xmlO6tuXKYd3qX0AkBuiQkcScyirnB9MWU3igjEevz9SlrEUC2kOQmHPfv1bz79U7+OXFAzmlW7twlyMSMRQIElPeXrmdKf/ZwPWjenCdboEp8hkKBIkZ7s4D76yjZ2oL7talrEU+R4EgMeOj9btYmlvEpNF9SIzXr75IbfpfITHjoTnr6dCqGZcN1V3PROqiQJCYsCK/iPfX7eQbp/ckOVFXMBWpiwJBYsKf31pL62YJfH1kj3CXIhKxFAjS5H2ysZC3V+3gO2f3oW3zxHCXIxKxFAjSpLk7v5u1ihPaJHPj6bqktcgXUSBIkzZjQS6LtuzhB2MzdPczkXqEFAhmNs7M1phZtplNrmN+MzObHsyfZ2Y9g/ZrzWxxjUeVmQ0J5r0XrPPQvPSG3DCJbRWVVfzhX6v58YylDOvRnsuH6h4HIvWp91pGZhYPPAiMBXKB+WY2091X1uh2E7Db3fua2QTgPuAqd38GeCZYz2DgFXdfXGO5a909q4G2ReRTd760nOlZOVw9vDu/uHggCfregUi9QvlfMhzIdvcN7l4GTAPG1+ozHngymJ4BjDGz2lcMuxp47liKFQnFh9k7mZ6Vw7dH9+Z3lw3WMFOREIUSCF2AnBrPc4O2Ovu4ewVQBKTW6nMVnw+Ex4PDRXfXESAiR6ykvJI7X15Oj9QW/GDsieEuRySqhBIIdf2h9iPpY2YjgGJ3X15j/rXuPhg4M3hcV+eLm00ysywzyyooKAihXIll//duNht3HuA3l2rPQORIhRIIuUDNO4h0BfIP18fMEoC2QGGN+ROotXfg7nnBz33As1Qfmvocd5/i7pnunpmWlhZCuRKr1m3fx0Nz1vPVU7twRkaHcJcjEnVCCYT5QIaZ9TKzJKr/uM+s1WcmMDGYvgJ4x90dwMzigCupPvdA0JZgZh2C6UTgImA5Ikepqsr52UvLaJGUwJ0XDgh3OSJRqd5RRu5eYWa3ArOBeOAxd19hZvcAWe4+E5gK/MPMsqneM5hQYxWjgVx331CjrRkwOwiDeOBt4O8NskUSk57PymH+pt3cd/lgOrTS/ZFFjoYFH+SjQmZmpmdlaZSqfNa+knLO+uN79E1rxfRvj0TjE0Q+y8wWuHtmff00OFui3qPvb6TwQBl3XjhAYSByDBQIEtV27i/l0fc3cMHgE3R/ZJFjpECQqPb/3smmpKKKH57XL9yliEQ9BYJEreV5Rfzj4818LbMbfdJahbsckainQJCoVF5ZxU9mLKV9iyR+Ok57ByINod5hpyKRaMp/NrBy614e/vpQ2rVICnc5Ik2C9hAk6uTtOchf/72OcYNOYNxJncJdjkiToUCQqHP/7DUYcPfFA8NdikiTokCQqLIst4iXFuVx0xm96NKuebjLEWlSFAgSNdyde19fSWrLJG4+u0+4yxFpchQIEjUefDebeRsL+eF5/WidnBjuckSaHAWCRIW3V27nT2+tZfyQzlw9vFv9C4jIEVMgSMTbsbeE709fzKDObbjv8pN1vSKRRqJAkIg39YONFJdV8Lerh+ouaCKNSIEgEa3oYDnPfLyFC0/uTK8OLcNdjkiTpkCQiPb0x5vZX1rBd87qHe5SRJo8BYJErG1FJTz+wUbOOjGNQZ3bhrsckSZP1zKSiLNzfyl/enMNMxbk4g7fHdM33CWJxAQFgkSUd9fs4McvLGHvwQomnNadSaN70y2lRbjLEokJCgSJGP9ckMsPX1hCv46teeabI+l3QutwlyQSUxQIEhFyCov5+SvLGdErhSdvHK7hpSJhENJJZTMbZ2ZrzCzbzCbXMb+ZmU0P5s8zs55Be08zO2hmi4PHwzWWGWZmy4JlHjB92yhmVVY5P3xhCXFm/OlrpygMRMKk3kAws3jgQeB8YCBwtZnVvu7wTcBud+8L/Bm4r8a89e4+JHh8p0b7Q8AkICN4jDv6zZBoNnXuBj7ZWMgvLhlE1/Y6XyASLqHsIQwHst19g7uXAdOA8bX6jAeeDKZnAGO+6BO/mXUC2rj7R+7uwFPApUdcvUS9Ndv2cf/stZw3sCOXD+0S7nJEYloogdAFyKnxPDdoq7OPu1cARUBqMK+XmS0yszlmdmaN/rn1rFOauLKKKr4/fTFtmifwu8sG6xpFImEWyknluv6Xeoh9tgLd3X2XmQ0DXjazQSGus3rFZpOoPrRE9+7dQyhXIt3+0gpmLs7n+awcVm3dy9+vzyS1VbNwlyUS80IJhFyg5vWGuwL5h+mTa2YJQFugMDgcVArg7gvMbD1wYtC/az3rJFhuCjAFIDMzs87QkOixr6Scqx75mJVb99InrSX3XnoSYwd2DHdZIkJogTAfyDCzXkAeMAG4plafmcBE4CPgCuAdd3czS6M6GCrNrDfVJ483uHuhme0zs5HAPOB64G8Ns0kSqcoqqrj56YWs2b6Ph78+jK8M6qjDRCIRpN5AcPcKM7sVmA3EA4+5+wozuwfIcveZwFTgH2aWDRRSHRoAo4F7zKwCqAS+4+6FwbybgSeA5sCs4CFNVFWV85MZS5ibvZM/XnEy4046IdwliUgtVn1UJzpkZmZ6VlZWuMuQo/C7Wat4ZM4GfnTeidx6Tka4yxGJKWa2wN0z6+unq51Ko3vqo008MmcDXx/ZnVu+rAvViUQqBYI0qqLicn4/azVnnZjGry45SecMRCKYAkEa1TOfbKa4rJKfjutPfJzCQCSSKRCk0ZRWVPL4B5s4M6MDAzu3CXc5IlIPBYI0mlcW51Owr5RJo3X7S5FooECQRrFrfykPvpvNgE5tOKNvh3CXIyIh0P0QpMEVHijj2kfnsa2ohH/cNEInkkWihPYQpEGVlFdy3dR5bNx5gKkTT2N4r5RwlyQiIdIegjSoX726khX5e5k6MZMzMnSoSCSaaA9BGsyrS/J57pMt3Hx2H8YM0AXrRKKNAkEaxOZdB7jjxWUM7d6O28eeGO5yROQoKBDkmJVVVHHbc4uIM3jg6lNJjNevlUg00jkEOWb3/Ws1S3OLeOS6YbonskgU00c5OSbzNuxi6tyNTBzVg68M0iWtRaKZAkGOWmWV88tXV9K5bTKTzx8Q7nJE5BgpEOSoTZ9ffU/kn104gOZJ8eEuR0SOkQJBjsreknLuf3MNw3ulcOHgTuEuR0QagAJBjsr0T3IoPFDGXRcO0KUpRJoIBYIcscoq5x8fb2Z4zxRO7tou3OWISANRIMgRm7N2B1sKi7n+Sz3CXYqINCAFghyxJz/cTHrrZhpmKtLEhBQIZjbOzNaYWbaZTa5jfjMzmx7Mn2dmPYP2sWa2wMyWBT/PqbHMe8E6FweP9IbaKGk8i3P2MGdtAdeO6KFvJIs0MfV+U9nM4oEHgbFALjDfzGa6+8oa3W4Cdrt7XzObANwHXAXsBC5293wzOwmYDXSpsdy17p7VQNsijcjdmT4/h5/PXMEJbZK5dmT3cJckIg0slI94w4Fsd9/g7mXANGB8rT7jgSeD6RnAGDMzd1/k7vlB+wog2cyaNUThcnw9/fFmJr+4jBG9Unjtu2fQoZXeRpGmJpRA6ALk1Hiey2c/5X+mj7tXAEVAaq0+lwOL3L20RtvjweGiu01jFyPWzv2l/GH2Gs7M6MAT3xiuMBBpokIJhLr+UPuR9DGzQVQfRvp2jfnXuvtg4MzgcV2dL242ycyyzCyroKAghHKlof3hX6spKa/kl5cMIj5OuS3SVIUSCLlAtxrPuwL5h+tjZglAW6AweN4VeAm43t3XH1rA3fOCn/uAZ6k+NPU57j7F3TPdPTMtLS2UbZIGtGDzbp7PyuXGM3rRJ61VuMsRkUYUSiDMBzLMrJeZJQETgJm1+swEJgbTVwDvuLubWTvgdeAOd//gUGczSzCzDsF0InARsPzYNkUa2taig/zPMwvo0q45t52TEe5yRKSR1RsIwTmBW6keIbQKeN7dV5jZPWZ2SdBtKpBqZtnA7cChoam3An2Bu2sNL20GzDazpcBiIA/4e0NumByb/aUV3PhEFgdKK3l0YiatmunWGSJNnbnXPh0QuTIzMz0rS6NUG9N/1hbw7LwtzM3eycHySqZOzOTsfvqKiEg0M7MF7p5ZXz997BMAtu8t4d7XV/HqknzSWzfj4lM689VTuzC8V0q4SxOR40SBEMPcndeXbeW5T7bw0fpdJMTFcfvYE/n2Wb1plqD7G4jEGgVCDHJ3dh0o4+6XlzNr+TZ6prbgli/35YphXemR2jLc5YlImCgQmrDte0v42YvLyC8q4WBZBcVllRwsq+RAWQVVDonxxuTz+/OtM3vr+wUiokBoCjYU7OeNZVvJ7JlCZo/2JMTHUVJeyaSnsli3Yz9f6pNKi6QEWiTF0zwpnpZJCTRPimfMgHT6n9Am3OWLSIRQIES5JTl7uOHxT9hdXA5ASsskxvRPp/BAGUvziphyXSZjB3YMc5UiEg0UCFGkorKKssoqWiQl4O68tnQrk/+5lJRWSTzzzZFs2nWA2Su28a8V29hXUsFPx/VXGIhIyBQIYVZSXskfZ6+hT1orLhzcibYtEuvsN2dtAXe+tIxtRSWM6pPKgdIKFm7Zw0ld2jB14ml0bJPMwM5tuGBwJ8oqqti06wAZ6brUhIiELiYDYfaKbby8KI+/XX0qCWG+ycvvZ63miQ83AfDLV1dw7oB0Lju1K2f1SyMxPo7dB8r49WsreXFRHr3TWnLDl3ry79U7KCmv5L7LB3PFsG6fOyGclBDHiR1bh2FrRCSaxWQgvLliO7OWb+OlRXlcmdmt/gUayburd/DEh5u44Us9uXxoV/65MJeZS/J5Y9k22iQncFa/dD7M3knRwXJuO6cvt3y5L8mJ8dx10cCw1SwiTVdMBkJOYTEAf/33OsYP6UJSQuPtJeTtOcj6HfsZ3iuF5MR43J0V+XuZs7aAqXM30v+E1kw+vz/JifEM7tqWOy8cwJw1Bcxavo13Vm+nV4eW/PaywRoNJCKNLjYDYXcx3VKak1N4kOnzt3DdqJ4Nuv6ig+XMWraVlxblMW9jIQBtmycyolcKi3L2ULCv+h5Bp3Rty5++NoTkxP9+KzjwOLVNAAAJTElEQVQxPo5zB3bkXJ0MFpHjLOYCobSikm17S/juORl8tH4XD7yTzQWDO5HaAHcBW55XxNS5G3l92VbKKqro3aElPxx7Iv07tWHmknwWbCpkRK8Uzu6XzugTO5DeOrkBtkhEpGHEXCDk7T6IO3RPacHYgR25/KEP+eZTWTz3rZGf+aR+JBZu2c3/vrmWudk7aZkUz9WndePyYV0Z3KUth+4MquGfIhLpYi4QcnYfBKBbSgtO6tKWv04Yws3PLOT70xbzt2tOJfEIRh3l7i7m16+tZPaK7aS2TOJnF/RnwvDutEmue+ioiEgki71ACE4od0tpDsC4kzpx14UD+fVrK5kw5WMevGYoJ7T94kM5VVXOo3M38Oe31gHwo/NO5Bun96KlbiIjIlEs5v6C5ewuJik+jo41jt/fdEYv0lo3Y/I/l3LhA+/zk3H9PjO+f1tRCT96YQndUppzweBOPDJnA3Ozd3LugI78avwgurRrHq7NERFpMLEXCIXFdG3fnLhaX+a65JTODOzUmh/PWMpP/7mMqXM38q0ze3Nq93bc+EQWBftKWbB5N899kkNyYhy/v2wwV53W7dNzBCIi0S4GA+EgXVNa1Dmvb3prXrz5S8xavo3/fWstP56xFIA2yQk8N2kkfdJa8t6aAgZ1bkPvNF0WQkSaltgLhN3FnNKt7WHnmxkXDO7E+SedwMcbCnlj2VauHt6dgZ2rvxh28Smdj1epIiLHVUwFwt6ScvYUl9Otfd17CDWZGaP6pDKqT+pxqExEJPxCGmNpZuPMbI2ZZZvZ5DrmNzOz6cH8eWbWs8a8O4L2NWb2lVDX2Rj+O8Ko/kAQEYk19QaCmcUDDwLnAwOBq82s9tXVbgJ2u3tf4M/AfcGyA4EJwCBgHPB/ZhYf4jobXE5h8B2EEPYQRERiTSh7CMOBbHff4O5lwDRgfK0+44Eng+kZwBirHn4zHpjm7qXuvhHIDtYXyjob3KE9hO7aQxAR+ZxQziF0AXJqPM8FRhyuj7tXmFkRkBq0f1xr2S7BdH3rbDB3vrSMTzYWsnN/Ka2TEw57ExoRkVgWSiDUNdDeQ+xzuPa69kxqr7N6xWaTgEkA3bt3P3yVX6Bzu+ZkdGxFRsdWZPZIOap1iIg0daEEQi5Q8y4yXYH8w/TJNbMEoC1QWM+y9a0TAHefAkwByMzMrDM06nPLl/sezWIiIjEllHMI84EMM+tlZklUnySeWavPTGBiMH0F8I67e9A+IRiF1AvIAD4JcZ0iInIc1buHEJwTuBWYDcQDj7n7CjO7B8hy95nAVOAfZpZN9Z7BhGDZFWb2PLASqABucfdKgLrW2fCbJyIiobLqD/LRITMz07OyssJdhohIVDGzBe6eWV+/xruZsIiIRBUFgoiIAAoEEREJKBBERARQIIiISCCqRhmZWQGw+SgX7wDsbMByGks01BkNNYLqbGjRUGc01AjHv84e7p5WX6eoCoRjYWZZoQy7CrdoqDMaagTV2dCioc5oqBEit04dMhIREUCBICIigVgKhCnhLiBE0VBnNNQIqrOhRUOd0VAjRGidMXMOQUREvlgs7SGIiMgXiIlAMLNxZrbGzLLNbPJxfu3HzGyHmS2v0ZZiZm+Z2brgZ/ug3czsgaDOpWY2tMYyE4P+68xsYl2vdYx1djOzd81slZmtMLPvRVqtZpZsZp+Y2ZKgxl8F7b3MbF7wetODS6oTXHZ9elDjPDPrWWNddwTta8zsKw1VY616481skZm9Fql1mtkmM1tmZovNLCtoi5j3PFh3OzObYWarg9/PURFYY7/g3/DQY6+ZfT/S6qyXuzfpB9WX114P9AaSgCXAwOP4+qOBocDyGm1/ACYH05OB+4LpC4BZVN9pbiQwL2hPATYEP9sH0+0buM5OwNBgujWwFhgYSbUGr9UqmE4E5gWv/TwwIWh/GLg5mP4f4OFgegIwPZgeGPweNAN6Bb8f8Y3w3t8OPAu8FjyPuDqBTUCHWm0R854H638S+GYwnQS0i7Qaa9UbD2wDekRynXXWfrxeKFwPYBQwu8bzO4A7jnMNPflsIKwBOgXTnYA1wfQjwNW1+wFXA4/UaP9Mv0aq+RVgbKTWCrQAFlJ9L+6dQELt95vq+22MCqYTgn5W+3egZr8GrK8r8G/gHOC14HUjsc5NfD4QIuY9B9oAGwnOd0ZijXXUfB7wQaTXWdcjFg4ZdQFyajzPDdrCqaO7bwUIfqYH7Yer9bhuQ3DI4lSqP4FHVK3BYZjFwA7gLao/Ne9x94o6Xu/TWoL5RUBqY9cY+AvwE6AqeJ4aoXU68KaZLbDq+5dDZL3nvYEC4PHg8NujZtYywmqsbQLwXDAdyXV+TiwEgtXRFqlDqw5X63HbBjNrBfwT+L677/2iroepqVFrdfdKdx9C9Sfw4cCAL3i9sNRoZhcBO9x9Qc3mL3jNcL7vp7v7UOB84BYzG/0FfcNRZwLVh1wfcvdTgQNUH3o5nLD+HwrOC10CvFBf18PUE9a/V7EQCLlAtxrPuwL5YarlkO1m1gkg+LkjaD9crcdlG8wskeoweMbdX4zkWt19D/Ae1cdf25nZodvB1ny9T2sJ5rel+havjV3j6cAlZrYJmEb1YaO/RGCduHt+8HMH8BLVIRtJ73kukOvu84LnM6gOiEiqsabzgYXuvj14Hql11ikWAmE+kBGM8EiienduZphrmgkcGj0wkerj9Yfarw9GIIwEioLdzNnAeWbWPhilcF7Q1mDMzKi+N/Yqd//fSKzVzNLMrF0w3Rw4F1gFvAtccZgaD9V+BfCOVx+YnQlMCEb39AIygE8aokYAd7/D3bu6e0+qf9/ecfdrI61OM2tpZq0PTVP9Xi0ngt5zd98G5JhZv6BpDNX3aI+YGmu5mv8eLjpUTyTWWbfjdbIinA+qz+ivpfp4853H+bWfA7YC5VSn/01UHx/+N7Au+JkS9DXgwaDOZUBmjfXcCGQHj280Qp1nUL1ruhRYHDwuiKRagZOBRUGNy4GfB+29qf5DmU31rnqzoD05eJ4dzO9dY113BrWvAc5vxPf/bP47yiii6gzqWRI8Vhz6vxFJ73mw7iFAVvC+v0z16JuIqjFYfwtgF9C2RlvE1flFD31TWUREgNg4ZCQiIiFQIIiICKBAEBGRgAJBREQABYKIiAQUCCIiAigQREQkoEAQEREA/j+1BGr5b5YAlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "def get_mean_reward(reward_lst, batch_size=batch_size):\n",
    "    mean_rew=list()\n",
    "    for r in range(len(reward_lst)):\n",
    "        mean_rew.append(sum(reward_lst[:r+1]) * 1.0 / ((r+1)*batch_size))\n",
    "    return mean_rew\n",
    "plt.plot(get_mean_reward(rewards))\n",
    "plt.xticks([i*20 for i in range(8)], [i*1000 for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bootstrapped TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BootstrappedClassifierBase:\n",
    "    \n",
    "    def __init__(self, base, nsamples, percentile = 80):\n",
    "        self.bs_algos = [deepcopy(base) for n in range(nsamples)]\n",
    "        self.nsamples = nsamples\n",
    "        self.percentile = percentile\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        ix_take_all = np.random.randint(X.shape[0], size = (X.shape[0], self.nsamples))\n",
    "        for sample in range(self.nsamples):\n",
    "            self._fit_single(sample, ix_take_all, X, y) \n",
    "            \n",
    "    # for each bootstapped resample \n",
    "    def _fit_single(self, sample, ix_take_all, X, y):\n",
    "        ix_take = ix_take_all[:, sample]\n",
    "        xsample = X[ix_take, :]\n",
    "        ysample = y[ix_take]\n",
    "        nclass = ysample.sum()\n",
    "        \n",
    "        if nclass == ysample.shape[0]:\n",
    "            self.bs_algos[sample] = _OnePredictor()\n",
    "            return None\n",
    "            \n",
    "        self.bs_algos[sample].fit(xsample, ysample)\n",
    "\n",
    "#     def partial_fit(self, X, y, classes=None):\n",
    "#         if self.partial_method == \"gamma\":\n",
    "#             w_all = np.random.gamma(1, 1, size = (X.shape[0], self.nsamples))\n",
    "#             appear_times = None\n",
    "#             rng = None\n",
    "#         elif self.partial_method == \"poisson\":\n",
    "#             w_all = None\n",
    "#             appear_times = np.random.poisson(1, size = (X.shape[0], self.nsamples))\n",
    "#             rng = np.arange(X.shape[0])\n",
    "#         else:\n",
    "#             raise ValueError(_unexpected_err_msg)\n",
    "#         Parallel(n_jobs=self.njobs, verbose=0, require=\"sharedmem\")(delayed(self._partial_fit_single)(sample, w_all, appear_times, rng, X, y) for sample in range(self.nsamples))\n",
    "\n",
    "#     def _partial_fit_single(self, sample, w_all, appear_times_all, rng, X, y):\n",
    "#         if w_all is not None:\n",
    "#             self.bs_algos[sample].partial_fit(X, y, classes=[0, 1], sample_weight=w_all[:, sample])\n",
    "#         elif appear_times_all is not None:\n",
    "#             appear_times = np.repeat(rng, appear_times_all[:, sample])\n",
    "#             xsample = X[appear_times]\n",
    "#             ysample = y[appear_times]\n",
    "#             self.bs_algos[sample].partial_fit(xsample, ysample, classes = [0, 1])\n",
    "#         else:\n",
    "#             raise ValueError(_unexpected_err_msg)\n",
    "    # for bootstrapped UCB\n",
    "    def _score_max(self, X):\n",
    "        pred = np.empty((X.shape[0], self.nsamples))\n",
    "        for sample in range(self.nsamples):\n",
    "            self._assign_score(sample, pred, X) \n",
    "        return np.percentile(pred, self.percentile, axis=1)\n",
    "\n",
    "    def _score_avg(self, X):\n",
    "        ### Note: don't try to make it more memory efficient by summing to a single array,\n",
    "        ### as otherwise it won't be multithreaded.\n",
    "        pred = np.empty((X.shape[0], self.nsamples))\n",
    "        for sample in range(self.nsamples):\n",
    "            self._assign_score(sample, pred, X) \n",
    "        return pred.mean(axis = 1)\n",
    "    \n",
    "    # the probability estimates for all the classes \n",
    "    def _assign_score(self, sample, pred, X):\n",
    "        pred[:, sample] = self._get_score(sample, X)\n",
    "    # for bootstrapped thompson sampling\n",
    "    def _score_rnd(self, X):\n",
    "        chosen_sample = np.random.randint(self.nsamples)\n",
    "        return self._get_score(chosen_sample, X)\n",
    "\n",
    "    def exploit(self, X):\n",
    "        return self._score_avg(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        ### Thompson sampling\n",
    "        if self.percentile is None:\n",
    "            pred = self._score_rnd(X)\n",
    "\n",
    "        ### Upper confidence bound\n",
    "        else:\n",
    "            pred = self._score_max(X)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "\n",
    "class _BootstrappedClassifier_w_predict_proba(_BootstrappedClassifierBase):\n",
    "    def _get_score(self, sample, X):\n",
    "        # probability of getting 1 \n",
    "        return self.bs_algos[sample].predict_proba(X)[:, 1]\n",
    "\n",
    "class _BootstrappedClassifier_w_decision_function(_BootstrappedClassifierBase):\n",
    "    def _get_score(self, sample, X):\n",
    "        pred = self.bs_algos[sample].decision_function(X).reshape(-1)\n",
    "        _apply_sigmoid(pred)\n",
    "        return pred\n",
    "\n",
    "class _BootstrappedClassifier_w_predict(_BootstrappedClassifierBase):\n",
    "    def _get_score(self, sample, X):\n",
    "        return self.bs_algos[sample].predict(X).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BasePolicyWithExploit(_BasePolicy):\n",
    "    def _add_bootstrapped_inputs(self, base_algorithm, nsamples, percentile):\n",
    "        #assert (batch_sample_method == 'gamma') or (batch_sample_method == 'poisson')\n",
    "        assert isinstance(nsamples, int)\n",
    "        assert nsamples >= 2\n",
    "        #self.batch_sample_method = batch_sample_method\n",
    "        self.nsamples = nsamples\n",
    "        #self.njobs_samples = _check_njobs(njobs_samples)   base, nsamples, percentile = 80\n",
    "        if \"predict_proba\" in dir(base_algorithm):\n",
    "            self.base_algorithm = _BootstrappedClassifier_w_predict_proba(\n",
    "                base_algorithm, self.nsamples, percentile)\n",
    "        elif \"decision_function\" in dir(base_algorithm):\n",
    "            self.base_algorithm = _BootstrappedClassifier_w_decision_function(\n",
    "                base_algorithm, self.nsamples, percentile)\n",
    "        else:\n",
    "            self.base_algorithm = _BootstrappedClassifier_w_predict(\n",
    "                base_algorithm, self.nsamples, percentile)\n",
    "\n",
    "    def exploit(self, X):\n",
    "        return self._oracles.exploit(X)\n",
    "\n",
    "    def predict(self, X, exploit = False, output_score = False):\n",
    "        \"\"\"\n",
    "        Selects actions according to this policy for new data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array (n_samples, n_features)\n",
    "            New observations for which to choose an action according to this policy.\n",
    "        exploit : bool\n",
    "            Whether to make a prediction according to the policy, or to just choose the\n",
    "            arm with the highest expected reward according to current models.\n",
    "        output_score : bool\n",
    "            Whether to output the score that this method predicted, in case it is desired to use\n",
    "            it with this pakckage's offpolicy and evaluation modules.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pred : array (n_samples,) or dict(\"choice\" : array(n_samples,), \"score\" : array(n_samples,))\n",
    "            Actions chosen by the policy. If passing output_score=True, it will be a dictionary\n",
    "            with the chosen arm and the score that the arm got following this policy with the classifiers used.\n",
    "        \"\"\"\n",
    "        if exploit:\n",
    "            scores = self.exploit(X)\n",
    "        else:\n",
    "            scores = self.decision_function(X)\n",
    "        pred = self._name_arms(np.argmax(scores, axis = 1))\n",
    "\n",
    "        if not output_score:\n",
    "            return pred\n",
    "        else:\n",
    "            score_max = np.max(scores, axis=1).reshape((-1, 1))\n",
    "            return {\"choice\" : pred, \"score\" : score_max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrappedTS(_BasePolicyWithExploit):\n",
    "    \"\"\"\n",
    "    Bootstrapped Thompson Sampling\n",
    "    \n",
    "    Performs Thompson Sampling by fitting several models per class on bootstrapped samples,\n",
    "    then makes predictions by taking one of them at random for each class.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    When fitting the algorithm to data in batches (online), it's not possible to take an\n",
    "    exact bootstrapped sample, as the sample is not known in advance. In theory, as the sample size\n",
    "    grows to infinity, the number of times that an observation appears in a bootstrapped sample is\n",
    "    distributed ~ Poisson(1). However, I've found that assigning random weights to observations\n",
    "    produces a more stable effect, so it also has the option to assign weights randomly ~ Gamma(1,1).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_algorithm : obj\n",
    "        Base binary classifier for which each sample for each class will be fit.\n",
    "        Will look for, in this order:\n",
    "            1) A 'predict_proba' method with outputs (n_samples, 2), values in [0,1], rows suming to 1\n",
    "            2) A 'decision_function' method with unbounded outputs (n_samples,) to which it will apply a sigmoid function.\n",
    "            3) A 'predict' method with outputs (n_samples,) with values in [0,1].\n",
    "        Can also pass a list with a different (or already-fit) classifier for each arm.\n",
    "    nchoices : int or list-like\n",
    "        Number of arms/labels to choose from. Can also pass a list, array or series with arm names, in which case\n",
    "        the outputs from predict will follow these names and arms can be dropped by name, and new ones added with a\n",
    "        custom name.\n",
    "    nsamples : int\n",
    "        Number of bootstrapped samples per class to take.\n",
    "    beta_prior : str 'auto', None, or tuple ((a,b), n)\n",
    "        If not None, when there are less than 'n' positive samples from a class\n",
    "        (actions from that arm that resulted in a reward), it will predict the score\n",
    "        for that class as a random number drawn from a beta distribution with the prior\n",
    "        specified by 'a' and 'b'. If set to auto, will be calculated as:\n",
    "        beta_prior = ((3/nchoices, 4), 2)\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    smoothing : None or tuple (a,b)\n",
    "        If not None, predictions will be smoothed as yhat_smooth = (yhat*n + a)/(n + b),\n",
    "        where 'n' is the number of times each arm was chosen in the training data.\n",
    "        This will not work well with non-probabilistic classifiers such as SVM, in which case you might\n",
    "        want to define a class that embeds it with some recalibration built-in.\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    batch_train : bool\n",
    "        Whether the base algorithm will be fit to the data in batches as it comes (online),\n",
    "        or to the whole dataset each time it is refit. Requires a classifier with a\n",
    "        'partial_fit' method.\n",
    "    assume_unique_reward : bool\n",
    "        Whether to assume that only one arm has a reward per observation. If set to False,\n",
    "        whenever an arm receives a reward, the classifiers for all other arms will be\n",
    "        fit to that observation too, having negative label.\n",
    "    batch_sample_method : str, either 'gamma' or 'poisson'\n",
    "        How to simulate bootstrapped samples when training in batch mode (online).\n",
    "        See Note.\n",
    "    njobs_arms : int or None\n",
    "        Number of parallel jobs to run (for dividing work across arms). If passing None will set it to 1.\n",
    "        If passing -1 will set it to the number of CPU cores. Note that if the base algorithm is itself\n",
    "        parallelized, this might result in a slowdown as both compete for available threads, so don't set\n",
    "        parallelization in both. The total number of parallel jobs will be njobs_arms * njobs_samples.\n",
    "    njobs_samples : int or None\n",
    "        Number of parallel jobs to run (for dividing work across samples within one arm). If passing None\n",
    "        will set it to 1. If passing -1 will set it to the number of CPU cores. The total number of parallel\n",
    "        jobs will be njobs_arms * njobs_samples.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [1] Cortes, David. \"Adapting multi-armed bandits policies to contextual bandits scenarios.\"\n",
    "        arXiv preprint arXiv:1811.04383 (2018).\n",
    "    [2] Chapelle, Olivier, and Lihong Li. \"An empirical evaluation of thompson sampling.\"\n",
    "        Advances in neural information processing systems. 2011.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_algorithm, nchoices, nsamples=10, beta_prior='auto'):\n",
    "    \n",
    "        self._add_common_params(base_algorithm, beta_prior, nchoices)\n",
    "        base_algorithm, nsamples, percentile\n",
    "        self._add_bootstrapped_inputs(base_algorithm, nsamples, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrappedUCB(_BasePolicyWithExploit):\n",
    "    \"\"\"\n",
    "    Bootstrapped Upper Confidence Bound\n",
    "    Obtains an upper confidence bound by taking the percentile of the predictions from a\n",
    "    set of classifiers, all fit with different bootstrapped samples (multiple samples per arm).\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    When fitting the algorithm to data in batches (online), it's not possible to take an\n",
    "    exact bootstrapped sample, as the sample is not known in advance. In theory, as the sample size\n",
    "    grows to infinity, the number of times that an observation appears in a bootstrapped sample is\n",
    "    distributed ~ Poisson(1). However, I've found that assigning random weights to observations\n",
    "    produces a more stable effect, so it also has the option to assign weights randomly ~ Gamma(1,1).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_algorithm : obj or list\n",
    "        Base binary classifier for which each sample for each class will be fit.\n",
    "        Will look for, in this order:\n",
    "            1) A 'predict_proba' method with outputs (n_samples, 2), values in [0,1], rows suming to 1\n",
    "            2) A 'decision_function' method with unbounded outputs (n_samples,) to which it will apply a sigmoid function.\n",
    "            3) A 'predict' method with outputs (n_samples,) with values in [0,1].\n",
    "        Can also pass a list with a different (or already-fit) classifier for each arm.\n",
    "    nchoices : int or list-like\n",
    "        Number of arms/labels to choose from. Can also pass a list, array or series with arm names, in which case\n",
    "        the outputs from predict will follow these names and arms can be dropped by name, and new ones added with a\n",
    "        custom name.\n",
    "    nsamples : int\n",
    "        Number of bootstrapped samples per class to take.\n",
    "    percentile : int [0,100]\n",
    "        Percentile of the predictions sample to take\n",
    "    beta_prior : str 'auto', None, or tuple ((a,b), n)\n",
    "        If not None, when there are less than 'n' positive samples from a class\n",
    "        (actions from that arm that resulted in a reward), it will predict the score\n",
    "        for that class as a random number drawn from a beta distribution with the prior\n",
    "        specified by 'a' and 'b'. If set to auto, will be calculated as:\n",
    "        beta_prior = ((5/nchoices, 4), 2)\n",
    "        Note that it will only generate one random number per arm, so the 'a' parameters should be higher\n",
    "        than for other methods.\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    smoothing : None or tuple (a,b)\n",
    "        If not None, predictions will be smoothed as yhat_smooth = (yhat*n + a)/(n + b),\n",
    "        where 'n' is the number of times each arm was chosen in the training data.\n",
    "        This will not work well with non-probabilistic classifiers such as SVM, in which case you might\n",
    "        want to define a class that embeds it with some recalibration built-in.\n",
    "        Recommended to use only one of 'beta_prior' or 'smoothing'.\n",
    "    batch_train : bool\n",
    "        Whether the base algorithm will be fit to the data in batches as it comes (online),\n",
    "        or to the whole dataset each time it is refit. Requires a classifier with a\n",
    "        'partial_fit' method.\n",
    "    assume_unique_reward : bool\n",
    "        Whether to assume that only one arm has a reward per observation. If set to False,\n",
    "        whenever an arm receives a reward, the classifiers for all other arms will be\n",
    "        fit to that observation too, having negative label.\n",
    "    batch_sample_method : str, either 'gamma' or 'poisson'\n",
    "        How to simulate bootstrapped samples when training in batch mode (online).\n",
    "        See Note.\n",
    "    njobs_arms : int or None\n",
    "        Number of parallel jobs to run (for dividing work across arms). If passing None will set it to 1.\n",
    "        If passing -1 will set it to the number of CPU cores. Note that if the base algorithm is itself\n",
    "        parallelized, this might result in a slowdown as both compete for available threads, so don't set\n",
    "        parallelization in both. The total number of parallel jobs will be njobs_arms * njobs_samples.\n",
    "    njobs_samples : int or None\n",
    "        Number of parallel jobs to run (for dividing work across samples within one arm). If passing None\n",
    "        will set it to 1. If passing -1 will set it to the number of CPU cores. The total number of parallel\n",
    "        jobs will be njobs_arms * njobs_samples.\n",
    "    References\n",
    "    ----------\n",
    "    [1] Cortes, David. \"Adapting multi-armed bandits policies to contextual bandits scenarios.\"\n",
    "        arXiv preprint arXiv:1811.04383 (2018).\n",
    "        \"\"\"\n",
    "    def __init__(self, base_algorithm, nchoices, nsamples=10, percentile=80,\n",
    "                 beta_prior='auto'):\n",
    "        assert (percentile >= 0) and (percentile <= 100)\n",
    "        self._add_common_params(base_algorithm, beta_prior, nchoices)\n",
    "        self.percentile = percentile\n",
    "        self._add_bootstrapped_inputs(base_algorithm, nsamples,elf.percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lints, linucb, bayesiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BayesianLogisticRegression:\n",
    "    def __init__(self,params,nchoices):\n",
    "        self.params = params\n",
    "        self.nchoices = nchoices\n",
    "        \n",
    "        sef.lambda_prior = self.params['lambda_prior']\n",
    "        \n",
    "        self.mu = [\n",
    "            np.zeros(self.params['context_dim']+1)\n",
    "            for _ in range(self.nchoices)\n",
    "        ]\n",
    "        \n",
    "        self.mu = [\n",
    "            np.zeros(self.params['context_dim']+1)<\n",
    "            for _ in range(self.nchoices)\n",
    "        ]\n",
    "        \n",
    "        self.cov = [(1.0 / self.lambda_prior) * np.eye(self.params['context_dim'] + 1)\n",
    "                for _ in range(self.nchoices)]\n",
    "\n",
    "        self.precision = [\n",
    "        self.lambda_prior * np.eye(self.params['context_dim'] + 1)\n",
    "        for _ in range(self.nchoices)\n",
    "        ]\n",
    "        \n",
    "        self._a0 = self.a0\n",
    "        self._b0 = self.b0\n",
    "        self.a = [self._a0 for _ in range(self.nchoices)]\n",
    "        self.b = [self._a0 for _ in range(self.nchoices)]\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
