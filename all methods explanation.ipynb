{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section1: Data Sampler\n",
    "\n",
    "> 1.1 Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/data/data_sampler.py' \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def one_hot(df, cols):\n",
    "    \n",
    "    \"\"\"Returns one-hot encoding of DataFrame df including columns in cols.\"\"\"\n",
    "    for col in cols:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mushroom Dataset (Schlimmer, 1981) contains 22 attributes per mushroom, and\n",
    "two classes: poisonous and safe. As in Blundell et al. (2015), we create a bandit problem where the\n",
    "agent must decide whether to eat or not a given mushroom. Eating a safe mushroom provides reward\n",
    "+5. Eating a poisonous mushroom delivers reward +5 with probability 1/2 and reward -35 otherwise.\n",
    "If the agent does not eat a mushroom, then the reward is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/data/data_sampler.py' \n",
    "def sample_mushroom_data(file_name,\n",
    "                         num_contexts,\n",
    "                         r_noeat=0,\n",
    "                         r_eat_safe=5,\n",
    "                         r_eat_poison_bad=-35,\n",
    "                         r_eat_poison_good=5,\n",
    "                         prob_poison_bad=0.5):\n",
    "    \"\"\"Samples bandit game from Mushroom UCI Dataset.\n",
    "    Args:\n",
    "    file_name: Route of file containing the original Mushroom UCI dataset.\n",
    "    num_contexts: Number of points to sample, i.e. (context, action rewards).\n",
    "    r_noeat: Reward for not eating a mushroom.\n",
    "    r_eat_safe: Reward for eating a non-poisonous mushroom.\n",
    "    r_eat_poison_bad: Reward for eating a poisonous mushroom if harmed.\n",
    "    r_eat_poison_good: Reward for eating a poisonous mushroom if not harmed.\n",
    "    prob_poison_bad: Probability of being harmed by eating a poisonous mushroom.\n",
    "    Returns:\n",
    "    dataset: Sampled matrix with n rows: (context, eat_reward, no_eat_reward).\n",
    "    opt_vals: Vector of expected optimal (reward, action) for each context.\n",
    "    We assume r_eat_safe > r_noeat, and r_eat_poison_good > r_eat_poison_bad.\n",
    "    ###########\n",
    "    after one hot encoding\n",
    "    first column: edibale or not\n",
    "    second column: poisonious or not\n",
    "    column 2: : context\n",
    "    \"\"\"\n",
    "\n",
    "    # first two cols of df encode whether mushroom is edible or poisonous\n",
    "    df = pd.read_csv(file_name)\n",
    "    df = one_hot(df, df.columns)\n",
    "    ind = np.random.choice(range(df.shape[0]), num_contexts, replace=True)\n",
    "\n",
    "    contexts = df.iloc[ind, 2:]\n",
    "    no_eat_reward = r_noeat * np.ones((num_contexts, 1))\n",
    "    random_poison = np.random.choice(\n",
    "      [r_eat_poison_bad, r_eat_poison_good],\n",
    "      p=[prob_poison_bad, 1 - prob_poison_bad],\n",
    "      size=num_contexts)\n",
    "    eat_reward = r_eat_safe * df.iloc[ind, 0]\n",
    "    eat_reward += np.multiply(random_poison, df.iloc[ind, 1])\n",
    "    eat_reward = eat_reward.values.reshape((num_contexts, 1))\n",
    "\n",
    "    # compute optimal expected reward and optimal actions\n",
    "    exp_eat_poison_reward = r_eat_poison_bad * prob_poison_bad\n",
    "    exp_eat_poison_reward += r_eat_poison_good * (1 - prob_poison_bad)\n",
    "    opt_exp_reward = r_eat_safe * df.iloc[ind, 0] + max(\n",
    "      r_noeat, exp_eat_poison_reward) * df.iloc[ind, 1]\n",
    "\n",
    "    if r_noeat > exp_eat_poison_reward:\n",
    "    # actions: no eat = 0 ; eat = 1\n",
    "        # eat only edible mushrooms\n",
    "        opt_actions = df.iloc[ind, 0]  # indicator of edible\n",
    "    else:\n",
    "        # should always eat (higher expected reward)\n",
    "        \n",
    "        opt_actions = np.ones((num_contexts, 1))\n",
    "\n",
    "    opt_vals = (opt_exp_reward.values, opt_actions.values)\n",
    "\n",
    "    return np.hstack((contexts.values, no_eat_reward, eat_reward)), opt_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.2 Census\n",
    "\n",
    "The US Census (1990) Dataset (Asuncion & Newman, 2007) contains a number of personal\n",
    "features (age, native language, education...) which we summarize in d = 389 covariates, including\n",
    "binary dummy variables for categorical features. Our goal again is to predict the occupation of the\n",
    "individual among k = 9 classes. The agent obtains reward 1 for making the right prediction, and 0\n",
    "otherwise, for each of the n = 250000 randomly selected data points.\n",
    "\n",
    "source: https://archive.ics.uci.edu/ml/machine-learning-databases/census1990-mld/ (USCensus1990.data.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/data/data_sampler.py' \n",
    "def sample_census_data(file_name, num_contexts, shuffle_rows=True):\n",
    "    \"\"\"Returns bandit problem dataset based on the UCI census data.\n",
    "    Args:\n",
    "    file_name: Route of file containing the Census dataset.\n",
    "    num_contexts: Number of contexts to sample.\n",
    "    shuffle_rows: If True, rows from original dataset are shuffled.\n",
    "    remove_underrepresented: If True, removes arms with very few rewards.\n",
    "    Returns:\n",
    "    dataset: Sampled matrix with rows: (context, action rewards).\n",
    "    opt_vals: Vector of deterministic optimal (reward, action) for each context.\n",
    "    Preprocessing:\n",
    "    * drop rows with missing labels\n",
    "    * convert categorical variables to 1 hot encoding\n",
    "    Note: this is the processed (not the 'raw') dataset. It contains a subset\n",
    "    of the raw features and they've all been discretized.\n",
    "\n",
    "    \"\"\"\n",
    "    # 'USCensus1990.data.txt'\n",
    "    df = pd.read_csv(file_name, sep=\",\")\n",
    "\n",
    "    num_actions = 9\n",
    "\n",
    "    if shuffle_rows:\n",
    "        df = df.sample(frac=1)\n",
    "    df = df.iloc[:num_contexts, :]\n",
    "\n",
    "    # Assuming what the paper calls response variable is the label?\n",
    "    labels = df['dOccup'].astype('category').cat.codes.as_matrix()\n",
    "    # In addition to label, also drop the (unique?) key.\n",
    "    df = df.drop(['dOccup', 'caseid'], axis=1)\n",
    "\n",
    "    # All columns are categorical. Convert to 1 hot encoding.\n",
    "    df = pd.get_dummies(df, columns=df.columns)\n",
    "\n",
    "#     if remove_underrepresented:\n",
    "#         df, labels = remove_underrepresented_classes(df, labels)\n",
    "    contexts = df.as_matrix()\n",
    "\n",
    "    return classification_to_bandit_problem(contexts, labels, num_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.3 Adult\n",
    "\n",
    "The Adult Dataset (Kohavi, 1996; Asuncion & Newman, 2007) comprises personal information from the US Census Bureau database, and the standard prediction task is to determine if a person\n",
    "makes over $50K a year or not. However, we consider the k = 14 different occupations as feasible\n",
    "actions, based on d = 94 covariates (many of them binarized). As in previous datasets, the agent\n",
    "obtains reward 1 for making the right prediction, and 0 otherwise.\n",
    "\n",
    "source: https://archive.ics.uci.edu/ml/datasets/census+income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/data/data_sampler.py' \n",
    "def sample_adult_data(file_name, num_contexts, shuffle_rows=True):\n",
    "    \"\"\"Returns bandit problem dataset based on the UCI adult data.\n",
    "    Args:\n",
    "    file_name: Route of file containing the Adult dataset.\n",
    "    num_contexts: Number of contexts to sample.\n",
    "    shuffle_rows: If True, rows from original dataset are shuffled.\n",
    "    remove_underrepresented: If True, removes arms with very few rewards.\n",
    "    Returns:\n",
    "    dataset: Sampled matrix with rows: (context, action rewards).\n",
    "    opt_vals: Vector of deterministic optimal (reward, action) for each context.\n",
    "    Preprocessing:\n",
    "    * drop rows with missing values\n",
    "    * convert categorical variables to 1 hot encoding\n",
    "    \"\"\"\n",
    "    # adult.data\n",
    "    df = pd.read_csv(file_name, sep=\",\", header=None,\n",
    "                     na_values=[' ?']).dropna()\n",
    "\n",
    "    num_actions = 14\n",
    "\n",
    "    if shuffle_rows:\n",
    "        df = df.sample(frac=1)\n",
    "    df = df.iloc[:num_contexts, :]\n",
    "\n",
    "    labels = df[6].astype('category').cat.codes.as_matrix()\n",
    "    df = df.drop([6], axis=1)\n",
    "\n",
    "    # Convert categorical variables to 1 hot encoding\n",
    "    cols_to_transform = [1, 3, 5, 7, 8, 9, 13, 14]\n",
    "    df = pd.get_dummies(df, columns=cols_to_transform)\n",
    "\n",
    "#     if remove_underrepresented:\n",
    "#     df, labels = remove_underrepresented_classes(df, labels)\n",
    "    contexts = df.as_matrix()\n",
    "\n",
    "    return classification_to_bandit_problem(contexts, labels, num_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Core codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.1 Turning classificaion to a bandit problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/data/data_sampler.py' \n",
    "\n",
    "def safe_std(values):\n",
    "    \"\"\"Remove zero std values for ones.\"\"\"\n",
    "    return np.array([val if val != 0.0 else 1.0 for val in values])\n",
    "\n",
    "def classification_to_bandit_problem(contexts, labels, num_actions=None):\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "      Normalize contexts and encode deterministic rewards.\n",
    "         returns (third output): optimal reward(always 1) and optimal actions(the labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    if num_actions is None:\n",
    "        num_actions = np.max(labels) + 1\n",
    "    num_contexts = contexts.shape[0]\n",
    "\n",
    "    # Due to random subsampling in small problems, some features may be constant\n",
    "    sstd = safe_std(np.std(contexts, axis=0, keepdims=True)[0, :])\n",
    "\n",
    "    # Normalize features\n",
    "    contexts = ((contexts - np.mean(contexts, axis=0, keepdims=True)) / sstd)\n",
    "\n",
    "    # One hot encode labels as rewards\n",
    "    rewards = np.zeros((num_contexts, num_actions))\n",
    "    rewards[np.arange(num_contexts), labels] = 1.0\n",
    "\n",
    "    return contexts, rewards, (np.ones(num_contexts), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.2 Creating a ContextualBandit object on which we can define some methods to feed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/core/contextual_bandit.py'\n",
    "class ContextualBandit(object):\n",
    "    \"\"\"Implements a Contextual Bandit with d-dimensional contexts and k arms.\"\"\"\n",
    "\n",
    "    def __init__(self, context_dim, num_actions):\n",
    "        \"\"\"Creates a contextual bandit object.\n",
    "        Args:\n",
    "          context_dim: Dimension of the contexts.\n",
    "          num_actions: Number of arms for the multi-armed bandit.\n",
    "        \"\"\"\n",
    "\n",
    "        self._context_dim = context_dim\n",
    "        self._num_actions = num_actions\n",
    "\n",
    "    def feed_data(self, data):\n",
    "        \"\"\"Feeds the data (contexts + rewards) to the bandit object.\n",
    "        Args:\n",
    "          data: Numpy array with shape [n, d+k], where n is the number of contexts,\n",
    "            d is the dimension of each context, and k the number of arms (rewards) ---> this is the output of sample_*_data\n",
    "        Raises:\n",
    "          ValueError: when data dimensions do not correspond to the object values.\n",
    "        \"\"\"\n",
    "\n",
    "        if data.shape[1] != self.context_dim + self.num_actions:\n",
    "            raise ValueError('Data dimensions do not match.')\n",
    "\n",
    "        self._number_contexts = data.shape[0]\n",
    "        self.data = data\n",
    "        self.order = range(self.number_contexts)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Randomly shuffle the order of the contexts to deliver.\"\"\"\n",
    "        self.order = np.random.permutation(self.number_contexts)\n",
    "\n",
    "    def context(self, number):\n",
    "        \"\"\"Returns the number-th context.\"\"\"\n",
    "        return self.data[self.order[number]][:self.context_dim]\n",
    "\n",
    "    def reward(self, number, action):\n",
    "        \"\"\"Returns the reward for the number-th context and action.\"\"\"\n",
    "        return self.data[self.order[number]][self.context_dim + action]\n",
    "\n",
    "    def optimal(self, number):\n",
    "        \"\"\"Returns the optimal action (in hindsight) for the number-th context.\"\"\"\n",
    "        return np.argmax(self.data[self.order[number]][self.context_dim:])\n",
    "\n",
    "    @property\n",
    "    def context_dim(self):\n",
    "        return self._context_dim\n",
    "\n",
    "    @property\n",
    "    def num_actions(self):\n",
    "        return self._num_actions\n",
    "\n",
    "    @property\n",
    "    def number_contexts(self):\n",
    "        return self._number_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.3 The abstract class for contextual bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/core/bandit_algorithm.py'\n",
    "class BanditAlgorithm(object):\n",
    "    \"\"\"A bandit algorithm must be able to do two basic operations.\n",
    "    1. Choose an action given a context.\n",
    "    2. Update its internal model given a triple (context, played action, reward).\n",
    "    \"\"\"\n",
    "\n",
    "    def action(self, context):\n",
    "        pass\n",
    "\n",
    "    def update(self, context, action, reward):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.4 The abstract class for Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/core/bayesian_nn.py' \n",
    "class BayesianNN(object):\n",
    "    \"\"\"A Bayesian neural network keeps a distribution over neural nets.\"\"\"\n",
    "\n",
    "    def __init__(self, optimizer):\n",
    "        pass\n",
    "\n",
    "    def build_model(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, data):\n",
    "        pass\n",
    "\n",
    "    def sample(self, steps):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.5 Creating ContextualDataset object on which we define some attributes and methods every algorithm needs to add data to or to query data from selected actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/core/contextual_dataset.py' \n",
    "class ContextualDataset(object):\n",
    "    \"\"\"The buffer is able to append new data, and sample random minibatches.\"\"\"\n",
    "\n",
    "    def __init__(self, context_dim, num_actions, buffer_s=-1, intercept=False):\n",
    "        \"\"\"Creates a ContextualDataset object.\n",
    "        The data is stored in attributes: contexts and rewards.\n",
    "        The sequence of taken actions are stored in attribute actions.\n",
    "        Args:\n",
    "          context_dim: Dimension of the contexts.\n",
    "          num_actions: Number of arms for the multi-armed bandit.\n",
    "          buffer_s: Size of buffer for training. Only last buffer_s will be\n",
    "            returned as minibatch. If buffer_s = -1, all data will be used.\n",
    "          intercept: If True, it adds a constant (1.0) dimension to each context X,\n",
    "            at the end.\n",
    "        \"\"\"\n",
    "\n",
    "        self._context_dim = context_dim\n",
    "        self._num_actions = num_actions\n",
    "        self._contexts = None\n",
    "        self._rewards = None\n",
    "        self.actions = []\n",
    "        self.buffer_s = buffer_s\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def add(self, context, action, reward):\n",
    "        \"\"\"Adds a new triplet (context, action, reward) to the dataset.---> online learning\n",
    "        The reward for the actions that weren't played is assumed to be zero.\n",
    "        Args:\n",
    "          context: A d-dimensional vector with the context.\n",
    "          action: Integer between 0 and k-1 representing the chosen arm.\n",
    "          reward: Real number representing the reward for the (context, action).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.intercept:\n",
    "\n",
    "            c = np.array(context[:])\n",
    "            c = np.append(c, 1.0).reshape((1, self.context_dim + 1))\n",
    "        else:\n",
    "            c = np.array(context[:]).reshape((1, self.context_dim))\n",
    "\n",
    "        if self.contexts is None:\n",
    "            self.contexts = c\n",
    "        else:\n",
    "            self.contexts = np.vstack((self.contexts, c))\n",
    "\n",
    "        r = np.zeros((1, self.num_actions))\n",
    "        r[0, action] = reward\n",
    "        if self.rewards is None:\n",
    "            self.rewards = r\n",
    "        else:\n",
    "            self.rewards = np.vstack((self.rewards, r))\n",
    "\n",
    "        self.actions.append(action)\n",
    "\n",
    "    def replace_data(self, contexts=None, actions=None, rewards=None):\n",
    "        if contexts is not None:\n",
    "            self.contexts = contexts\n",
    "        if actions is not None:\n",
    "            self.actions = actions\n",
    "        if rewards is not None:\n",
    "            self.rewards = rewards\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        \"\"\"Returns a random minibatch of (contexts, rewards) with batch_size.\"\"\"\n",
    "        n, _ = self.contexts.shape\n",
    "        if self.buffer_s == -1:\n",
    "          # use all the data\n",
    "            ind = np.random.choice(range(n), batch_size)\n",
    "        else:\n",
    "          # use only buffer (last buffer_s observations)\n",
    "            ind = np.random.choice(range(max(0, n - self.buffer_s), n), batch_size)\n",
    "        return self.contexts[ind, :], self.rewards[ind, :]\n",
    "\n",
    "    def get_data(self, action):\n",
    "        \"\"\"Returns all (context, reward) where the action was played.\"\"\"\n",
    "        n, _ = self.contexts.shape\n",
    "        ind = np.array([i for i in range(n) if self.actions[i] == action])\n",
    "        return self.contexts[ind, :], self.rewards[ind, action]\n",
    "\n",
    "    def get_data_with_weights(self):\n",
    "        \"\"\"Returns all observations with one-hot weights for actions. 1 for selected actions 0 otherwise.\"\"\"\n",
    "        weights = np.zeros((self.contexts.shape[0], self.num_actions))\n",
    "        a_ind = np.array([(i, val) for i, val in enumerate(self.actions)])\n",
    "        weights[a_ind[:, 0], a_ind[:, 1]] = 1.0\n",
    "        return self.contexts, self.rewards, weights\n",
    "\n",
    "    def get_batch_with_weights(self, batch_size):\n",
    "        \"\"\"Returns a random mini-batch with one-hot weights for actions.\"\"\"\n",
    "        n, _ = self.contexts.shape\n",
    "        if self.buffer_s == -1:\n",
    "          # use all the data\n",
    "            ind = np.random.choice(range(n), batch_size)\n",
    "        else:\n",
    "          # use only buffer (last buffer_s obs)\n",
    "            ind = np.random.choice(range(max(0, n - self.buffer_s), n), batch_size)\n",
    "\n",
    "        weights = np.zeros((batch_size, self.num_actions))\n",
    "        sampled_actions = np.array(self.actions)[ind]\n",
    "        a_ind = np.array([(i, val) for i, val in enumerate(sampled_actions)])\n",
    "        weights[a_ind[:, 0], a_ind[:, 1]] = 1.0\n",
    "        return self.contexts[ind, :], self.rewards[ind, :], weights\n",
    "\n",
    "    def num_points(self, f=None):\n",
    "        \"\"\"Returns number of points in the buffer (after applying function f).\"\"\"\n",
    "        if f is not None:\n",
    "            return f(self.contexts.shape[0])\n",
    "        return self.contexts.shape[0]\n",
    "\n",
    "    @property\n",
    "    def context_dim(self):\n",
    "        return self._context_dim\n",
    "\n",
    "    @property\n",
    "    def num_actions(self):\n",
    "        return self._num_actions\n",
    "\n",
    "    @property\n",
    "    def contexts(self):\n",
    "        return self._contexts\n",
    "\n",
    "    @contexts.setter\n",
    "    def contexts(self, value):\n",
    "        self._contexts = value\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self._actions\n",
    "\n",
    "    @actions.setter\n",
    "    def actions(self, value):\n",
    "        self._actions = value\n",
    "\n",
    "    @property\n",
    "    def rewards(self):\n",
    "        return self._rewards\n",
    "\n",
    "    @rewards.setter\n",
    "    def rewards(self, value):\n",
    "        self._rewards = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.1 Linear contextual bandit Thompson Sampling \n",
    "\n",
    "Performs Bayesian linear regression for exact posterior inference in linear models:\n",
    "    \n",
    "Assuming the reward $Y_a$ for each action(arm) a given context $X_t$ at round t is obtained by:\n",
    "$$Y_a = {X_t}^T \\beta_a + \\epsilon_a $$ with $\\epsilon_a \\sim N(0,\\sigma_a^2)$  Thus:\n",
    "\n",
    "$$p(Y_a|\\beta_a,\\sigma_i^2,X_a) \\sim N(X_a^T \\beta_a,\\sigma_a^2)$$\n",
    "\n",
    "and according to Bayes theorem the posterior at time t for action i after observing context X_i and reward Y_i is obtained by:\n",
    "\n",
    "$$\n",
    " \\begin{aligned}\n",
    "    p_t(\\beta_a,\\sigma_a^2|Y_i,X_i) &= p_t(\\beta_a,\\sigma_a^2) \\times p_t(Y_a|\\beta_a,\\sigma_a^2,X_a)\\\\\n",
    "    &=p_t(\\beta_a|\\sigma_a^2)p_t(\\sigma_a^2)p_t(Y_a|\\beta_a,\\sigma_a^2,X_a)\n",
    " \\end{aligned}\n",
    "$$\n",
    "\n",
    "where we assume $p_0(\\sigma_a^2) \\sim IG(a_0 ,b_0)$ and $p_0(\\beta_a|\\sigma_a^2) \\sim N(\\mu_0,\\sigma_a^2 \\Sigma_0)$.\n",
    "Here, we take $\\Sigma_0 = \\sigma_0^2 \\frac{1}{\\lambda} Id$ and $\\Lambda_0 = \\lambda Id$\n",
    "therefore, the above formula gives us the inference for the posterior parameters as :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma_t & = {(X_a^T X + \\Lambda_0)}^{-1} \\\\\n",
    "\\mu_t &= \\Sigma_t(\\Lambda_0 \\mu_0 + X_a^TY_a)\\\\\n",
    "a_t &= a_0 + t/2\\\\\n",
    "b_t &= b_0 + 1/2 (Y_a^TY_a+\\mu_0^T \\Sigma_0 \\mu_0 - \\mu_t^T \\Sigma_t^{-1} \\mu_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/linear_thompson_sampling.py' \n",
    "class LinTS(BanditAlgorithm):\n",
    "    \"\"\"Bayesian Linear Regression\"\"\"\n",
    "    \n",
    "    def __init__(self, name, hparams):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          name: Name of the algorithm.\n",
    "          hparams: Hyper-parameters of the algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.hparams = hparams\n",
    "\n",
    "        # Gaussian prior for each beta_i: zero mean\n",
    "        self._lambda_prior = self.hparams.lambda_prior #\\lambda\n",
    "\n",
    "        self.mu = [\n",
    "            np.zeros(self.hparams.context_dim + 1)\n",
    "            for _ in range(self.hparams.num_actions)\n",
    "        ]\n",
    "\n",
    "        self.cov = [(1.0 / self.lambda_prior) * np.eye(self.hparams.context_dim + 1)\n",
    "                    for _ in range(self.hparams.num_actions)] \n",
    "\n",
    "        self.precision = [\n",
    "            self.lambda_prior * np.eye(self.hparams.context_dim + 1)\n",
    "            for _ in range(self.hparams.num_actions)\n",
    "        ] # \\Lambda_0\n",
    "\n",
    "        # Inverse Gamma prior for each sigma2_i\n",
    "        self._a0 = self.hparams.a0\n",
    "        self._b0 = self.hparams.b0\n",
    "\n",
    "        self.a = [self._a0 for _ in range(self.hparams.num_actions)]\n",
    "        self.b = [self._b0 for _ in range(self.hparams.num_actions)]\n",
    "\n",
    "        self.t = 0\n",
    "        self.data_h = ContextualDataset(hparams.context_dim,\n",
    "                                        hparams.num_actions,\n",
    "                                        intercept=True)\n",
    "\n",
    "    def action(self, context):\n",
    "        \"\"\"for given context Samples beta's from posterior, and chooses action with maximum X^T \\beta_i + \\epsilon_i.\n",
    "        Args:\n",
    "          context: Context for which the action need to be chosen.\n",
    "        Returns:\n",
    "          action: Selected action for the context.\n",
    "        \"\"\"\n",
    "\n",
    "        # Round robin until each action has been selected \"initial_pulls\" times\n",
    "        if self.t < self.hparams.num_actions * self.hparams.initial_pulls:\n",
    "            return self.t % self.hparams.num_actions\n",
    "\n",
    "        # Sample sigma2, and beta conditional on sigma2\n",
    "        sigma2_s = [\n",
    "            self.b[i] * invgamma.rvs(self.a[i])\n",
    "            for i in range(self.hparams.num_actions)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            beta_s = [\n",
    "                np.random.multivariate_normal(self.mu[i], sigma2_s[i] * self.cov[i])\n",
    "                for i in range(self.hparams.num_actions)\n",
    "            ]\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            # Sampling could fail if covariance is not positive definite\n",
    "            print('Exception when sampling from {}.'.format(self.name))\n",
    "            print('Details: {} | {}.'.format(e.message, e.args))\n",
    "            d = self.hparams.context_dim + 1\n",
    "            beta_s = [\n",
    "                  np.random.multivariate_normal(np.zeros((d)), np.eye(d))\n",
    "                  for i in range(self.hparams.num_actions)\n",
    "              ]\n",
    "\n",
    "        # Compute sampled expected values, intercept is last component of beta\n",
    "        vals = [\n",
    "            np.dot(beta_s[i][:-1], context.T) + beta_s[i][-1]\n",
    "            for i in range(self.hparams.num_actions)\n",
    "        ]\n",
    "\n",
    "        return np.argmax(vals)\n",
    "\n",
    "    def update(self, context, action, reward):\n",
    "        \"\"\"Updates action posterior using the linear Bayesian regression formula.\n",
    "        Args:\n",
    "          context: Last observed context.\n",
    "          action: Last observed action.\n",
    "          reward: Last observed reward.\n",
    "        \"\"\"\n",
    "\n",
    "        self.t += 1\n",
    "        self.data_h.add(context, action, reward)\n",
    "\n",
    "        # Update posterior of action with formulas: \\beta | x,y ~ N(mu_q, cov_q) with the observed data from that action\n",
    "        x, y = self.data_h.get_data(action)\n",
    "\n",
    "        # The algorithm could be improved with sequential update formulas (cheaper)\n",
    "        s = np.dot(x.T, x)\n",
    "\n",
    "        # Some terms are removed as we assume prior mu_0 = 0.\n",
    "        precision_a = s + self.lambda_prior * np.eye(self.hparams.context_dim + 1)\n",
    "        cov_a = np.linalg.inv(precision_a)\n",
    "        mu_a = np.dot(cov_a, np.dot(x.T, y))\n",
    "\n",
    "        # Inverse Gamma posterior update\n",
    "        a_post = self.a0 + x.shape[0] / 2.0\n",
    "        b_upd = 0.5 * (np.dot(y.T, y) - np.dot(mu_a.T, np.dot(precision_a, mu_a)))\n",
    "        b_post = self.b0 + b_upd\n",
    "\n",
    "        # Store new posterior distributions\n",
    "        self.mu[action] = mu_a\n",
    "        self.cov[action] = cov_a\n",
    "        self.precision[action] = precision_a\n",
    "        self.a[action] = a_post\n",
    "        self.b[action] = b_post\n",
    "\n",
    "    @property\n",
    "    def a0(self):\n",
    "        return self._a0\n",
    "\n",
    "    @property\n",
    "    def b0(self):\n",
    "        return self._b0\n",
    "\n",
    "    @property\n",
    "    def lambda_prior(self):\n",
    "        return self._lambda_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/linucb.py' \n",
    "class LinUcb(BanditAlgorithm):\n",
    "    def __init__(self, name, hparams):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          name: Name of the algorithm.\n",
    "          hparams: Hyper-parameters of the algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.hparams = hparams\n",
    "\n",
    "        # Gaussian prior for each beta_i: zero mean\n",
    "        self._alpha = self.hparams.alpha #\\lambda\n",
    "\n",
    "        self.b = [\n",
    "            np.zeros(self.hparams.context_dim)\n",
    "            for _ in range(self.hparams.num_actions)\n",
    "        ]\n",
    "\n",
    "        self.Ainv = [np.eye(self.hparams.context_dim)\n",
    "                    for _ in range(self.hparams.num_actions)] \n",
    "\n",
    "       \n",
    "\n",
    "       \n",
    "        self.data_h = ContextualDataset(hparams.context_dim,\n",
    "                                        hparams.num_actions,\n",
    "                                        intercept=True)\n",
    "        \n",
    "    def action(self, context):\n",
    "        \"\"\"for given context Samples beta's from posterior, and chooses action with maximum X^T \\beta_i + \\epsilon_i.\n",
    "        Args:\n",
    "          context: Context for which the action need to be chosen.\n",
    "        Returns:\n",
    "          action: Selected action for the context.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        preds = [\n",
    "            self.Ainv[i].dot(self.b[i]).T.dot(context)\n",
    "            for i in range(self.hparams.num_actions)\n",
    "        ]\n",
    "        \n",
    "        cbs = [\n",
    "            self.alpha * np.sqrt(np.linalg.multi_dot([context.T, self.Ainv[i], context]))\n",
    "            for i in range(self.hparams.num_actions)\n",
    "            \n",
    "        ]\n",
    "\n",
    "        \n",
    "        # Compute sampled expected values, intercept is last component of beta\n",
    "        vals = [\n",
    "            preds[i]+cbs[i]\n",
    "            for i in range(self.hparams.num_actions)\n",
    "        ]\n",
    "\n",
    "        return np.argmax(vals)\n",
    "    \n",
    "    def update(self, context, action, reward):\n",
    "        \n",
    "        \n",
    "        self.Ainv[action] -= np.linalg.multi_dot([self.Ainv[action], context.reshape(-1,1), context.reshape(-1,1).T,self.Ainv[action]]) / \\\n",
    "                             (1.0 + np.linalg.multi_dot([context, self.Ainv[action], context]))\n",
    "        self.b[action] = self.b[action] + np.dot(context.T, reward)\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self._alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.2: Stochastic variational  inference (bayes by back-propagation)\n",
    "\n",
    "Bayesian inference for neural networks calculates the posterior distribution of the weights given the training data ($x,y$),\n",
    "$P(w|y,x) = \\frac{P(y|x,w)P(w)}{P(y|x)}$. This distribution answers predictive queries\n",
    "about unseen data by taking expectations: the predictive\n",
    "distribution of an unknown label $\\hat{y}$ of a test data item $\\hat{x}$,\n",
    "is given by $P(\\hat{y}|\\hat{x},x,y) = E_{P(w|y,x)}[P(\\hat{y}|\\hat{x},w)]$\n",
    ". Each possible configuration of the weights, weighted according to\n",
    "the posterior distribution, makes a prediction about the unknown label given the test data item $\\hat{x}$.  Thus taking an\n",
    "expectation under the posterior distribution on weights is\n",
    "equivalent to using an ensemble of an uncountably infinite number of neural networks. Unfortunately, this is intractable for neural networks of any practical size.\n",
    "\n",
    "A solution to this problem is a variational approximation to the\n",
    "Bayesian posterior distribution on the weights. Variational\n",
    "learning finds the parameters $\\theta$ of a distribution on the\n",
    "weights $q(w|\\theta)$ that minimises the Kullback-Leibler (KL) between this distribution and $P(w|y,x)$ as the following:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta^* &= argmin_\\theta KL[q(w|\\theta)||P(w|y,x)]\\\\\n",
    "&=argmin_\\theta \\int q(w|\\theta) \\log \\frac{q(w|\\theta)}{P(y|x,w)P(w)} dw\\\\\n",
    "&=argmin_\\theta KL[q(w|\\theta)||P(w)] - E_{q(w|\\theta)} [\\log P(y|x,w)]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Suppose that the variational posterior is a diagonal Gaussian distribution, then a sample of the weights $w$ can be\n",
    "obtained by sampling a unit Gaussian, shifting it by a mean\n",
    "$\\mu$ and scaling by a standard deviation $\\sigma$.\n",
    "We parameterise\n",
    "the standard deviation pointwise as $\\sigma = \\log(1 + \\exp(\\rho))$\n",
    "and so $\\sigma$ is always non-negative. So, the variational posterior\n",
    "parameters are $\\theta = (\\mu, \\rho)$ and the transform from a sample of parameter-free noise and the variational posterior parameters that yields a posterior sample of the weights $w$ is $w=\\mu+\\log(1 + \\exp(\\rho)) \\circ \\epsilon$, where $\\circ$ is point-wise multiplication and $\\epsilon \\sim N(0,I)$.\n",
    "\n",
    "$\\theta = (\\mu, \\rho)$ can then be obtained by minimizing the following expression (Monte Carlo estiamtion of log-liklihood plus a KL divergence term that can be calculated analytically)\n",
    "as the loss function through stochastic gradient discent (mini-batches with replacement): \n",
    "\n",
    "$$f(w,\\theta) = \\sum_{i=1}^n(\\log q(w|\\theta) - \\log P(w) - \\log P(y^i|x^i,w=f(\\epsilon^i,\\theta)))$$ where $i$ is ampled from variationa posterior $N(\\mu,\\sigma^2)$\n",
    "\n",
    "References:\n",
    "\n",
    "https://arxiv.org/pdf/1505.05424.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1506.02557.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1802.09127.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### 3.2.1 First, we define the corresponding bayesian neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/variational_neural_bandit_model.py' \n",
    "# **some helper functions**\n",
    "def log_gaussian(x, mu, sigma, reduce_sum=True):\n",
    "    \"\"\"Returns log Gaussian pdf.\"\"\"\n",
    "    res = (-0.5 * np.log(2 * np.pi) - tf.log(sigma) - tf.square(x - mu) /\n",
    "         (2 * tf.square(sigma)))\n",
    "    if reduce_sum:\n",
    "        return tf.reduce_sum(res)\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def analytic_kl(mu_1, sigma_1, mu_2, sigma_2):\n",
    "    \"\"\"KL for two Gaussian distributions with diagonal covariance matrix.\"\"\"\n",
    "    sigma_1_sq = tf.square(sigma_1)\n",
    "    sigma_2_sq = tf.square(sigma_2)\n",
    "\n",
    "    t1 = tf.square(mu_1 - mu_2) / (2. * sigma_2_sq)\n",
    "    t2 = (sigma_1_sq/sigma_2_sq - 1. - tf.log(sigma_1_sq) + tf.log(sigma_2_sq))/2.\n",
    "    return tf.reduce_sum(t1 + t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/algorithms/variational_neural_bandit_model.py' \n",
    "\n",
    "class VariationalNeuralBanditModel(BayesianNN):\n",
    "    \n",
    "    \n",
    "    \"\"\"Implements an approximate Bayesian NN using Variational Inference.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, hparams, name=\"BBBNN\"):\n",
    "        \n",
    "\n",
    "\n",
    "        self.name = name\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.n_in = self.hparams.context_dim\n",
    "        self.n_out = self.hparams.num_actions\n",
    "        self.layers = self.hparams.layer_sizes\n",
    "        self.init_scale = self.hparams.init_scale\n",
    "        self.f_num_points = None\n",
    "        if \"f_num_points\" in hparams:\n",
    "            self.f_num_points = self.hparams.f_num_points\n",
    "\n",
    "        self.cleared_times_trained = self.hparams.cleared_times_trained\n",
    "        self.initial_training_steps = self.hparams.initial_training_steps \n",
    "        self.training_schedule = np.linspace(self.initial_training_steps,\n",
    "                                             self.hparams.training_epochs,\n",
    "                                             self.cleared_times_trained) # this t_s in the paper (number of mini-batches \n",
    "                                                                         # per training epoch)\n",
    "        self.verbose = getattr(self.hparams, \"verbose\", True)\n",
    "\n",
    "        self.weights_m = {}\n",
    "        self.weights_std = {}\n",
    "        self.biases_m = {}\n",
    "        self.biases_std = {}\n",
    "\n",
    "        self.times_trained = 0\n",
    "\n",
    "        if self.hparams.use_sigma_exp_transform:            \n",
    "            self.sigma_transform = tf.exp\n",
    "            self.inverse_sigma_transform = np.log\n",
    "        else:\n",
    "            self.sigma_transform = tf.nn.softplus\n",
    "            self.inverse_sigma_transform = lambda y: y + np.log(1. - np.exp(-y))\n",
    "\n",
    "        # Whether to use the local reparameterization trick to compute the loss.\n",
    "        # See details in https://arxiv.org/abs/1506.02557\n",
    "        self.use_local_reparameterization = True\n",
    "\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_mu_variable(self, shape):\n",
    "        \"\"\"Returns a mean variable initialized as N(0, 0.05).\"\"\"\n",
    "        return tf.Variable(tf.random_normal(shape, 0.0, 0.05))\n",
    "\n",
    "    def build_sigma_variable(self, shape, init=-5.):\n",
    "        \"\"\"Returns a sigma variable initialized as N(init, 0.05).\"\"\"\n",
    "    # Initialize sigma to be very small initially to encourage MAP opt first\n",
    "        return tf.Variable(tf.random_normal(shape, init, 0.05))\n",
    "\n",
    "    def build_layer(self, input_x, input_x_local, shape,\n",
    "                  layer_id, activation_fn=tf.nn.relu):\n",
    "        \"\"\"Builds a variational layer, and computes KL term.\n",
    "        Args:\n",
    "          input_x: Input to the variational layer.\n",
    "          input_x_local: Input when the local reparameterization trick was applied.\n",
    "          shape: [number_inputs, number_outputs] for the layer.\n",
    "          layer_id: Number of layer in the architecture.\n",
    "          activation_fn: Activation function to apply.\n",
    "        Returns:\n",
    "          output_h: Output of the variational layer.\n",
    "          output_h_local: Output when local reparameterization trick was applied.\n",
    "          neg_kl: Negative KL term for the layer.\n",
    "        \"\"\"\n",
    "\n",
    "        w_mu = self.build_mu_variable(shape)\n",
    "        w_sigma = self.sigma_transform(self.build_sigma_variable(shape))\n",
    "        w_noise = tf.random_normal(shape)\n",
    "        w = w_mu + w_sigma * w_noise\n",
    "\n",
    "        b_mu = self.build_mu_variable([1, shape[1]]) # bias for mu\n",
    "        b_sigma = self.sigma_transform(self.build_sigma_variable([1, shape[1]]))# bias for sigma\n",
    "        b = b_mu\n",
    "\n",
    "        # Store means and stds\n",
    "        self.weights_m[layer_id] = w_mu\n",
    "        self.weights_std[layer_id] = w_sigma\n",
    "        self.biases_m[layer_id] = b_mu\n",
    "        self.biases_std[layer_id] = b_sigma\n",
    "\n",
    "        # Create outputs\n",
    "        output_h = activation_fn(tf.matmul(input_x, w) + b)\n",
    "\n",
    "        if self.use_local_reparameterization:\n",
    "          # Use analytic KL divergence wrt the prior\n",
    "            neg_kl = -analytic_kl(w_mu, w_sigma,\n",
    "                                0., tf.to_float(np.sqrt(2./shape[0])))\n",
    "        else:\n",
    "              # Create empirical KL loss terms\n",
    "            log_p = log_gaussian(w, 0., tf.to_float(np.sqrt(2./shape[0])))\n",
    "            log_q = log_gaussian(w, tf.stop_gradient(w_mu), tf.stop_gradient(w_sigma))\n",
    "            neg_kl = log_p - log_q\n",
    "\n",
    "        # Apply local reparameterization trick: sample activations pre nonlinearity\n",
    "        m_h = tf.matmul(input_x_local, w_mu) + b  # \\gama_mj = \\sum a_mi * mu_i,j\n",
    "        v_h = tf.matmul(tf.square(input_x_local), tf.square(w_sigma)) # \\delta_mj = \\sum a_mi^2 * \\sigma_ij^2\n",
    "        output_h_local = m_h + tf.sqrt(v_h + 1e-6) * tf.random_normal(tf.shape(v_h)) # a sample from N(\\gama_mj,\\delta_mj)\n",
    "        output_h_local = activation_fn(output_h_local)\n",
    "\n",
    "        return output_h, output_h_local, neg_kl\n",
    "\n",
    "    def build_action_noise(self):\n",
    "        \"\"\"Defines a model for additive noise per action, and its KL term.\"\"\"\n",
    "\n",
    "        # Define mean and std variables (log-normal dist) for each action.\n",
    "        noise_sigma_mu = (self.build_mu_variable([1, self.n_out])\n",
    "                          + self.inverse_sigma_transform(self.hparams.noise_sigma))\n",
    "        noise_sigma_sigma = self.sigma_transform(\n",
    "            self.build_sigma_variable([1, self.n_out]))\n",
    "\n",
    "        pre_noise_sigma = (noise_sigma_mu\n",
    "                           + tf.random_normal([1, self.n_out]) * noise_sigma_sigma)\n",
    "        self.noise_sigma = self.sigma_transform(pre_noise_sigma)\n",
    "\n",
    "        # Compute KL for additive noise sigma terms.\n",
    "        if getattr(self.hparams, \"infer_noise_sigma\", False):\n",
    "            neg_kl_term = log_gaussian(\n",
    "                  pre_noise_sigma,\n",
    "                  self.inverse_sigma_transform(self.hparams.noise_sigma),\n",
    "                  self.hparams.prior_sigma\n",
    "              )\n",
    "            neg_kl_term -= log_gaussian(pre_noise_sigma,\n",
    "                                          noise_sigma_mu,\n",
    "                                          noise_sigma_sigma)\n",
    "        else:\n",
    "            neg_kl_term = 0.\n",
    "\n",
    "        return neg_kl_term\n",
    "\n",
    "    def build_model(self, activation_fn=tf.nn.relu):\n",
    "        \"\"\"Defines the actual NN model with fully connected layers.\n",
    "        The loss is computed for partial feedback settings (bandits), so only\n",
    "        the observed outcome is backpropagated (see weighted loss).\n",
    "        Selects the optimizer and, finally, it also initializes the graph.\n",
    "        Args:\n",
    "          activation_fn: the activation function used in the nn layers.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Initializing model {}.\".format(self.name))\n",
    "        neg_kl_term, l_number = 0, 0\n",
    "        use_local_reparameterization = self.use_local_reparameterization\n",
    "\n",
    "        # Compute model additive noise for each action with log-normal distribution\n",
    "        neg_kl_term += self.build_action_noise()\n",
    "\n",
    "        # Build network.\n",
    "        input_x = self.x\n",
    "        input_local = self.x\n",
    "        n_in = self.n_in\n",
    "\n",
    "        for l_number, n_nodes in enumerate(self.layers):\n",
    "            if n_nodes > 0:\n",
    "                h, h_local, neg_kl = self.build_layer(input_x, input_local,\n",
    "                                                  [n_in, n_nodes], l_number)\n",
    "\n",
    "            neg_kl_term += neg_kl\n",
    "            input_x, input_local = h, h_local\n",
    "            n_in = n_nodes\n",
    "\n",
    "        # Create last linear layer\n",
    "        h, h_local, neg_kl = self.build_layer(input_x, input_local,\n",
    "                                              [n_in, self.n_out],\n",
    "                                              l_number + 1,\n",
    "                                              activation_fn=lambda x: x)\n",
    "        neg_kl_term += neg_kl\n",
    "\n",
    "        self.y_pred = h\n",
    "        self.y_pred_local = h_local\n",
    "\n",
    "        # Compute log likelihood (with learned or fixed noise level)\n",
    "        if getattr(self.hparams, \"infer_noise_sigma\", False):\n",
    "            log_likelihood = log_gaussian(\n",
    "              self.y, self.y_pred_local, self.noise_sigma, reduce_sum=False)\n",
    "        else:\n",
    "            y_hat = self.y_pred_local if use_local_reparameterization else self.y_pred\n",
    "            log_likelihood = log_gaussian(\n",
    "              self.y, y_hat, self.hparams.noise_sigma, reduce_sum=False)\n",
    "\n",
    "        # Only take into account observed outcomes (bandits setting)\n",
    "        batch_size = tf.to_float(tf.shape(self.x)[0])\n",
    "        weighted_log_likelihood = tf.reduce_sum(\n",
    "            log_likelihood * self.weights) / batch_size\n",
    "\n",
    "        # The objective is 1/n * (\\sum_i log_like_i - KL); neg_kl_term estimates -KL\n",
    "        elbo = weighted_log_likelihood + (neg_kl_term / self.n)\n",
    "\n",
    "        self.loss = -elbo\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        self.train_op = tf.train.AdamOptimizer(self.hparams.initial_lr).minimize(\n",
    "            self.loss, global_step=self.global_step)\n",
    "\n",
    "        # Create tensorboard metrics\n",
    "        self.create_summaries()\n",
    "        self.summary_writer = tf.summary.FileWriter(\n",
    "            \"{}/graph_{}\".format('results', self.name), self.sess.graph)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Defines graph, session, placeholders, and model.\n",
    "        Placeholders are: n (size of the dataset), x and y (context and observed\n",
    "        reward for each action), and weights (one-hot encoding of selected action\n",
    "        for each context, i.e., only possibly non-zero element in each y).\n",
    "        \"\"\"\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            self.sess = tf.Session()\n",
    "\n",
    "            self.n = tf.placeholder(shape=[], dtype=tf.float32)\n",
    "\n",
    "            self.x = tf.placeholder(shape=[None, self.n_in], dtype=tf.float32)\n",
    "            self.y = tf.placeholder(shape=[None, self.n_out], dtype=tf.float32)\n",
    "            self.weights = tf.placeholder(shape=[None, self.n_out], dtype=tf.float32)\n",
    "\n",
    "            self.build_model()\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def create_summaries(self):\n",
    "        \"\"\"Defines summaries including mean loss, and global step.\"\"\"\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope(self.name + \"_summaries\"):\n",
    "                tf.summary.scalar(\"loss\", self.loss)\n",
    "                tf.summary.scalar(\"global_step\", self.global_step)\n",
    "                self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "    def assign_lr(self):\n",
    "        \"\"\"Resets the learning rate in dynamic schedules for subsequent trainings.\n",
    "        In bandits settings, we do expand our dataset over time. Then, we need to\n",
    "        re-train the network with the new data. The algorithms that do not keep\n",
    "        the step constant, can reset it at the start of each *training* process.\n",
    "        \"\"\"\n",
    "\n",
    "        decay_steps = 1\n",
    "        if self.hparams.activate_decay:\n",
    "            current_gs = self.sess.run(self.global_step)\n",
    "            with self.graph.as_default():\n",
    "                self.lr = tf.train.inverse_time_decay(self.hparams.initial_lr,\n",
    "                                                      self.global_step - current_gs,\n",
    "                                                      decay_steps,\n",
    "                                                      self.hparams.lr_decay_rate)\n",
    "\n",
    "    def train(self, data, num_steps):\n",
    "        \"\"\"Trains the BNN for num_steps, using the data in 'data'.\n",
    "        Args:\n",
    "          data: ContextualDataset object that provides the data.\n",
    "          num_steps: Number of minibatches to train the network for.\n",
    "        Returns:\n",
    "          losses: Loss history during training.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.times_trained < self.cleared_times_trained:\n",
    "            num_steps = int(self.training_schedule[self.times_trained])\n",
    "        self.times_trained += 1\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Training {} for {} steps...\".format(self.name, num_steps))\n",
    "\n",
    "            for step in range(num_steps):\n",
    "                x, y, weights = data.get_batch_with_weights(self.hparams.batch_size)\n",
    "                _, summary, global_step, loss = self.sess.run(\n",
    "                    [self.train_op, self.summary_op, self.global_step, self.loss],\n",
    "                    feed_dict={\n",
    "                        self.x: x,\n",
    "                        self.y: y,\n",
    "                        self.weights: weights,\n",
    "                        self.n: data.num_points(self.f_num_points),\n",
    "                    })\n",
    "\n",
    "                losses.append(loss)\n",
    "\n",
    "                if step % self.hparams.freq_summary == 0:\n",
    "                    if self.hparams.show_training:\n",
    "\n",
    "                        print(\"{} | step: {}, loss: {}\".format(\n",
    "                            self.name, global_step, loss))\n",
    "                    self.summary_writer.add_summary(summary, global_step)\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### 3.2.2 Second, we define the contextual bandit class that defines the corresponding bandit problem (the name sampling referes to Thompson sampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/posterior_bnn_sampling.py' \n",
    "class PosteriorBNNSampling(BanditAlgorithm):\n",
    "    \"\"\"Posterior Sampling algorithm based on a Bayesian neural network.\"\"\"\n",
    "\n",
    "    def __init__(self, name, hparams, bnn_model='RMSProp'):\n",
    "        \"\"\"Creates a PosteriorBNNSampling object based on a specific optimizer.\n",
    "        The algorithm has two basic tools: an Approx BNN and a Contextual Dataset.\n",
    "        The Bayesian Network keeps the posterior based on the optimizer iterations.\n",
    "        Args:\n",
    "          name: Name of the algorithm.\n",
    "          hparams: Hyper-parameters of the algorithm.\n",
    "          bnn_model: Type of BNN. By default RMSProp (point estimate).\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.hparams = hparams\n",
    "        self.optimizer_n = hparams.optimizer\n",
    "\n",
    "        self.training_freq = hparams.training_freq\n",
    "        self.training_epochs = hparams.training_epochs\n",
    "        self.t = 0\n",
    "        self.data_h = ContextualDataset(hparams.context_dim, hparams.num_actions,\n",
    "                                        hparams.buffer_s)\n",
    "\n",
    "        # to be extended with more BNNs (BB alpha-div, GPs, SGFS, constSGD...)\n",
    "        bnn_name = '{}-bnn'.format(name)\n",
    "        if bnn_model == 'Variational':       # variational inference\n",
    "            self.bnn = VariationalNeuralBanditModel(hparams, bnn_name)\n",
    "#         elif bnn_model == 'AlphaDiv':\n",
    "#           self.bnn = BBAlphaDivergence(hparams, bnn_name)\n",
    "#         elif bnn_model == 'Variational_BF':\n",
    "#           self.bnn = BfVariationalNeuralBanditModel(hparams, bnn_name)\n",
    "        else:# bnn_model == 'GP':            # multi-task gaussian process\n",
    "          self.bnn = MultitaskGP(hparams)\n",
    "#         else:\n",
    "#           self.bnn = NeuralBanditModel(self.optimizer_n, hparams, bnn_name)\n",
    "\n",
    "    def action(self, context):\n",
    "        \"\"\"Selects action for context based on Thompson Sampling using the BNN.\"\"\"\n",
    "\n",
    "        if self.t < self.hparams.num_actions * self.hparams.initial_pulls:\n",
    "          # round robin until each action has been taken \"initial_pulls\" times\n",
    "            return self.t % self.hparams.num_actions\n",
    "\n",
    "        with self.bnn.graph.as_default():\n",
    "            c = context.reshape((1, self.hparams.context_dim))\n",
    "            output = self.bnn.sess.run(self.bnn.y_pred, feed_dict={self.bnn.x: c})\n",
    "            return np.argmax(output)\n",
    "\n",
    "    def update(self, context, action, reward):\n",
    "        \"\"\"Updates data buffer, and re-trains the BNN every training_freq steps.\"\"\"\n",
    "\n",
    "        self.t += 1\n",
    "        self.data_h.add(context, action, reward)\n",
    "\n",
    "        if self.t % self.training_freq == 0:\n",
    "            if self.hparams.reset_lr:\n",
    "                self.bnn.assign_lr()\n",
    "            self.bnn.train(self.data_h, self.training_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.3 contextual bandits based on Bootstapped Networks\n",
    "\n",
    "A simple empirical approach to approximate the sampling distribution of any estimator is\n",
    "the Bootstrap.  The main idea is to simultaneously train $q$ models, where each model $i$\n",
    "is based on a different dataset $D_i$\n",
    ". When all the data $D$ is available in advance, $D_i$\n",
    "is typically created\n",
    "by sampling $|D|$ elements from $D$ at random **with replacement**. In our case, however, the data grows\n",
    "one example at a time. Accordingly, we set a parameter $p \\in (0, 1]$, and append the new datapoint to\n",
    "each $D_i$ independently at random with probability $p$. So the Thompson sampling procedure in this case is:\n",
    "\n",
    "1: among the q models select a model unifromly at random\n",
    "\n",
    "2: take the action predicted to be best by the sampled model\n",
    "\n",
    "3: with probability p add the new collected datapoint ($X_t,a_t,r_t$) to each q model dataset \n",
    "\n",
    "4: re-train all q models every update time frequency \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### 3.3.1 First, we need to define a neural network structure that can be used for each of the bootstrapped samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/neural_bandit_model.py' \n",
    "\n",
    "class NeuralBanditModel(BayesianNN):\n",
    "    \"\"\"Implements a neural network for bandit problems.\"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, hparams, name):\n",
    "        \"\"\"Saves hyper-params and builds the Tensorflow graph.\"\"\"\n",
    "\n",
    "        self.opt_name = optimizer\n",
    "        self.name = name\n",
    "        self.hparams = hparams\n",
    "        self.verbose = getattr(self.hparams, \"verbose\", True)\n",
    "        self.times_trained = 0\n",
    "        self.build_model()\n",
    "\n",
    "    def build_layer(self, x, num_units):\n",
    "        \"\"\"Builds a layer with input x; dropout and layer norm if specified.\"\"\"\n",
    "\n",
    "        init_s = self.hparams.init_scale\n",
    "\n",
    "        layer_n = getattr(self.hparams, \"layer_norm\", False)\n",
    "        dropout = getattr(self.hparams, \"use_dropout\", False)\n",
    "\n",
    "        nn = tf.contrib.layers.fully_connected(\n",
    "            x,\n",
    "            num_units,\n",
    "            activation_fn=self.hparams.activation,\n",
    "            normalizer_fn=None if not layer_n else tf.contrib.layers.layer_norm,\n",
    "            normalizer_params={},\n",
    "            weights_initializer=tf.random_uniform_initializer(-init_s, init_s)\n",
    "        )\n",
    "\n",
    "        if dropout:            \n",
    "            nn = tf.nn.dropout(nn, self.hparams.keep_prob)\n",
    "\n",
    "        return nn\n",
    "\n",
    "    def forward_pass(self):\n",
    "\n",
    "        init_s = self.hparams.init_scale\n",
    "\n",
    "        scope_name = \"prediction_{}\".format(self.name)\n",
    "        with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE):\n",
    "            nn = self.x\n",
    "            for num_units in self.hparams.layer_sizes:\n",
    "                if num_units > 0:\n",
    "                    nn = self.build_layer(nn, num_units)\n",
    "\n",
    "            y_pred = tf.layers.dense(\n",
    "                      nn,\n",
    "                      self.hparams.num_actions,\n",
    "                      kernel_initializer=tf.random_uniform_initializer(-init_s, init_s))\n",
    "\n",
    "        return nn, y_pred\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Defines the actual NN model with fully connected layers.\n",
    "        The loss is computed for partial feedback settings (bandits), so only\n",
    "        the observed outcome is backpropagated (see weighted loss).\n",
    "        Selects the optimizer and, finally, it also initializes the graph.\n",
    "        \"\"\"\n",
    "\n",
    "        # create and store the graph corresponding to the BNN instance\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "\n",
    "          # create and store a new session for the graph\n",
    "            self.sess = tf.Session()\n",
    "\n",
    "\n",
    "            with tf.name_scope(self.name):\n",
    "\n",
    "                self.global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "                # context\n",
    "                self.x = tf.placeholder(\n",
    "                    shape=[None, self.hparams.context_dim],\n",
    "                    dtype=tf.float32,\n",
    "                    name=\"{}_x\".format(self.name))\n",
    "\n",
    "                # reward vector\n",
    "                self.y = tf.placeholder(\n",
    "                    shape=[None, self.hparams.num_actions],\n",
    "                    dtype=tf.float32,\n",
    "                    name=\"{}_y\".format(self.name))\n",
    "\n",
    "                # weights (1 for selected action, 0 otherwise)\n",
    "                self.weights = tf.placeholder(\n",
    "                    shape=[None, self.hparams.num_actions],\n",
    "                    dtype=tf.float32,\n",
    "                    name=\"{}_w\".format(self.name))\n",
    "\n",
    "                # with tf.variable_scope(\"prediction_{}\".format(self.name)):\n",
    "                self.nn, self.y_pred = self.forward_pass()\n",
    "                self.loss = tf.squared_difference(self.y_pred, self.y)\n",
    "                self.weighted_loss = tf.multiply(self.weights, self.loss)\n",
    "                self.cost = tf.reduce_sum(self.weighted_loss) / self.hparams.batch_size\n",
    "\n",
    "                if self.hparams.activate_decay:\n",
    "                    self.lr = tf.train.inverse_time_decay(\n",
    "                      self.hparams.initial_lr, self.global_step,\n",
    "                      1, self.hparams.lr_decay_rate)\n",
    "                else:\n",
    "                    self.lr = tf.Variable(self.hparams.initial_lr, trainable=False)\n",
    "\n",
    "                # create tensorboard metrics\n",
    "                self.create_summaries()\n",
    "                self.summary_writer = tf.summary.FileWriter(\n",
    "                    \"{}/graph_{}\".format('results', self.name), self.sess.graph)\n",
    "\n",
    "                tvars = tf.trainable_variables()\n",
    "                grads, _ = tf.clip_by_global_norm(\n",
    "                    tf.gradients(self.cost, tvars), self.hparams.max_grad_norm)\n",
    "\n",
    "                self.optimizer = self.select_optimizer()\n",
    "\n",
    "                self.train_op = self.optimizer.apply_gradients(\n",
    "                    zip(grads, tvars), global_step=self.global_step)\n",
    "\n",
    "                self.init = tf.global_variables_initializer()\n",
    "\n",
    "                self.initialize_graph()\n",
    "\n",
    "    def initialize_graph(self):\n",
    "        \"\"\"Initializes all variables.\"\"\"\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            if self.verbose:\n",
    "                print(\"Initializing model {}.\".format(self.name))\n",
    "            self.sess.run(self.init)\n",
    "\n",
    "    def assign_lr(self):\n",
    "        \"\"\"Resets the learning rate in dynamic schedules for subsequent trainings.\n",
    "        In bandits settings, we do expand our dataset over time. Then, we need to\n",
    "        re-train the network with the new data. The algorithms that do not keep\n",
    "        the step constant, can reset it at the start of each *training* process.\n",
    "        \"\"\"\n",
    "\n",
    "        decay_steps = 1\n",
    "        if self.hparams.activate_decay:\n",
    "            current_gs = self.sess.run(self.global_step)\n",
    "            with self.graph.as_default():\n",
    "                self.lr = tf.train.inverse_time_decay(self.hparams.initial_lr,\n",
    "                                                  self.global_step - current_gs,\n",
    "                                                  decay_steps,\n",
    "                                                  self.hparams.lr_decay_rate)\n",
    "\n",
    "    def select_optimizer(self):        \n",
    "        \"\"\"Selects optimizer. To be extended (SGLD, KFAC, etc).\"\"\"\n",
    "        return tf.train.RMSPropOptimizer(self.lr)\n",
    "\n",
    "    def create_summaries(self):\n",
    "        \"\"\"Defines summaries including mean loss, learning rate, and global step.\"\"\"\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope(self.name + \"_summaries\"):\n",
    "                tf.summary.scalar(\"cost\", self.cost)\n",
    "                tf.summary.scalar(\"lr\", self.lr)\n",
    "                tf.summary.scalar(\"global_step\", self.global_step)\n",
    "                self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "    def train(self, data, num_steps):\n",
    "        \"\"\"Trains the network for num_steps, using the provided data.\n",
    "        Args:\n",
    "          data: ContextualDataset object that provides the data.\n",
    "          num_steps: Number of minibatches to train the network for.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Training {} for {} steps...\".format(self.name, num_steps))\n",
    "\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            for step in range(num_steps):\n",
    "                x, y, w = data.get_batch_with_weights(self.hparams.batch_size)\n",
    "                _, cost,summary, lr = self.sess.run(\n",
    "                    [self.train_op, self.cost, self.summary_op, self.lr],\n",
    "                    feed_dict={self.x: x, self.y: y, self.weights: w})\n",
    "\n",
    "                if step % self.hparams.freq_summary == 0:\n",
    "                    if self.hparams.show_training:\n",
    "                        print(\"{} | step: {}, lr: {}, loss: {}\".format(\n",
    "                            self.name, step, lr, cost))\n",
    "                    self.summary_writer.add_summary(summary, step)\n",
    "\n",
    "            self.times_trained += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### 3.3.2 Second, we define the bootstrapped sampler class:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/bootstrapped_bnn_sampling.py' \n",
    "class BootstrappedBNNSampling(BanditAlgorithm):\n",
    "    \n",
    "    \"\"\"Thompson Sampling algorithm based on training several neural networks.\"\"\"\n",
    "\n",
    "    def __init__(self, name, hparams, optimizer='RMS'):\n",
    "        \"\"\"Creates a BootstrappedSGDSampling object based on a specific optimizer.\n",
    "          hparams.q: Number of NN models that are independently trained.(number of bootstrapped samples)\n",
    "          hparams.p: Prob of independently including each selcted datapoint in each model.\n",
    "        Args:\n",
    "          name: Name given to the instance.\n",
    "          hparams: Hyperparameters for each individual model.\n",
    "          optimizer: Neural network optimization algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.hparams = hparams\n",
    "        self.optimizer_n = optimizer\n",
    "\n",
    "        self.training_freq = hparams.training_freq\n",
    "        self.training_epochs = hparams.training_epochs\n",
    "        self.t = 0 # keeps track of number of times update is called \n",
    "\n",
    "        self.q = hparams.q\n",
    "        self.p = hparams.p\n",
    "        \n",
    "        \n",
    "        # q datasets, one for each mocel\n",
    "        self.datasets = [\n",
    "            ContextualDataset(hparams.context_dim,\n",
    "                              hparams.num_actions,\n",
    "                              hparams.buffer_s)\n",
    "            for _ in range(self.q)\n",
    "        ]\n",
    "        \n",
    "        # q neural networks, one for each model\n",
    "        self.bnn_boot = [\n",
    "            NeuralBanditModel(optimizer, hparams, '{}-{}-bnn'.format(name, i))\n",
    "            for i in range(self.q)\n",
    "        ]\n",
    "\n",
    "    def action(self, context):\n",
    "        \"\"\"Selects action for context based on Thompson Sampling using one BNN.\"\"\"\n",
    "\n",
    "        if self.t < self.hparams.num_actions * self.hparams.initial_pulls:\n",
    "            \n",
    "              # round robin until each action has been taken \"initial_pulls\" times\n",
    "            return self.t % self.hparams.num_actions\n",
    "\n",
    "        # choose model uniformly at random\n",
    "        model_index = np.random.randint(self.q)\n",
    "        # take action\n",
    "        with self.bnn_boot[model_index].graph.as_default():\n",
    "            c = context.reshape((1, self.hparams.context_dim))\n",
    "            output = self.bnn_boot[model_index].sess.run(\n",
    "                  self.bnn_boot[model_index].y_pred,\n",
    "                  feed_dict={self.bnn_boot[model_index].x: c})\n",
    "            return np.argmax(output)\n",
    "\n",
    "    def update(self, context, action, reward):\n",
    "        \"\"\"Updates the data buffer, and re-trains the BNN every self.freq_update.\"\"\"\n",
    "\n",
    "        self.t += 1\n",
    "        # add the selected action data wih proba p to each model q\n",
    "        for i in range(self.q):\n",
    "            \n",
    "          # include the data point with probability p independently in each dataset\n",
    "            if np.random.random() < self.p or self.t < 2:\n",
    "                self.datasets[i].add(context, action, reward)\n",
    "\n",
    "        if self.t % self.training_freq == 0:\n",
    "          # update all the models:\n",
    "            for i in range(self.q):\n",
    "                if self.hparams.reset_lr:\n",
    "                    self.bnn_boot[i].assign_lr()\n",
    "                self.bnn_boot[i].train(self.datasets[i], self.training_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.4 Multi-task Gaussian Process as anon-parametric method\n",
    "\n",
    "Consider $y = f(x)+\\epsilon$ where $\\epsilon$ is an iid Gaussian noise with variance $\\sigma_n^2$. The Gaussian process (GP)describes a joint distribution over fucntions $f(x)$. \n",
    "\n",
    "\n",
    "\n",
    "We have a set $X$ of $N$ distinct inputs $x1, . . . , xN$ we define the complete set of responses for $M$ tasks\n",
    "as $y = (y11, . . . , yN1, . . . , y12, . . . , yN2, . . . , y1M, . . . , yNM)^T$\n",
    ", where $y_{il}$ is the response for the $l$\n",
    "th\n",
    "task on the $i$\n",
    "th input $xi$\n",
    ". \n",
    "\n",
    "Given a set of observations $y_o$\n",
    ", which is a subset of $y$, we want to predict some of the unobserved\n",
    "response-values $y_u$\n",
    "at some input locations for certain tasks.\n",
    "\n",
    "We approach this problem by placing a GP prior over the latent functions ($f_l(x_i)$) so that we directly\n",
    "induce correlations between tasks. Assuming that the GPs have zero mean we set\n",
    "\n",
    "$$<f_l(x),f_k(x^\\prime)> = K(x,x^\\prime) = (\\alpha k_{matern}(x,x^\\prime) + \\beta k_{lin}(x,x^\\prime) ) \\times K_{task}(v^k,v^l) = k^x(x,x^\\prime) K^{task}$$\n",
    "and $$y_{il} \\sim N(f_l(x_i),\\sigma_n^2)$$\n",
    "\n",
    "So the inference for a single test point $x_*$ for task l is given by:\n",
    "\n",
    "$$\\bar{f_l}(x_*) = (k^x(x,x_*) K^{task}_l)^T (K(x,x) + \\sigma_n^2 I )^{-1} y$$\n",
    "and $$V[f_l(x_*)] = k^x(x_*,x_*) K^{task}_l - (k^x(x,x_*) K^{task}_l)^T (K(x,x) + \\sigma_n^2 I )^{-1} (k^x(x,x_*) K^{task}_l)$$\n",
    "\n",
    "and the objective is to maximize the log of marginal liklihood:\n",
    "\n",
    "$$p(y|x) = \\int p(y|f,x) p(f|x)$$ where under the Gaussian process model the prior is Gaussian $p(f|x) \\sim N(0,K(x,x))$ or\n",
    "$$log p(f|X) = 0.5 f^T K^{-1} f - 0.5 \\log |K| - n/2 \\log 2\\pi$$, and the liklihood is $$p(y|f) \\sim N(f,\\sigma_n^2I)$$ As a result the log marginal liklihood becomes:\n",
    "$$log(y|x) = -0.5 y^T (K+\\sigma_n^2I)^{-1}y - 0.5 \\log |K+\\sigma_n^2I| - n/2 \\log 2\\pi$$\n",
    "\n",
    "In which the parameters to optimize are $K^{task}$ elements, and the parameters of $k^x$ ($\\alpha$,$\\beta$, and the length scales of matern and linear kernels)\n",
    "\n",
    "References:\n",
    "\n",
    "* https://arxiv.org/pdf/1802.09127.pdf\n",
    "\n",
    "* http://papers.nips.cc/paper/3189-multi-task-gaussian-process-prediction.pdf\n",
    "\n",
    "* Gaussian Processes for Machine Learning (book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/algorithms/multitask_gp.py' \n",
    "from absl import flags\n",
    "FLAGS = flags.FLAGS\n",
    "tfd = tf.contrib.distributions\n",
    "\n",
    "class MultitaskGP(BayesianNN):\n",
    "    \"\"\"Implements a Gaussian process with multi-task outputs.\n",
    "    Optimizes the hyperparameters over the log marginal likelihood.\n",
    "    Uses a Matern 3/2 + linear covariance and returns\n",
    "    sampled predictions for test inputs.  The outputs are optionally\n",
    "    correlated where the correlation structure is learned through latent\n",
    "    embeddings of the tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        self.name = \"MultiTaskGP\"\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.n_in = self.hparams.context_dim\n",
    "        self.n_out = self.hparams.num_outputs # task sim\n",
    "        self.keep_fixed_after_max_obs = self.hparams.keep_fixed_after_max_obs\n",
    "\n",
    "        self._show_training = self.hparams.show_training\n",
    "        self._freq_summary = self.hparams.freq_summary\n",
    "\n",
    "        # Dimensionality of the latent task vectors\n",
    "        self.task_latent_dim = self.hparams.task_latent_dim\n",
    "\n",
    "        # Maximum number of observations to include\n",
    "        self.max_num_points = self.hparams.max_num_points\n",
    "\n",
    "        if self.hparams.learn_embeddings:\n",
    "            self.learn_embeddings = self.hparams.learn_embeddings\n",
    "        else:\n",
    "            self.learn_embeddings = False\n",
    "\n",
    "        # create the graph corresponding to the BNN instance\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            # store a new session for the graph\n",
    "            self.sess = tf.Session()\n",
    "\n",
    "            with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "                self.n = tf.placeholder(shape=[], dtype=tf.float64)\n",
    "                self.x = tf.placeholder(shape=[None, self.n_in], dtype=tf.float64)\n",
    "                self.x_in = tf.placeholder(shape=[None, self.n_in], dtype=tf.float64)\n",
    "                self.y = tf.placeholder(shape=[None, self.n_out], dtype=tf.float64)\n",
    "                self.weights = tf.placeholder(shape=[None, self.n_out],\n",
    "                                              dtype=tf.float64)\n",
    "\n",
    "                self.build_model()\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def atleast_2d(self, x, dims):\n",
    "        return tf.reshape(tf.expand_dims(x, axis=0), (-1, dims))\n",
    "\n",
    "    def sq_dist(self, x, x2):\n",
    "        a2 = tf.reduce_sum(tf.square(x), 1)\n",
    "        b2 = tf.reduce_sum(tf.square(x2), 1)\n",
    "        sqdists = tf.expand_dims(a2, 1) + b2 - 2.0 * tf.matmul(x, tf.transpose(x2))\n",
    "        return sqdists\n",
    "\n",
    "    # Covariance between outputs\n",
    "    def task_cov(self, x, x2):\n",
    "        \"\"\"Squared Exponential Covariance Kernel over the latent embeding of predicted(selected) tasks.\"\"\"\n",
    "        # Index into latent task vectors\n",
    "        x_vecs = tf.gather(self.task_vectors, tf.argmax(x, axis=1), axis=0)\n",
    "        x2_vecs = tf.gather(self.task_vectors, tf.argmax(x2, axis=1), axis=0)\n",
    "        r = self.sq_dist(self.atleast_2d(x_vecs, self.task_latent_dim),\n",
    "                         self.atleast_2d(x2_vecs, self.task_latent_dim))\n",
    "        return tf.exp(-r)\n",
    "\n",
    "    def cov(self, x, x2):\n",
    "        \"\"\"Matern 3/2 + Linear Gaussian Process Covariance Function over inputs(contexts) .\"\"\"\n",
    "        # alpha*marten + beta*linear\n",
    "        ls = tf.clip_by_value(self.length_scales, -5.0, 5.0)\n",
    "        ls_lin = tf.clip_by_value(self.length_scales_lin, -5.0, 5.0)\n",
    "        r = self.sq_dist(self.atleast_2d(x, self.n_in)/tf.nn.softplus(ls),\n",
    "                         self.atleast_2d(x2, self.n_in)/tf.nn.softplus(ls))\n",
    "        r = tf.clip_by_value(r, 0, 1e8)\n",
    "\n",
    "        # Matern 3/2 Covariance\n",
    "        matern = (1.0 + tf.sqrt(3.0*r + 1e-16)) * tf.exp(-tf.sqrt(3.0*r + 1e-16))\n",
    "        # Linear Covariance\n",
    "        lin = tf.matmul(x / tf.nn.softplus(ls_lin),\n",
    "                        x2 / tf.nn.softplus(ls_lin), transpose_b=True)\n",
    "        return (tf.nn.softplus(self.amplitude) * matern +\n",
    "                tf.nn.softplus(self.amplitude_linear) * lin)\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Defines the GP model.\n",
    "        The loss is computed for partial feedback settings (bandits), so only\n",
    "        the observed outcome is backpropagated (see weighted loss).\n",
    "        Selects the optimizer and, finally, it also initializes the graph.\n",
    "        \"\"\"\n",
    "\n",
    "        #logging.info(\"Initializing model %s.\", self.name)\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        # Define state for the model (inputs, etc.)\n",
    "        self.x_train = tf.get_variable(\n",
    "            \"training_data\",\n",
    "            initializer=tf.ones(\n",
    "                [self.hparams.batch_size, self.n_in], dtype=tf.float64),\n",
    "            validate_shape=False,\n",
    "            trainable=False)\n",
    "        self.y_train = tf.get_variable(\n",
    "            \"training_labels\",\n",
    "            initializer=tf.zeros([self.hparams.batch_size, 1], dtype=tf.float64),\n",
    "            validate_shape=False,\n",
    "            trainable=False)\n",
    "        self.weights_train = tf.get_variable(\n",
    "            \"weights_train\",\n",
    "            initializer=tf.ones(\n",
    "                [self.hparams.batch_size, self.n_out], dtype=tf.float64),\n",
    "            validate_shape=False,\n",
    "            trainable=False)\n",
    "        self.input_op = tf.assign(self.x_train, self.x_in, validate_shape=False)\n",
    "        self.input_w_op = tf.assign(\n",
    "            self.weights_train, self.weights, validate_shape=False)\n",
    "\n",
    "        self.input_std = tf.get_variable(\n",
    "            \"data_standard_deviation\",\n",
    "            initializer=tf.ones([1, self.n_out], dtype=tf.float64),\n",
    "            dtype=tf.float64,\n",
    "            trainable=False)\n",
    "        self.input_mean = tf.get_variable(\n",
    "            \"data_mean\",\n",
    "            initializer=tf.zeros([1, self.n_out], dtype=tf.float64),\n",
    "            dtype=tf.float64,\n",
    "            trainable=True)\n",
    "\n",
    "        # GP Hyperparameters\n",
    "        self.noise = tf.get_variable(\n",
    "            \"noise\", initializer=tf.cast(0.0, dtype=tf.float64))\n",
    "        self.amplitude = tf.get_variable(\n",
    "            \"amplitude\", initializer=tf.cast(1.0, dtype=tf.float64))\n",
    "        self.amplitude_linear = tf.get_variable(\n",
    "            \"linear_amplitude\", initializer=tf.cast(1.0, dtype=tf.float64))\n",
    "        self.length_scales = tf.get_variable(\n",
    "            \"length_scales\", initializer=tf.zeros([1, self.n_in], dtype=tf.float64))\n",
    "        self.length_scales_lin = tf.get_variable(\n",
    "            \"length_scales_linear\",\n",
    "            initializer=tf.zeros([1, self.n_in], dtype=tf.float64))\n",
    "\n",
    "        # Latent embeddings of the different outputs for task covariance\n",
    "        self.task_vectors = tf.get_variable(\n",
    "            \"latent_task_vectors\",\n",
    "            initializer=tf.random_normal(\n",
    "                [self.n_out, self.task_latent_dim], dtype=tf.float64))\n",
    "\n",
    "        # Normalize outputs across each dimension\n",
    "        # Since we have different numbers of observations across each task, we\n",
    "        # normalize by their respective counts.\n",
    "        index_counts = self.atleast_2d(tf.reduce_sum(self.weights, axis=0),\n",
    "                                       self.n_out)\n",
    "        index_counts = tf.where(index_counts > 0, index_counts,\n",
    "                                tf.ones(tf.shape(index_counts), dtype=tf.float64))\n",
    "        self.mean_op = tf.assign(self.input_mean,\n",
    "                                 tf.reduce_sum(self.y, axis=0) / index_counts)\n",
    "        self.var_op = tf.assign(\n",
    "            self.input_std, tf.sqrt(1e-4 + tf.reduce_sum(tf.square(\n",
    "                self.y - tf.reduce_sum(self.y, axis=0) / index_counts), axis=0)\n",
    "                                    / index_counts))\n",
    "\n",
    "        with tf.control_dependencies([self.var_op]):\n",
    "            y_normed = self.atleast_2d(\n",
    "              (self.y - self.input_mean) / self.input_std, self.n_out)\n",
    "            y_normed = self.atleast_2d(tf.boolean_mask(y_normed, self.weights > 0), 1)\n",
    "        self.out_op = tf.assign(self.y_train, y_normed, validate_shape=False)\n",
    "\n",
    "        # Observation noise\n",
    "        alpha = tf.nn.softplus(self.noise) + 1e-6\n",
    "\n",
    "        # Covariance\n",
    "        with tf.control_dependencies([self.input_op, self.input_w_op, self.out_op]):\n",
    "            self.self_cov = (self.cov(self.x_in, self.x_in) *\n",
    "                           self.task_cov(self.weights, self.weights) +\n",
    "                           tf.eye(tf.shape(self.x_in)[0], dtype=tf.float64) * alpha)\n",
    "\n",
    "        self.chol = tf.cholesky(self.self_cov)\n",
    "        self.kinv = tf.cholesky_solve(self.chol, tf.eye(tf.shape(self.x_in)[0],\n",
    "                                                        dtype=tf.float64))\n",
    "\n",
    "        self.input_inv = tf.Variable(\n",
    "            tf.eye(self.hparams.batch_size, dtype=tf.float64),\n",
    "            validate_shape=False,\n",
    "            trainable=False)\n",
    "        self.input_cov_op = tf.assign(self.input_inv, self.kinv,\n",
    "                                      validate_shape=False)\n",
    "\n",
    "        # Log determinant by taking the singular values along the diagonal\n",
    "        # of self.chol\n",
    "        with tf.control_dependencies([self.input_cov_op]):\n",
    "            logdet = 2.0 * tf.reduce_sum(tf.log(tf.diag_part(self.chol) + 1e-16))\n",
    "\n",
    "        # Log Marginal likelihood\n",
    "        self.marginal_ll = -tf.reduce_sum(-0.5 * tf.matmul(\n",
    "            tf.transpose(y_normed), tf.matmul(self.kinv, y_normed)) - 0.5 * logdet -\n",
    "                                          0.5 * self.n * np.log(2 * np.pi))\n",
    "\n",
    "        zero = tf.cast(0., dtype=tf.float64)\n",
    "        one = tf.cast(1., dtype=tf.float64)\n",
    "        standard_normal = tfd.Normal(loc=zero, scale=one)\n",
    "\n",
    "        # Loss is marginal likelihood and priors\n",
    "        self.loss = tf.reduce_sum(\n",
    "            self.marginal_ll -\n",
    "            (standard_normal.log_prob(self.amplitude) +\n",
    "             standard_normal.log_prob(tf.exp(self.noise)) +\n",
    "             standard_normal.log_prob(self.amplitude_linear) +\n",
    "             tfd.Normal(loc=zero, scale=one * 10.).log_prob(\n",
    "                 self.task_vectors))\n",
    "        )\n",
    "\n",
    "        # Optimizer for hyperparameters\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.hparams.lr)\n",
    "        vars_to_optimize = [\n",
    "            self.amplitude, self.length_scales, self.length_scales_lin,\n",
    "            self.amplitude_linear, self.noise, self.input_mean\n",
    "        ]\n",
    "\n",
    "        if self.learn_embeddings:\n",
    "            vars_to_optimize.append(self.task_vectors)\n",
    "        grads = optimizer.compute_gradients(self.loss, vars_to_optimize)\n",
    "        self.train_op = optimizer.apply_gradients(grads,\n",
    "                                                  global_step=self.global_step)\n",
    "\n",
    "        # Predictions for test data\n",
    "        self.y_mean, self.y_pred = self.posterior_mean_and_sample(self.x)\n",
    "\n",
    "        # create tensorboard metrics\n",
    "        self.create_summaries()\n",
    "        self.summary_writer = tf.summary.FileWriter(\"{}/graph_{}\".format(\n",
    "            'results', self.name), self.sess.graph)\n",
    "        self.check = tf.add_check_numerics_ops()\n",
    "\n",
    "    def posterior_mean_and_sample(self, candidates):\n",
    "        \"\"\"Draw samples for test predictions.\n",
    "        Given a Tensor of 'candidates' inputs, returns samples from the posterior\n",
    "        and the posterior mean prediction for those inputs.\n",
    "        Args:\n",
    "          candidates: A (num-examples x num-dims) Tensor containing the inputs for\n",
    "          which to return predictions.\n",
    "        Returns:\n",
    "          y_mean: The posterior mean prediction given these inputs\n",
    "          y_sample: A sample from the posterior of the outputs given these inputs\n",
    "        \"\"\"\n",
    "        # Cross-covariance for test predictions\n",
    "        w = tf.identity(self.weights_train)\n",
    "        inds = tf.squeeze(\n",
    "            tf.reshape(\n",
    "                tf.tile(\n",
    "                    tf.reshape(tf.range(self.n_out), (self.n_out, 1)),\n",
    "                    (1, tf.shape(candidates)[0])), (-1, 1)))\n",
    "        # covariances between the test points x (candiates) and the training points\n",
    "        cross_cov = self.cov(tf.tile(candidates, [self.n_out, 1]), self.x_train) \n",
    "        # covariance between tasks\n",
    "        cross_task_cov = self.task_cov(tf.one_hot(inds, self.n_out), w)\n",
    "        cross_cov *= cross_task_cov\n",
    "\n",
    "        # Test mean prediction\n",
    "        y_mean = tf.matmul(cross_cov, tf.matmul(self.input_inv, self.y_train))\n",
    "\n",
    "        # Test sample predictions\n",
    "        # Note this can be done much more efficiently using Kronecker products\n",
    "        # if all tasks are fully observed (which we won't assume)\n",
    "        test_cov = (\n",
    "            self.cov(tf.tile(candidates, [self.n_out, 1]),\n",
    "                     tf.tile(candidates, [self.n_out, 1])) *\n",
    "            self.task_cov(tf.one_hot(inds, self.n_out),\n",
    "                          tf.one_hot(inds, self.n_out)) -\n",
    "            tf.matmul(cross_cov,\n",
    "                      tf.matmul(self.input_inv,\n",
    "                                tf.transpose(cross_cov))))\n",
    "\n",
    "        # Get the matrix square root through an SVD for drawing samples\n",
    "        # This seems more numerically stable than the Cholesky\n",
    "        s, _, v = tf.svd(test_cov, full_matrices=True)\n",
    "        test_sqrt = tf.matmul(v, tf.matmul(tf.diag(s), tf.transpose(v)))\n",
    "\n",
    "        y_sample = (\n",
    "            tf.matmul(\n",
    "                test_sqrt,\n",
    "                tf.random_normal([tf.shape(test_sqrt)[0], 1], dtype=tf.float64)) +\n",
    "            y_mean)\n",
    "\n",
    "        y_sample = (\n",
    "            tf.transpose(tf.reshape(y_sample,\n",
    "                                    (self.n_out, -1))) * self.input_std +\n",
    "            self.input_mean)\n",
    "\n",
    "        return y_mean, y_sample\n",
    "\n",
    "    def create_summaries(self):\n",
    "        with self.graph.as_default():\n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "            tf.summary.scalar(\"log_noise\", self.noise)\n",
    "            tf.summary.scalar(\"log_amp\", self.amplitude)\n",
    "            tf.summary.scalar(\"log_amp_lin\", self.amplitude_linear)\n",
    "            tf.summary.histogram(\"length_scales\", self.length_scales)\n",
    "            tf.summary.histogram(\"length_scales_lin\", self.length_scales_lin)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "    def train(self, data, num_steps):\n",
    "        \"\"\"Trains the GP for num_steps, using the data in 'data'.\n",
    "        Args:\n",
    "          data: ContextualDataset object that provides the data.\n",
    "          num_steps: Number of minibatches to train the network for.\n",
    "        \"\"\"\n",
    "\n",
    "        #logging.info(\"Training %s for %d steps...\", self.name, num_steps)\n",
    "        for step in range(num_steps):\n",
    "            numpts = min(data.num_points(None), self.max_num_points)\n",
    "            if numpts >= self.max_num_points and self.keep_fixed_after_max_obs:\n",
    "                \n",
    "                x = data.contexts[:numpts, :]\n",
    "                y = data.rewards[:numpts, :]\n",
    "                weights = np.zeros((x.shape[0], self.n_out))\n",
    "                for i, val in enumerate(data.actions[:numpts]):\n",
    "                    weights[i, val] = 1.0\n",
    "            else:\n",
    "                x, y, weights = data.get_batch_with_weights(numpts)\n",
    "\n",
    "            ops = [\n",
    "                  self.global_step, self.summary_op, self.loss, self.noise,\n",
    "                  self.amplitude, self.amplitude_linear, self.length_scales,\n",
    "                  self.length_scales_lin, self.input_cov_op, self.input_op, self.var_op,\n",
    "                  self.input_w_op, self.out_op, self.train_op\n",
    "              ]\n",
    "\n",
    "            res = self.sess.run(ops,\n",
    "                                  feed_dict={self.x: x,\n",
    "                                             self.x_in: x,\n",
    "                                             self.y: y,\n",
    "                                             self.weights: weights,\n",
    "                                             self.n: numpts,\n",
    "                                            })\n",
    "\n",
    "            if step % self._freq_summary == 0:\n",
    "                if self._show_training:\n",
    "                    logging.info(\"step: %d, loss: %g noise: %f amp: %f amp_lin: %f\",\n",
    "                               step, res[2], res[3], res[4], res[5])\n",
    "            summary = res[1]\n",
    "            global_step = res[0]\n",
    "            self.summary_writer.add_summary(summary, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### functions in order to run a contextual bandit problem on a single or a set of algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile -a 'scripts/core/contextual_bandit.py' \n",
    "def run_contextual_bandit_algos(context_dim, num_actions, dataset, algos):\n",
    "    \"\"\"Run a contextual bandit problem on a set of algorithms.\n",
    "    Args:\n",
    "    context_dim: Dimension of the context.\n",
    "    num_actions: Number of available actions.\n",
    "    dataset: Matrix where every row is a context + num_actions rewards. ---> this is the output of sample_*_data\n",
    "    algos: List of algorithms to use in the contextual bandit instance.\n",
    "    Returns:\n",
    "    h_actions: Matrix with actions: size (num_context, num_algorithms).\n",
    "    h_rewards: Matrix with rewards: size (num_context, num_algorithms).\n",
    "    \"\"\"\n",
    "\n",
    "    num_contexts = dataset.shape[0]\n",
    "\n",
    "    # Create contextual bandit\n",
    "    cmab = ContextualBandit(context_dim, num_actions)\n",
    "    cmab.feed_data(dataset)\n",
    "\n",
    "    h_actions = np.empty((0, len(algos)), float)\n",
    "    h_rewards = np.empty((0, len(algos)), float)\n",
    "\n",
    "    # Run the contextual bandit process\n",
    "      # for each context:\n",
    "            # select actions for each algo, get the rewards for each algo\n",
    "            # update the selected action, its reward and the corresponding context for each algo\n",
    "            # add  the selected actions and the given rewards to global h_actions and h_rewards\n",
    "    for i in range(num_contexts):\n",
    "        \n",
    "        context = cmab.context(i)\n",
    "        # select actions according to each algo\n",
    "        actions = [a.action(context) for a in algos] # \n",
    "        rewards = [cmab.reward(i, action) for action in actions]\n",
    "\n",
    "        for j, a in enumerate(algos):\n",
    "            a.update(context, actions[j], rewards[j])\n",
    "\n",
    "        h_actions = np.vstack((h_actions, np.array(actions)))\n",
    "        h_rewards = np.vstack((h_rewards, np.array(rewards)))\n",
    "\n",
    "    return h_actions, h_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile 'scripts/core/contextual_dataset.py' \n",
    "def run_contextual_bandit(context_dim, num_actions, dataset,algo):\n",
    "    \"\"\"Run a contextual bandit problem on a given algorithm.\n",
    "    Args:\n",
    "    context_dim: Dimension of the context.\n",
    "    num_actions: Number of available actions.\n",
    "    dataset: Matrix where every row is a context + num_actions rewards. ---> this is the output of sample_*_data\n",
    "    algos: List of algorithms to use in the contextual bandit instance.\n",
    "    Returns:\n",
    "    h_actions: Matrix with actions: size (num_context, num_algorithms).\n",
    "    h_rewards: Matrix with rewards: size (num_context, num_algorithms).\n",
    "    \"\"\"\n",
    "\n",
    "    num_contexts = dataset.shape[0]\n",
    "\n",
    "    # Create contextual bandit\n",
    "    cmab = ContextualBandit(context_dim, num_actions)\n",
    "    cmab.feed_data(dataset)\n",
    "\n",
    "    h_actions = []\n",
    "    h_rewards = []\n",
    "\n",
    "    # Run the contextual bandit process\n",
    "      # for each context:\n",
    "            # select actions for each algo, get the rewards for each algo\n",
    "            # update the selected action, its reward and the corresponding context for each algo\n",
    "            # add  the selected actions and the given rewards to global h_actions and h_rewards\n",
    "    for i in range(num_contexts):\n",
    "        \n",
    "        context = cmab.context(i)\n",
    "        # select actions according to each algo\n",
    "        action = algo.action(context)# \n",
    "        reward = cmab.reward(i, action) \n",
    "\n",
    "        \n",
    "        algo.update(context, action, reward)\n",
    "\n",
    "        h_actions.append(action)\n",
    "        h_rewards.append(reward)\n",
    "\n",
    "    return h_actions, h_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test each model on mushrooms dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_route = os.getcwd()\n",
    "data_route = 'datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contexts = 2000\n",
    "num_actions = 2\n",
    "context_dim = 117\n",
    "dataset, opt_mushroom = sample_mushroom_data(os.path.join(base_route, data_route, 'mushrooms.csv'), num_contexts)\n",
    "opt_rewards, opt_actions = opt_mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_linear = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                               context_dim=context_dim,\n",
    "                                               a0=6,\n",
    "                                               b0=6,\n",
    "                                               lambda_prior=0.25,\n",
    "                                               initial_pulls=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = LinTS('LinFullPost', hparams_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_contextual_bandit(context_dim, num_actions, dataset, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_actions, h_rewards = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(0,2000),np.cumsum(h_rewards))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(opt_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_ucb = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                               context_dim=context_dim,\n",
    "                                               alpha=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo1 = LinUcb('LinUCB', hparams_ucb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = run_contextual_bandit(context_dim, num_actions, dataset, algo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_actions1, h_rewards1 = results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(h_rewards1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_bbb = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                            context_dim=context_dim,\n",
    "                                            init_scale=0.3,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            layer_sizes=[50],\n",
    "                                            batch_size=512,\n",
    "                                            activate_decay=True,\n",
    "                                            initial_lr=0.1,\n",
    "                                            max_grad_norm=5.0,\n",
    "                                            show_training=False,\n",
    "                                            freq_summary=1000,\n",
    "                                            buffer_s=-1,\n",
    "                                            initial_pulls=2,\n",
    "                                            optimizer='RMS',\n",
    "                                            use_sigma_exp_transform=True,\n",
    "                                            cleared_times_trained=10,\n",
    "                                            initial_training_steps=100,\n",
    "                                            noise_sigma=0.1,\n",
    "                                            reset_lr=False,\n",
    "                                            training_freq=50,\n",
    "                                            training_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = PosteriorBNNSampling('BBB', hparams_bbb, 'Variational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_contextual_bandit(context_dim, num_actions, dataset, algo)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_actions2, h_rewards2 = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(h_rewards2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_gp = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                           num_outputs=num_actions,\n",
    "                                           context_dim=context_dim,\n",
    "                                           reset_lr=False,\n",
    "                                           learn_embeddings=True,\n",
    "                                           max_num_points=1000,\n",
    "                                           show_training=False,\n",
    "                                           freq_summary=1000,\n",
    "                                           batch_size=512,\n",
    "                                           keep_fixed_after_max_obs=True,\n",
    "                                           training_freq=50,\n",
    "                                           initial_pulls=2,\n",
    "                                           training_epochs=100,\n",
    "                                           lr=0.01,\n",
    "                                           buffer_s=-1,\n",
    "                                           initial_lr=0.001,\n",
    "                                           lr_decay_rate=0.0,\n",
    "                                           optimizer='RMS',\n",
    "                                           task_latent_dim=5,\n",
    "                                           activate_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = PosteriorBNNSampling('MultitaskGP', hparams_gp, 'GP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = run_contextual_bandit(context_dim, num_actions, dataset, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_actions3, h_rewards3 = results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(h_rewards3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " hparams_rms = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                            context_dim=context_dim,\n",
    "                                            init_scale=0.3,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            layer_sizes=[50],\n",
    "                                            batch_size=512,\n",
    "                                            activate_decay=True,\n",
    "                                            initial_lr=0.1,\n",
    "                                            max_grad_norm=5.0,\n",
    "                                            show_training=False,\n",
    "                                            freq_summary=1000,\n",
    "                                            buffer_s=-1,\n",
    "                                            initial_pulls=2,\n",
    "                                            optimizer='RMS',\n",
    "                                            reset_lr=True,\n",
    "                                            lr_decay_rate=0.5,\n",
    "                                            training_freq=50,\n",
    "                                            training_epochs=100,\n",
    "                                            p=0.95,\n",
    "                                            q=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = BootstrappedBNNSampling('BootRMS', hparams_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = run_contextual_bandit(context_dim, num_actions, dataset, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_actions4, h_rewards4 = results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(h_rewards4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test all models on mushroom, adult, and census datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 14\n",
    "num_contexts = 2000\n",
    "sampled_vals = sample_adult_data(os.path.join(base_route, data_route, 'adult.data'), num_contexts,\n",
    "                                     shuffle_rows=True)\n",
    "contexts, rewards, (opt_rewards, opt_actions) = sampled_vals\n",
    "dataset = np.hstack((contexts, rewards))\n",
    "context_dim = contexts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font_scale=2.5, style = 'whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_ucb = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                               context_dim=context_dim,\n",
    "                                               alpha=10.0)\n",
    "hparams_linear = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                               context_dim=context_dim,\n",
    "                                               a0=6,\n",
    "                                               b0=6,\n",
    "                                               lambda_prior=0.25,\n",
    "                                               initial_pulls=2)\n",
    "hparams_bbb = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                            context_dim=context_dim,\n",
    "                                            init_scale=0.3,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            layer_sizes=[50],\n",
    "                                            batch_size=512,\n",
    "                                            activate_decay=True,\n",
    "                                            initial_lr=0.1,\n",
    "                                            max_grad_norm=5.0,\n",
    "                                            show_training=False,\n",
    "                                            freq_summary=1000,\n",
    "                                            buffer_s=-1,\n",
    "                                            initial_pulls=2,\n",
    "                                            optimizer='RMS',\n",
    "                                            use_sigma_exp_transform=True,\n",
    "                                            cleared_times_trained=10,\n",
    "                                            initial_training_steps=100,\n",
    "                                            noise_sigma=0.1,\n",
    "                                            reset_lr=False,\n",
    "                                            training_freq=50,\n",
    "                                            training_epochs=100)\n",
    "hparams_gp = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                           num_outputs=num_actions,\n",
    "                                           context_dim=context_dim,\n",
    "                                           reset_lr=False,\n",
    "                                           learn_embeddings=True,\n",
    "                                           max_num_points=1000,\n",
    "                                           show_training=False,\n",
    "                                           freq_summary=1000,\n",
    "                                           batch_size=512,\n",
    "                                           keep_fixed_after_max_obs=True,\n",
    "                                           training_freq=50,\n",
    "                                           initial_pulls=2,\n",
    "                                           training_epochs=100,\n",
    "                                           lr=0.01,\n",
    "                                           buffer_s=-1,\n",
    "                                           initial_lr=0.001,\n",
    "                                           lr_decay_rate=0.0,\n",
    "                                           optimizer='RMS',\n",
    "                                           task_latent_dim=5,\n",
    "                                           activate_decay=False)\n",
    "hparams_rms = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                            context_dim=context_dim,\n",
    "                                            init_scale=0.3,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            layer_sizes=[50],\n",
    "                                            batch_size=512,\n",
    "                                            activate_decay=True,\n",
    "                                            initial_lr=0.1,\n",
    "                                            max_grad_norm=5.0,\n",
    "                                            show_training=False,\n",
    "                                            freq_summary=1000,\n",
    "                                            buffer_s=-1,\n",
    "                                            initial_pulls=2,\n",
    "                                            optimizer='RMS',\n",
    "                                            reset_lr=True,\n",
    "                                            lr_decay_rate=0.5,\n",
    "                                            training_freq=50,\n",
    "                                            training_epochs=100,\n",
    "                                            p=0.95,\n",
    "                                            q=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [\n",
    "      LinUcb('LinUCB', hparams_ucb),\n",
    "      PosteriorBNNSampling('BBB', hparams_bbb, 'Variational'),\n",
    "      LinTS('LinFullPost', hparams_linear),\n",
    "      BootstrappedBNNSampling('BootRMS', hparams_rms),\n",
    "      PosteriorBNNSampling('MultitaskGP', hparams_gp, 'GP'),\n",
    "      \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_contextual_bandit_algos(context_dim, num_actions, dataset, algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " _, h_rewards = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(np.arange(0,2000),np.cumsum(h_rewards[:,i]),label= a.name)\n",
    "plt.legend(loc= 'best')\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('cumulative reward - adult data')\n",
    "#plt.ylim((0,2000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards[:,i]),label= a.name)\n",
    "plt.legend(loc= 'best')\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('cumulative regret - adult data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 9\n",
    "num_contexts = 2000\n",
    "sampled_vals = sample_census_data(os.path.join(base_route, data_route, 'USCensus1990.data.txt'), num_contexts,\n",
    "                                      shuffle_rows=True)\n",
    "contexts, rewards, (opt_rewards, opt_actions) = sampled_vals\n",
    "dataset = np.hstack((contexts, rewards))\n",
    "context_dim = contexts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [\n",
    "      LinUcb('LinUCB', hparams_ucb),\n",
    "      PosteriorBNNSampling('BBB', hparams_bbb, 'Variational'),\n",
    "      BootstrappedBNNSampling('BootRMS', hparams_rms),\n",
    "      PosteriorBNNSampling('MultitaskGP', hparams_gp, 'GP')\n",
    "      \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = run_contextual_bandit_algos(context_dim, num_actions, dataset, algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " _, h_rewards2 = results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(np.arange(0,2000),np.cumsum(h_rewards2[:,i]),label= a.name)\n",
    "plt.legend(loc= 'best')\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('cumulative reward - census data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards2[:,i]),label= a.name)\n",
    "plt.legend(loc= 'best')\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('cumulative regret - census data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contexts = 2000\n",
    "num_actions = 2\n",
    "context_dim = 117\n",
    "dataset, opt_mushroom = sample_mushroom_data('mushrooms.csv', num_contexts)\n",
    "opt_rewards, opt_actions = opt_mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = run_contextual_bandit_algos(context_dim, num_actions, dataset, algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h_rewards3 = results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(np.arange(0,2000),np.cumsum(h_rewards3[:,i]),label= a.name)\n",
    "ax.legend(loc= 'best')\n",
    "ax.set_xlabel('rounds')\n",
    "ax.set_ylabel('cumulative reward - mushrooms data')\n",
    "\n",
    "plt.xlim((0,2000))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "for i, a in enumerate(algos):\n",
    "    plt.plot(np.arange(0,2000),np.cumsum(opt_rewards - h_rewards3[:,i]),label= a.name)\n",
    "plt.legend(loc= 'upper left')\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('cumulative regret - mushrooms data')\n",
    "plt.xlim((0,2000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
